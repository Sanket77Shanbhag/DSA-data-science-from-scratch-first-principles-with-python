{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99438649",
   "metadata": {},
   "source": [
    "# Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a71a27a2",
   "metadata": {},
   "source": [
    "## Overfitting and Underfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e86607fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "750\n",
      "250\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 766, 767, 768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 791, 792, 793, 794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 819, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 865, 866, 867, 868, 869, 870, 871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 894, 895, 896, 897, 898, 899, 900, 901, 902, 903, 904, 905, 906, 907, 908, 909, 910, 911, 912, 913, 914, 915, 916, 917, 918, 919, 920, 921, 922, 923, 924, 925, 926, 927, 928, 929, 930, 931, 932, 933, 934, 935, 936, 937, 938, 939, 940, 941, 942, 943, 944, 945, 946, 947, 948, 949, 950, 951, 952, 953, 954, 955, 956, 957, 958, 959, 960, 961, 962, 963, 964, 965, 966, 967, 968, 969, 970, 971, 972, 973, 974, 975, 976, 977, 978, 979, 980, 981, 982, 983, 984, 985, 986, 987, 988, 989, 990, 991, 992, 993, 994, 995, 996, 997, 998, 999]\n",
      "\n",
      "Train\n",
      "\n",
      "[653, 757, 181, 571, 657, 692, 620, 332, 400, 212, 698, 809, 231, 198, 413, 457, 86, 321, 647, 566, 814, 802, 475, 493, 41, 253, 49, 477, 66, 550, 867, 27, 276, 902, 293, 969, 752, 974, 85, 779, 127, 954, 999, 106, 582, 701, 281, 515, 626, 184, 789, 950, 939, 29, 112, 447, 923, 801, 658, 450, 768, 1, 409, 492, 933, 666, 421, 682, 731, 952, 143, 463, 670, 524, 745, 317, 257, 182, 263, 43, 612, 302, 967, 603, 297, 72, 58, 35, 157, 363, 69, 186, 711, 798, 282, 162, 738, 860, 734, 895, 303, 963, 859, 987, 529, 928, 526, 216, 361, 588, 926, 342, 486, 262, 563, 468, 713, 712, 695, 997, 78, 425, 964, 345, 811, 758, 690, 336, 28, 368, 200, 494, 395, 917, 199, 154, 804, 996, 60, 256, 482, 335, 490, 742, 73, 879, 805, 175, 227, 573, 961, 64, 68, 691, 592, 760, 577, 824, 308, 846, 756, 31, 871, 929, 138, 506, 857, 773, 201, 514, 841, 296, 279, 489, 459, 993, 995, 552, 59, 11, 485, 930, 38, 220, 445, 604, 340, 384, 453, 883, 722, 179, 319, 96, 575, 411, 893, 674, 399, 500, 517, 544, 791, 904, 746, 763, 61, 33, 105, 289, 374, 221, 781, 716, 994, 729, 318, 346, 111, 145, 275, 813, 892, 667, 410, 313, 356, 655, 280, 812, 737, 567, 373, 367, 480, 642, 862, 168, 661, 89, 99, 130, 6, 4, 793, 539, 975, 527, 159, 633, 803, 911, 706, 625, 856, 645, 84, 379, 235, 677, 102, 79, 808, 615, 680, 547, 338, 607, 381, 330, 958, 241, 989, 378, 444, 245, 866, 912, 631, 75, 22, 663, 583, 94, 424, 827, 502, 555, 700, 383, 935, 403, 87, 823, 462, 880, 537, 497, 67, 748, 194, 446, 606, 498, 355, 464, 171, 0, 487, 702, 299, 77, 875, 774, 298, 783, 560, 918, 551, 839, 795, 837, 634, 101, 173, 810, 150, 481, 764, 254, 214, 135, 366, 161, 437, 426, 873, 643, 510, 505, 50, 422, 649, 46, 564, 430, 264, 609, 114, 948, 672, 471, 614, 507, 516, 715, 129, 449, 304, 513, 532, 504, 877, 167, 389, 541, 250, 248, 676, 122, 858, 818, 370, 287, 905, 569, 291, 434, 329, 323, 852, 762, 236, 888, 908, 316, 215, 30, 347, 116, 641, 988, 650, 901, 924, 40, 382, 820, 121, 761, 397, 62, 348, 71, 247, 436, 310, 226, 985, 819, 158, 18, 479, 5, 600, 14, 372, 63, 854, 193, 998, 668, 277, 364, 579, 315, 694, 115, 472, 126, 743, 417, 431, 776, 730, 230, 285, 847, 333, 972, 755, 654, 942, 448, 863, 719, 343, 849, 769, 979, 728, 495, 896, 747, 630, 206, 619, 76, 595, 766, 23, 213, 765, 272, 141, 55, 953, 283, 570, 512, 234, 944, 540, 605, 898, 478, 983, 618, 951, 754, 561, 844, 596, 637, 782, 265, 621, 435, 217, 890, 189, 19, 739, 261, 767, 327, 197, 886, 681, 855, 393, 699, 390, 876, 753, 909, 433, 531, 307, 344, 174, 439, 800, 943, 443, 244, 233, 624, 219, 16, 339, 164, 375, 591, 391, 202, 581, 652, 401, 968, 146, 794, 290, 119, 288, 830, 611, 521, 940, 542, 139, 685, 986, 501, 57, 865, 778, 556, 861, 110, 843, 557, 786, 723, 451, 978, 249, 203, 836, 709, 369, 683, 312, 432, 460, 268, 562, 553, 169, 301, 707, 897, 461, 117, 44, 269, 651, 353, 669, 519, 328, 429, 440, 137, 415, 720, 442, 151, 936, 934, 362, 314, 93, 441, 970, 456, 2, 635, 906, 386, 113, 48, 554, 925, 423, 664, 869, 42, 153, 835, 775, 491, 240, 88, 977, 385, 152, 736, 140, 991, 228, 831, 790, 816, 696, 850, 331, 587, 488, 937, 15, 599, 103, 81, 408, 354, 270, 822, 416, 840, 616, 714, 133, 981, 104, 47, 799, 404, 772, 697, 324, 83, 919, 196, 123, 128, 476, 108, 286, 622, 724, 522, 887, 727, 255, 322, 405, 662, 945, 932, 833, 278, 218, 920, 632, 350, 576, 740, 148, 365, 735, 965, 107, 872, 412, 565, 80, 232, 894, 710, 732, 982, 238, 273, 54, 543, 134, 656, 271, 149, 191, 785, 118, 608, 574, 949, 438, 207, 132, 465, 525, 770, 190, 124, 239, 337, 24, 884, 646, 53, 225, 590, 851, 629, 874, 82, 891, 580, 326, 885, 613, 796, 419, 520, 914, 689, 52, 907, 205, 509, 467, 792, 946, 195, 536, 74, 585, 915, 826, 548]\n",
      "\n",
      "Test\n",
      "\n",
      "[959, 589, 586, 380, 718, 147, 593, 617, 387, 209, 864, 853, 51, 825, 176, 258, 469, 955, 787, 638, 665, 394, 163, 187, 878, 156, 941, 402, 160, 180, 903, 708, 780, 208, 538, 601, 473, 726, 828, 155, 845, 559, 882, 992, 980, 100, 25, 56, 829, 166, 352, 251, 131, 37, 172, 821, 771, 90, 751, 36, 602, 407, 97, 136, 913, 144, 499, 177, 188, 398, 725, 693, 675, 70, 921, 957, 838, 644, 349, 170, 237, 688, 357, 610, 243, 294, 13, 721, 229, 759, 648, 815, 640, 931, 750, 503, 703, 788, 797, 976, 420, 717, 211, 916, 627, 545, 922, 45, 777, 341, 704, 109, 222, 868, 260, 92, 684, 252, 351, 65, 518, 679, 484, 454, 39, 223, 806, 990, 396, 210, 267, 938, 305, 474, 427, 584, 678, 428, 705, 10, 899, 91, 528, 984, 470, 371, 671, 870, 376, 572, 295, 534, 623, 549, 7, 733, 889, 259, 300, 392, 900, 266, 309, 325, 594, 558, 12, 568, 971, 508, 686, 956, 659, 359, 483, 533, 834, 511, 311, 973, 418, 744, 458, 360, 455, 358, 246, 687, 26, 927, 639, 910, 224, 628, 535, 204, 466, 578, 741, 120, 807, 966, 306, 962, 183, 546, 178, 377, 320, 673, 832, 292, 142, 185, 165, 17, 523, 636, 947, 960, 20, 784, 284, 749, 848, 817, 192, 21, 406, 496, 9, 388, 125, 95, 98, 8, 660, 242, 334, 452, 32, 3, 842, 530, 881, 598, 414, 597, 34, 274]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from typing import TypeVar, List, Tuple\n",
    "X = TypeVar('X') # generic type to represent a data point\n",
    "def split_data(data: List[X], prob: float) -> Tuple[List[X], List[X]]:\n",
    "    \"\"\"Split data into fractions [prob, 1 - prob]\"\"\"\n",
    "    data = data[:] # Make a shallow copy\n",
    "    random.shuffle(data) # because shuffle modifies the list.\n",
    "    cut = int(len(data) * prob) # Use prob to find a cutoff\n",
    "    return data[:cut], data[cut:] # and split the shuffled list there.\n",
    "data = [n for n in range(1000)]\n",
    "train, test = split_data(data, 0.75)\n",
    "print(len(train) == 750)\n",
    "print(len(test) == 250)\n",
    "# And the original data should be preserved (in some order)\n",
    "print(sorted(train + test) == data)\n",
    "print(len(train))\n",
    "print(len(test))\n",
    "print(sorted(train + test))\n",
    "print(\"\\nTrain\\n\")\n",
    "print(train)\n",
    "print(\"\\nTest\\n\")\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c85ac13a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([284, 232, 797, 344, 4, 150, 223, 660, 33, 461, 659, 146, 229, 239, 802, 876, 669, 758, 913, 249, 186, 918, 418, 273, 524, 225, 34, 384, 112, 734, 870, 634, 393, 134, 751, 488, 893, 736, 908, 420, 725, 32, 123, 845, 569, 811, 783, 780, 218, 901, 19, 801, 830, 436, 38, 216, 793, 788, 293, 415, 760, 644, 724, 60, 828, 889, 1, 492, 290, 857, 104, 605, 392, 868, 938, 147, 368, 298, 621, 877, 589, 632, 466, 312, 681, 140, 113, 366, 731, 458, 502, 525, 954, 424, 558, 800, 951, 432, 608, 401, 750, 917, 543, 834, 428, 181, 988, 869, 380, 460, 114, 606, 156, 208, 369, 192, 803, 101, 299, 258, 972, 199, 200, 373, 993, 804, 257, 269, 204, 756, 878, 388, 735, 538, 916, 774, 479, 506, 814, 370, 96, 705, 371, 339, 707, 168, 598, 320, 568, 625, 838, 958, 408, 233, 636, 53, 884, 775, 743, 854, 821, 306, 153, 36, 700, 921, 28, 674, 451, 965, 791, 649, 185, 596, 259, 100, 840, 255, 975, 944, 429, 449, 886, 687, 26, 934, 195, 266, 516, 365, 635, 125, 405, 422, 794, 620, 343, 684, 910, 866, 648, 495, 43, 355, 303, 247, 282, 325, 176, 234, 667, 853, 287, 860, 473, 59, 121, 280, 852, 390, 427, 350, 950, 271, 699, 119, 481, 795, 3, 326, 474, 730, 262, 385, 983, 95, 15, 179, 646, 718, 627, 142, 576, 981, 551, 978, 122, 209, 554, 377, 920, 680, 402, 604, 201, 552, 726, 85, 624, 688, 555, 927, 141, 855, 618, 361, 575, 629, 677, 395, 892, 48, 945, 13, 991, 413, 285, 54, 189, 593, 286, 490, 588, 237, 582, 906, 345, 599, 275, 406, 241, 990, 319, 662, 856, 739, 88, 497, 987, 58, 316, 727, 723, 363, 663, 118, 374, 753, 813, 847, 661, 434, 99, 116, 633, 527, 896, 22, 622, 611, 310, 640, 357, 202, 683, 8, 277, 337, 172, 989, 90, 431, 307, 609, 163, 509, 689, 710, 940, 762, 404, 656, 748, 110, 679, 362, 963, 778, 690, 973, 205, 84, 417, 330, 174, 435, 340, 499, 925, 678, 571, 882, 504, 903, 397, 311, 213, 398, 250, 759, 194, 9, 453, 900, 712, 645, 341, 553, 915, 939, 749, 733, 314, 493, 767, 865, 386, 489, 980, 773, 665, 976, 455, 391, 581, 518, 376, 477, 722, 254, 974, 879, 744, 947, 144, 768, 188, 91, 531, 149, 106, 992, 45, 912, 93, 65, 67, 914, 696, 111, 383, 755, 322, 178, 772, 108, 960, 313, 62, 837, 924, 215, 69, 425, 578, 776, 484, 190, 248, 702, 505, 97, 833, 251, 214, 462, 708, 302, 272, 57, 769, 628, 573, 0, 278, 463, 969, 638, 639, 513, 126, 567, 964, 672, 586, 327, 873, 245, 55, 709, 267, 949, 304, 11, 532, 522, 874, 592, 73, 511, 78, 264, 68, 41, 970, 946, 706, 394, 512, 236, 468, 494, 703, 549, 997, 832, 177, 301, 63, 641, 826, 809, 471, 360, 537, 129, 86, 130, 806, 170, 379, 328, 56, 716, 521, 729, 996, 265, 715, 261, 786, 445, 984, 810, 143, 559, 183, 955, 533, 765, 529, 720, 848, 446, 798, 46, 867, 222, 761, 407, 986, 595, 92, 871, 61, 224, 746, 872, 335, 443, 577, 841, 923, 207, 162, 842, 448, 292, 18, 742, 30, 191, 295, 347, 745, 933, 615, 331, 610, 535, 17, 132, 403, 607, 387, 514, 931, 982, 670, 671, 210, 523, 704, 7, 597, 603, 151, 206, 928, 861, 711, 647, 587, 815, 657, 898, 79, 419, 979, 654, 77, 220, 348, 81, 421, 808, 486, 544, 103, 44, 70, 211, 875, 591, 161, 602, 998, 336, 133, 296, 694, 904, 217, 907, 136, 496, 550, 324, 820, 184, 396, 570, 698, 173, 242, 378, 905, 372, 902, 353, 766, 268, 911, 827, 652, 442, 719, 152, 507, 807, 66, 309, 738, 561, 300, 107, 883, 128, 966, 850, 631, 732, 894, 967, 29, 691, 228, 819, 478, 414, 952, 962, 164, 585, 332, 193, 410, 673, 238, 862, 102, 167, 82, 721, 501, 439, 556, 822, 294, 2, 999, 35, 12, 226, 166, 717, 24, 812, 851, 752, 835, 839, 354, 148, 930, 642, 666, 740, 52, 546, 899, 637, 858, 864, 240, 787, 942, 823, 519, 651, 72, 154, 246, 212, 600, 105, 937, 283, 594, 470, 198, 437, 158, 342, 47, 117, 175, 14, 948, 423, 476, 818, 231, 926, 131, 323, 253, 844, 515, 318], [21, 764, 74, 6, 89, 849, 796, 616, 658, 526, 159, 548, 31, 454, 456, 308, 885, 846, 115, 375, 613, 447, 334, 80, 426, 676, 508, 590, 701, 180, 367, 480, 985, 564, 459, 139, 956, 770, 977, 317, 824, 686, 643, 887, 713, 227, 382, 697, 668, 560, 650, 483, 500, 433, 536, 457, 472, 75, 995, 349, 469, 897, 929, 155, 935, 863, 297, 221, 545, 792, 124, 279, 961, 836, 23, 452, 541, 685, 583, 565, 364, 187, 692, 785, 817, 623, 695, 87, 219, 409, 540, 584, 741, 40, 805, 39, 539, 574, 953, 909, 957, 528, 799, 557, 510, 358, 614, 630, 714, 779, 389, 42, 352, 244, 98, 138, 747, 932, 338, 890, 579, 165, 412, 5, 305, 27, 757, 547, 37, 626, 203, 145, 831, 270, 653, 315, 601, 416, 675, 994, 520, 71, 617, 971, 485, 693, 444, 475, 351, 157, 919, 51, 346, 572, 825, 754, 76, 321, 430, 728, 235, 790, 25, 859, 450, 20, 127, 160, 356, 737, 619, 465, 291, 580, 888, 566, 771, 281, 563, 782, 895, 941, 171, 440, 263, 276, 880, 260, 289, 399, 542, 137, 243, 784, 843, 922, 16, 135, 169, 182, 534, 959, 829, 109, 891, 881, 498, 64, 94, 968, 333, 816, 491, 329, 120, 517, 482, 197, 10, 530, 196, 763, 562, 252, 682, 664, 83, 467, 230, 50, 288, 503, 789, 438, 781, 256, 411, 936, 943, 464, 441, 612, 400, 274, 381, 49, 487, 777, 655, 359], [568, 464, 1594, 688, 8, 300, 446, 1320, 66, 922, 1318, 292, 458, 478, 1604, 1752, 1338, 1516, 1826, 498, 372, 1836, 836, 546, 1048, 450, 68, 768, 224, 1468, 1740, 1268, 786, 268, 1502, 976, 1786, 1472, 1816, 840, 1450, 64, 246, 1690, 1138, 1622, 1566, 1560, 436, 1802, 38, 1602, 1660, 872, 76, 432, 1586, 1576, 586, 830, 1520, 1288, 1448, 120, 1656, 1778, 2, 984, 580, 1714, 208, 1210, 784, 1736, 1876, 294, 736, 596, 1242, 1754, 1178, 1264, 932, 624, 1362, 280, 226, 732, 1462, 916, 1004, 1050, 1908, 848, 1116, 1600, 1902, 864, 1216, 802, 1500, 1834, 1086, 1668, 856, 362, 1976, 1738, 760, 920, 228, 1212, 312, 416, 738, 384, 1606, 202, 598, 516, 1944, 398, 400, 746, 1986, 1608, 514, 538, 408, 1512, 1756, 776, 1470, 1076, 1832, 1548, 958, 1012, 1628, 740, 192, 1410, 742, 678, 1414, 336, 1196, 640, 1136, 1250, 1676, 1916, 816, 466, 1272, 106, 1768, 1550, 1486, 1708, 1642, 612, 306, 72, 1400, 1842, 56, 1348, 902, 1930, 1582, 1298, 370, 1192, 518, 200, 1680, 510, 1950, 1888, 858, 898, 1772, 1374, 52, 1868, 390, 532, 1032, 730, 1270, 250, 810, 844, 1588, 1240, 686, 1368, 1820, 1732, 1296, 990, 86, 710, 606, 494, 564, 650, 352, 468, 1334, 1706, 574, 1720, 946, 118, 242, 560, 1704, 780, 854, 700, 1900, 542, 1398, 238, 962, 1590, 6, 652, 948, 1460, 524, 770, 1966, 190, 30, 358, 1292, 1436, 1254, 284, 1152, 1962, 1102, 1956, 244, 418, 1108, 754, 1840, 1360, 804, 1208, 402, 1104, 1452, 170, 1248, 1376, 1110, 1854, 282, 1710, 1236, 722, 1150, 1258, 1354, 790, 1784, 96, 1890, 26, 1982, 826, 570, 108, 378, 1186, 572, 980, 1176, 474, 1164, 1812, 690, 1198, 550, 812, 482, 1980, 638, 1324, 1712, 1478, 176, 994, 1974, 116, 632, 1454, 1446, 726, 1326, 236, 748, 1506, 1626, 1694, 1322, 868, 198, 232, 1266, 1054, 1792, 44, 1244, 1222, 620, 1280, 714, 404, 1366, 16, 554, 674, 344, 1978, 180, 862, 614, 1218, 326, 1018, 1378, 1420, 1880, 1524, 808, 1312, 1496, 220, 1358, 724, 1926, 1556, 1380, 1946, 410, 168, 834, 660, 348, 870, 680, 998, 1850, 1356, 1142, 1764, 1008, 1806, 794, 622, 426, 796, 500, 1518, 388, 18, 906, 1800, 1424, 1290, 682, 1106, 1830, 1878, 1498, 1466, 628, 986, 1534, 1730, 772, 978, 1960, 1546, 1330, 1952, 910, 782, 1162, 1036, 752, 954, 1444, 508, 1948, 1758, 1488, 1894, 288, 1536, 376, 182, 1062, 298, 212, 1984, 90, 1824, 186, 130, 134, 1828, 1392, 222, 766, 1510, 644, 356, 1544, 216, 1920, 626, 124, 1674, 1848, 430, 138, 850, 1156, 1552, 968, 380, 496, 1404, 1010, 194, 1666, 502, 428, 924, 1416, 604, 544, 114, 1538, 1256, 1146, 0, 556, 926, 1938, 1276, 1278, 1026, 252, 1134, 1928, 1344, 1172, 654, 1746, 490, 110, 1418, 534, 1898, 608, 22, 1064, 1044, 1748, 1184, 146, 1022, 156, 528, 136, 82, 1940, 1892, 1412, 788, 1024, 472, 936, 988, 1406, 1098, 1994, 1664, 354, 602, 126, 1282, 1652, 1618, 942, 720, 1074, 258, 172, 260, 1612, 340, 758, 656, 112, 1432, 1042, 1458, 1992, 530, 1430, 522, 1572, 890, 1968, 1620, 286, 1118, 366, 1910, 1066, 1530, 1058, 1440, 1696, 892, 1596, 92, 1734, 444, 1522, 814, 1972, 1190, 184, 1742, 122, 448, 1492, 1744, 670, 886, 1154, 1682, 1846, 414, 324, 1684, 896, 584, 36, 1484, 60, 382, 590, 694, 1490, 1866, 1230, 662, 1220, 1070, 34, 264, 806, 1214, 774, 1028, 1862, 1964, 1340, 1342, 420, 1046, 1408, 14, 1194, 1206, 302, 412, 1856, 1722, 1422, 1294, 1174, 1630, 1314, 1796, 158, 838, 1958, 1308, 154, 440, 696, 162, 842, 1616, 972, 1088, 206, 88, 140, 422, 1750, 1182, 322, 1204, 1996, 672, 266, 592, 1388, 1808, 434, 1814, 272, 992, 1100, 648, 1640, 368, 792, 1140, 1396, 346, 484, 756, 1810, 744, 1804, 706, 1532, 536, 1822, 1654, 1304, 884, 1438, 304, 1014, 1614, 132, 618, 1476, 1122, 600, 214, 1766, 256, 1932, 1700, 1262, 1464, 1788, 1934, 58, 1382, 456, 1638, 956, 828, 1904, 1924, 328, 1170, 664, 386, 820, 1346, 476, 1724, 204, 334, 164, 1442, 1002, 878, 1112, 1644, 588, 4, 1998, 70, 24, 452, 332, 1434, 48, 1624, 1702, 1504, 1670, 1678, 708, 296, 1860, 1284, 1332, 1480, 104, 1092, 1798, 1274, 1716, 1728, 480, 1574, 1884, 1646, 1038, 1302, 144, 308, 492, 424, 1200, 210, 1874, 566, 1188, 940, 396, 874, 316, 684, 94, 234, 350, 28, 1896, 846, 952, 1636, 462, 1852, 262, 646, 506, 1688, 1030, 636], [42, 1528, 148, 12, 178, 1698, 1592, 1232, 1316, 1052, 318, 1096, 62, 908, 912, 616, 1770, 1692, 230, 750, 1226, 894, 668, 160, 852, 1352, 1016, 1180, 1402, 360, 734, 960, 1970, 1128, 918, 278, 1912, 1540, 1954, 634, 1648, 1372, 1286, 1774, 1426, 454, 764, 1394, 1336, 1120, 1300, 966, 1000, 866, 1072, 914, 944, 150, 1990, 698, 938, 1794, 1858, 310, 1870, 1726, 594, 442, 1090, 1584, 248, 558, 1922, 1672, 46, 904, 1082, 1370, 1166, 1130, 728, 374, 1384, 1570, 1634, 1246, 1390, 174, 438, 818, 1080, 1168, 1482, 80, 1610, 78, 1078, 1148, 1906, 1818, 1914, 1056, 1598, 1114, 1020, 716, 1228, 1260, 1428, 1558, 778, 84, 704, 488, 196, 276, 1494, 1864, 676, 1780, 1158, 330, 824, 10, 610, 54, 1514, 1094, 74, 1252, 406, 290, 1662, 540, 1306, 630, 1202, 832, 1350, 1988, 1040, 142, 1234, 1942, 970, 1386, 888, 950, 702, 314, 1838, 102, 692, 1144, 1650, 1508, 152, 642, 860, 1456, 470, 1580, 50, 1718, 900, 40, 254, 320, 712, 1474, 1238, 930, 582, 1160, 1776, 1132, 1542, 562, 1126, 1564, 1790, 1882, 342, 880, 526, 552, 1760, 520, 578, 798, 1084, 274, 486, 1568, 1686, 1844, 32, 270, 338, 364, 1068, 1918, 1658, 218, 1782, 1762, 996, 128, 188, 1936, 666, 1632, 982, 658, 240, 1034, 964, 394, 20, 1060, 392, 1526, 1124, 504, 1364, 1328, 166, 934, 460, 100, 576, 1006, 1578, 876, 1562, 512, 822, 1872, 1886, 928, 882, 1224, 800, 548, 762, 98, 974, 1554, 1310, 718])\n"
     ]
    }
   ],
   "source": [
    "Y = TypeVar('Y') # generic type to represent output variables\n",
    "def train_test_split(xs: List[X],\n",
    "ys: List[Y],\n",
    "test_pct: float) -> Tuple[List[X], List[X], List[Y],\n",
    "List[Y]]:\n",
    "# Generate the indices and split them\n",
    "    idxs = [i for i in range(len(xs))]\n",
    "    train_idxs, test_idxs = split_data(idxs, 1 - test_pct)\n",
    "    return ([xs[i] for i in train_idxs], # x_train\n",
    "[xs[i] for i in test_idxs], # x_test\n",
    "[ys[i] for i in train_idxs], # y_train\n",
    "[ys[i] for i in test_idxs]) # y_test\n",
    "\n",
    "xs = [x for x in range(1000)] # xs are 1 ... 1000\n",
    "ys = [2 * x for x in xs] # each y_i is twice x_i\n",
    "x_train, x_test, y_train, y_test = train_test_split(xs, ys, 0.25)\n",
    "print(train_test_split(xs, ys, 0.25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f6472dc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of x_train\n",
      "750\n",
      "Length of y_train\n",
      "750\n",
      "Length of x_test\n",
      "250\n",
      "Length of y_test\n",
      "250\n"
     ]
    }
   ],
   "source": [
    "Y = TypeVar('Y') # generic type to represent output variables\n",
    "def train_test_split(xs: List[X],\n",
    "ys: List[Y],\n",
    "test_pct: float) -> Tuple[List[X], List[X], List[Y],\n",
    "List[Y]]:\n",
    "# Generate the indices and split them\n",
    "    idxs = [i for i in range(len(xs))]\n",
    "    train_idxs, test_idxs = split_data(idxs, 1 - test_pct)\n",
    "    return ([xs[i] for i in train_idxs], # x_train\n",
    "[xs[i] for i in test_idxs], # x_test\n",
    "[ys[i] for i in train_idxs], # y_train\n",
    "[ys[i] for i in test_idxs]) # y_test\n",
    "\n",
    "xs = [x for x in range(1000)] # xs are 1 ... 1000\n",
    "ys = [2 * x for x in xs] # each y_i is twice x_i\n",
    "x_train, x_test, y_train, y_test = train_test_split(xs, ys, 0.25)\n",
    "#print(train_test_split(xs, ys, 0.25))\n",
    "\n",
    "# Check that the proportions are correct\n",
    "print(\"Length of x_train\")\n",
    "print(len(x_train))\n",
    "print(\"Length of y_train\")\n",
    "print(len(y_train))\n",
    "print(\"Length of x_test\")\n",
    "print(len(x_test))\n",
    "print(\"Length of y_test\")\n",
    "print(len(y_test))\n",
    "\n",
    "# Check that the corresponding data points are paired correctly\n",
    "assert all(y == 2 * x for x, y in zip(x_train, y_train))\n",
    "assert all(y == 2 * x for x, y in zip(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9e0b6d12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00736842105263158"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def accuracy(tp: int, fp: int, fn: int, tn: int) -> float:\n",
    "    correct = tp + tn\n",
    "    total = tp + fp + fn + tn\n",
    "    return correct / total\n",
    "accuracy(70, 4930, 13930, 981070)\n",
    "\n",
    "def precision(tp: int, fp: int, fn: int, tn: int) -> float:\n",
    "    return tp / (tp + fp)\n",
    "precision(70, 4930, 13930, 981070)\n",
    "\n",
    "def recall(tp: int, fp: int, fn: int, tn: int) -> float:\n",
    "    return tp / (tp + fn)\n",
    "recall(70, 4930, 13930, 981070)\n",
    "\n",
    "def f1_score(tp: int, fp: int, fn: int, tn: int) -> float:\n",
    "    p = precision(tp, fp, fn, tn)\n",
    "    r = recall(tp, fp, fn, tn)\n",
    "    return 2 * p * r / (p + r)\n",
    "f1_score(70, 4930, 13930, 981070)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ccb1961",
   "metadata": {},
   "source": [
    "# k-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a467a389",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b\n"
     ]
    }
   ],
   "source": [
    "from typing import List\n",
    "from collections import Counter\n",
    "def raw_majority_vote(labels: List[str]) -> str:\n",
    "    votes = Counter(labels)\n",
    "    winner, _ = votes.most_common(1)[0]\n",
    "    return winner\n",
    "raw_majority_vote(['a', 'b', 'c', 'b'])\n",
    "\n",
    "\n",
    "def majority_vote(labels: List[str]) -> str:\n",
    "    \"\"\"Assumes that labels are ordered from nearest to farthest.\"\"\"\n",
    "    vote_counts = Counter(labels)\n",
    "    winner, winner_count = vote_counts.most_common(1)[0]\n",
    "    num_winners = len([count\n",
    "        for count in vote_counts.values()\n",
    "    if count == winner_count])\n",
    "    if (num_winners == 1):\n",
    "        return winner # unique winner, so return it\n",
    "    else:\n",
    "        return majority_vote(labels[:-1]) # try again without the farthest\n",
    "# Tie, so look at first 4, then 'b'\n",
    "print(majority_vote(['a', 'b', 'c', 'b', 'a']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f20ccb0",
   "metadata": {},
   "source": [
    "# Example: The Iris Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "579db341",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from collections import Counter\n",
    "\n",
    "def raw_majority_vote(labels: List[str]) -> str:\n",
    "    votes = Counter(labels)\n",
    "    winner, _ = votes.most_common(1)[0]\n",
    "    return winner\n",
    "\n",
    "assert raw_majority_vote(['a', 'b', 'c', 'b']) == 'b'\n",
    "\n",
    "def majority_vote(labels: List[str]) -> str:\n",
    "    \"\"\"Assumes that labels are ordered from nearest to farthest.\"\"\"\n",
    "    vote_counts = Counter(labels)\n",
    "    winner, winner_count = vote_counts.most_common(1)[0]\n",
    "    num_winners = len([count\n",
    "                       for count in vote_counts.values()\n",
    "                       if count == winner_count])\n",
    "\n",
    "    if num_winners == 1:\n",
    "        return winner                     # unique winner, so return it\n",
    "    else:\n",
    "        return majority_vote(labels[:-1]) # try again without the farthest\n",
    "\n",
    "# Tie, so look at first 4, then 'b'\n",
    "assert majority_vote(['a', 'b', 'c', 'b', 'a']) == 'b'\n",
    "\n",
    "from typing import NamedTuple\n",
    "from scratch.linear_algebra import Vector, distance\n",
    "\n",
    "class LabeledPoint(NamedTuple):\n",
    "    point: Vector\n",
    "    label: str\n",
    "\n",
    "def knn_classify(k: int,\n",
    "                 labeled_points: List[LabeledPoint],\n",
    "                 new_point: Vector) -> str:\n",
    "\n",
    "    # Order the labeled points from nearest to farthest.\n",
    "    by_distance = sorted(labeled_points,\n",
    "                         key=lambda lp: distance(lp.point, new_point))\n",
    "\n",
    "    # Find the labels for the k closest\n",
    "    k_nearest_labels = [lp.label for lp in by_distance[:k]]\n",
    "\n",
    "    # and let them vote.\n",
    "    return majority_vote(k_nearest_labels)\n",
    "\n",
    "\n",
    "import random\n",
    "\n",
    "def random_point(dim: int) -> Vector:\n",
    "    return [random.random() for _ in range(dim)]\n",
    "\n",
    "def random_distances(dim: int, num_pairs: int) -> List[float]:\n",
    "    return [distance(random_point(dim), random_point(dim))\n",
    "            for _ in range(num_pairs)]\n",
    "\n",
    "def main():\n",
    "    from typing import Dict\n",
    "    import csv\n",
    "    from collections import defaultdict\n",
    "    \n",
    "    def parse_iris_row(row: List[str]) -> LabeledPoint:\n",
    "        \"\"\"\n",
    "        sepal_length, sepal_width, petal_length, petal_width, class\n",
    "        \"\"\"\n",
    "        measurements = [float(value) for value in row[:-1]]\n",
    "        # class is e.g. \"Iris-virginica\"; we just want \"virginica\"\n",
    "        label = row[-1].split(\"-\")[-1]\n",
    "    \n",
    "        return LabeledPoint(measurements, label)\n",
    "    \n",
    "    with open('iris.data') as f:\n",
    "        reader = csv.reader(f)\n",
    "        print(reader)\n",
    "        iris_data = [parse_iris_row(row) for row in reader]\n",
    "    \n",
    "    # We'll also group just the points by species/label so we can plot them.\n",
    "    points_by_species: Dict[str, List[Vector]] = defaultdict(list)\n",
    "    for iris in iris_data:\n",
    "        points_by_species[iris.label].append(iris.point)\n",
    "    \n",
    "    from matplotlib import pyplot as plt\n",
    "    metrics = ['sepal length', 'sepal width', 'petal length', 'petal width']\n",
    "    pairs = [(i, j) for i in range(4) for j in range(4) if i < j]\n",
    "    marks = ['+', '.', 'x']  # we have 3 classes, so 3 markers\n",
    "    \n",
    "    fig, ax = plt.subplots(2, 3)\n",
    "    \n",
    "    for row in range(2):\n",
    "        for col in range(3):\n",
    "            i, j = pairs[3 * row + col]\n",
    "            ax[row][col].set_title(f\"{metrics[i]} vs {metrics[j]}\", fontsize=8)\n",
    "            ax[row][col].set_xticks([])\n",
    "            ax[row][col].set_yticks([])\n",
    "    \n",
    "            for mark, (species, points) in zip(marks, points_by_species.items()):\n",
    "                xs = [point[i] for point in points]\n",
    "                ys = [point[j] for point in points]\n",
    "                ax[row][col].scatter(xs, ys, marker=mark, label=species)\n",
    "    \n",
    "    ax[-1][-1].legend(loc='lower right', prop={'size': 6})\n",
    "    # plt.show()\n",
    "    \n",
    "    \n",
    "    \n",
    "    plt.savefig('im/iris_scatter.png')\n",
    "    plt.gca().clear()\n",
    "    \n",
    "    import random\n",
    "    from scratch.machine_learning import split_data\n",
    "    \n",
    "    random.seed(12)\n",
    "    iris_train, iris_test = split_data(iris_data, 0.70)\n",
    "    assert len(iris_train) == 0.7 * 150\n",
    "    assert len(iris_test) == 0.3 * 150\n",
    "    \n",
    "    from typing import Tuple\n",
    "    \n",
    "    # track how many times we see (predicted, actual)\n",
    "    confusion_matrix: Dict[Tuple[str, str], int] = defaultdict(int)\n",
    "    num_correct = 0\n",
    "    \n",
    "    for iris in iris_test:\n",
    "        predicted = knn_classify(5, iris_train, iris.point)\n",
    "        actual = iris.label\n",
    "    \n",
    "        if predicted == actual:\n",
    "            num_correct += 1\n",
    "    \n",
    "        confusion_matrix[(predicted, actual)] += 1\n",
    "    \n",
    "    pct_correct = num_correct / len(iris_test)\n",
    "    print(pct_correct, confusion_matrix)\n",
    "    \n",
    "    import tqdm\n",
    "    dimensions = range(1, 101)\n",
    "    \n",
    "    avg_distances = []\n",
    "    min_distances = []\n",
    "    \n",
    "    random.seed(0)\n",
    "    for dim in tqdm.tqdm(dimensions, desc=\"Curse of Dimensionality\"):\n",
    "        distances = random_distances(dim, 10000)      # 10,000 random pairs\n",
    "        avg_distances.append(sum(distances) / 10000)  # track the average\n",
    "        min_distances.append(min(distances))          # track the minimum\n",
    "    \n",
    "    min_avg_ratio = [min_dist / avg_dist\n",
    "                     for min_dist, avg_dist in zip(min_distances, avg_distances)]\n",
    "    \n",
    "if __name__ == \"_main_\": main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9c4c6343",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['5.1', '3.5', '1.4', '0.2', 'Iris-setosa']\n",
      "['4.9', '3.0', '1.4', '0.2', 'Iris-setosa']\n",
      "['4.7', '3.2', '1.3', '0.2', 'Iris-setosa']\n",
      "['4.6', '3.1', '1.5', '0.2', 'Iris-setosa']\n",
      "['5.0', '3.6', '1.4', '0.2', 'Iris-setosa']\n",
      "['5.4', '3.9', '1.7', '0.4', 'Iris-setosa']\n",
      "['4.6', '3.4', '1.4', '0.3', 'Iris-setosa']\n",
      "['5.0', '3.4', '1.5', '0.2', 'Iris-setosa']\n",
      "['4.4', '2.9', '1.4', '0.2', 'Iris-setosa']\n",
      "['4.9', '3.1', '1.5', '0.1', 'Iris-setosa']\n",
      "['5.4', '3.7', '1.5', '0.2', 'Iris-setosa']\n",
      "['4.8', '3.4', '1.6', '0.2', 'Iris-setosa']\n",
      "['4.8', '3.0', '1.4', '0.1', 'Iris-setosa']\n",
      "['4.3', '3.0', '1.1', '0.1', 'Iris-setosa']\n",
      "['5.8', '4.0', '1.2', '0.2', 'Iris-setosa']\n",
      "['5.7', '4.4', '1.5', '0.4', 'Iris-setosa']\n",
      "['5.4', '3.9', '1.3', '0.4', 'Iris-setosa']\n",
      "['5.1', '3.5', '1.4', '0.3', 'Iris-setosa']\n",
      "['5.7', '3.8', '1.7', '0.3', 'Iris-setosa']\n",
      "['5.1', '3.8', '1.5', '0.3', 'Iris-setosa']\n",
      "['5.4', '3.4', '1.7', '0.2', 'Iris-setosa']\n",
      "['5.1', '3.7', '1.5', '0.4', 'Iris-setosa']\n",
      "['4.6', '3.6', '1.0', '0.2', 'Iris-setosa']\n",
      "['5.1', '3.3', '1.7', '0.5', 'Iris-setosa']\n",
      "['4.8', '3.4', '1.9', '0.2', 'Iris-setosa']\n",
      "['5.0', '3.0', '1.6', '0.2', 'Iris-setosa']\n",
      "['5.0', '3.4', '1.6', '0.4', 'Iris-setosa']\n",
      "['5.2', '3.5', '1.5', '0.2', 'Iris-setosa']\n",
      "['5.2', '3.4', '1.4', '0.2', 'Iris-setosa']\n",
      "['4.7', '3.2', '1.6', '0.2', 'Iris-setosa']\n",
      "['4.8', '3.1', '1.6', '0.2', 'Iris-setosa']\n",
      "['5.4', '3.4', '1.5', '0.4', 'Iris-setosa']\n",
      "['5.2', '4.1', '1.5', '0.1', 'Iris-setosa']\n",
      "['5.5', '4.2', '1.4', '0.2', 'Iris-setosa']\n",
      "['4.9', '3.1', '1.5', '0.1', 'Iris-setosa']\n",
      "['5.0', '3.2', '1.2', '0.2', 'Iris-setosa']\n",
      "['5.5', '3.5', '1.3', '0.2', 'Iris-setosa']\n",
      "['4.9', '3.1', '1.5', '0.1', 'Iris-setosa']\n",
      "['4.4', '3.0', '1.3', '0.2', 'Iris-setosa']\n",
      "['5.1', '3.4', '1.5', '0.2', 'Iris-setosa']\n",
      "['5.0', '3.5', '1.3', '0.3', 'Iris-setosa']\n",
      "['4.5', '2.3', '1.3', '0.3', 'Iris-setosa']\n",
      "['4.4', '3.2', '1.3', '0.2', 'Iris-setosa']\n",
      "['5.0', '3.5', '1.6', '0.6', 'Iris-setosa']\n",
      "['5.1', '3.8', '1.9', '0.4', 'Iris-setosa']\n",
      "['4.8', '3.0', '1.4', '0.3', 'Iris-setosa']\n",
      "['5.1', '3.8', '1.6', '0.2', 'Iris-setosa']\n",
      "['4.6', '3.2', '1.4', '0.2', 'Iris-setosa']\n",
      "['5.3', '3.7', '1.5', '0.2', 'Iris-setosa']\n",
      "['5.0', '3.3', '1.4', '0.2', 'Iris-setosa']\n",
      "['7.0', '3.2', '4.7', '1.4', 'Iris-versicolor']\n",
      "['6.4', '3.2', '4.5', '1.5', 'Iris-versicolor']\n",
      "['6.9', '3.1', '4.9', '1.5', 'Iris-versicolor']\n",
      "['5.5', '2.3', '4.0', '1.3', 'Iris-versicolor']\n",
      "['6.5', '2.8', '4.6', '1.5', 'Iris-versicolor']\n",
      "['5.7', '2.8', '4.5', '1.3', 'Iris-versicolor']\n",
      "['6.3', '3.3', '4.7', '1.6', 'Iris-versicolor']\n",
      "['4.9', '2.4', '3.3', '1.0', 'Iris-versicolor']\n",
      "['6.6', '2.9', '4.6', '1.3', 'Iris-versicolor']\n",
      "['5.2', '2.7', '3.9', '1.4', 'Iris-versicolor']\n",
      "['5.0', '2.0', '3.5', '1.0', 'Iris-versicolor']\n",
      "['5.9', '3.0', '4.2', '1.5', 'Iris-versicolor']\n",
      "['6.0', '2.2', '4.0', '1.0', 'Iris-versicolor']\n",
      "['6.1', '2.9', '4.7', '1.4', 'Iris-versicolor']\n",
      "['5.6', '2.9', '3.6', '1.3', 'Iris-versicolor']\n",
      "['6.7', '3.1', '4.4', '1.4', 'Iris-versicolor']\n",
      "['5.6', '3.0', '4.5', '1.5', 'Iris-versicolor']\n",
      "['5.8', '2.7', '4.1', '1.0', 'Iris-versicolor']\n",
      "['6.2', '2.2', '4.5', '1.5', 'Iris-versicolor']\n",
      "['5.6', '2.5', '3.9', '1.1', 'Iris-versicolor']\n",
      "['5.9', '3.2', '4.8', '1.8', 'Iris-versicolor']\n",
      "['6.1', '2.8', '4.0', '1.3', 'Iris-versicolor']\n",
      "['6.3', '2.5', '4.9', '1.5', 'Iris-versicolor']\n",
      "['6.1', '2.8', '4.7', '1.2', 'Iris-versicolor']\n",
      "['6.4', '2.9', '4.3', '1.3', 'Iris-versicolor']\n",
      "['6.6', '3.0', '4.4', '1.4', 'Iris-versicolor']\n",
      "['6.8', '2.8', '4.8', '1.4', 'Iris-versicolor']\n",
      "['6.7', '3.0', '5.0', '1.7', 'Iris-versicolor']\n",
      "['6.0', '2.9', '4.5', '1.5', 'Iris-versicolor']\n",
      "['5.7', '2.6', '3.5', '1.0', 'Iris-versicolor']\n",
      "['5.5', '2.4', '3.8', '1.1', 'Iris-versicolor']\n",
      "['5.5', '2.4', '3.7', '1.0', 'Iris-versicolor']\n",
      "['5.8', '2.7', '3.9', '1.2', 'Iris-versicolor']\n",
      "['6.0', '2.7', '5.1', '1.6', 'Iris-versicolor']\n",
      "['5.4', '3.0', '4.5', '1.5', 'Iris-versicolor']\n",
      "['6.0', '3.4', '4.5', '1.6', 'Iris-versicolor']\n",
      "['6.7', '3.1', '4.7', '1.5', 'Iris-versicolor']\n",
      "['6.3', '2.3', '4.4', '1.3', 'Iris-versicolor']\n",
      "['5.6', '3.0', '4.1', '1.3', 'Iris-versicolor']\n",
      "['5.5', '2.5', '4.0', '1.3', 'Iris-versicolor']\n",
      "['5.5', '2.6', '4.4', '1.2', 'Iris-versicolor']\n",
      "['6.1', '3.0', '4.6', '1.4', 'Iris-versicolor']\n",
      "['5.8', '2.6', '4.0', '1.2', 'Iris-versicolor']\n",
      "['5.0', '2.3', '3.3', '1.0', 'Iris-versicolor']\n",
      "['5.6', '2.7', '4.2', '1.3', 'Iris-versicolor']\n",
      "['5.7', '3.0', '4.2', '1.2', 'Iris-versicolor']\n",
      "['5.7', '2.9', '4.2', '1.3', 'Iris-versicolor']\n",
      "['6.2', '2.9', '4.3', '1.3', 'Iris-versicolor']\n",
      "['5.1', '2.5', '3.0', '1.1', 'Iris-versicolor']\n",
      "['5.7', '2.8', '4.1', '1.3', 'Iris-versicolor']\n",
      "['6.3', '3.3', '6.0', '2.5', 'Iris-virginica']\n",
      "['5.8', '2.7', '5.1', '1.9', 'Iris-virginica']\n",
      "['7.1', '3.0', '5.9', '2.1', 'Iris-virginica']\n",
      "['6.3', '2.9', '5.6', '1.8', 'Iris-virginica']\n",
      "['6.5', '3.0', '5.8', '2.2', 'Iris-virginica']\n",
      "['7.6', '3.0', '6.6', '2.1', 'Iris-virginica']\n",
      "['4.9', '2.5', '4.5', '1.7', 'Iris-virginica']\n",
      "['7.3', '2.9', '6.3', '1.8', 'Iris-virginica']\n",
      "['6.7', '2.5', '5.8', '1.8', 'Iris-virginica']\n",
      "['7.2', '3.6', '6.1', '2.5', 'Iris-virginica']\n",
      "['6.5', '3.2', '5.1', '2.0', 'Iris-virginica']\n",
      "['6.4', '2.7', '5.3', '1.9', 'Iris-virginica']\n",
      "['6.8', '3.0', '5.5', '2.1', 'Iris-virginica']\n",
      "['5.7', '2.5', '5.0', '2.0', 'Iris-virginica']\n",
      "['5.8', '2.8', '5.1', '2.4', 'Iris-virginica']\n",
      "['6.4', '3.2', '5.3', '2.3', 'Iris-virginica']\n",
      "['6.5', '3.0', '5.5', '1.8', 'Iris-virginica']\n",
      "['7.7', '3.8', '6.7', '2.2', 'Iris-virginica']\n",
      "['7.7', '2.6', '6.9', '2.3', 'Iris-virginica']\n",
      "['6.0', '2.2', '5.0', '1.5', 'Iris-virginica']\n",
      "['6.9', '3.2', '5.7', '2.3', 'Iris-virginica']\n",
      "['5.6', '2.8', '4.9', '2.0', 'Iris-virginica']\n",
      "['7.7', '2.8', '6.7', '2.0', 'Iris-virginica']\n",
      "['6.3', '2.7', '4.9', '1.8', 'Iris-virginica']\n",
      "['6.7', '3.3', '5.7', '2.1', 'Iris-virginica']\n",
      "['7.2', '3.2', '6.0', '1.8', 'Iris-virginica']\n",
      "['6.2', '2.8', '4.8', '1.8', 'Iris-virginica']\n",
      "['6.1', '3.0', '4.9', '1.8', 'Iris-virginica']\n",
      "['6.4', '2.8', '5.6', '2.1', 'Iris-virginica']\n",
      "['7.2', '3.0', '5.8', '1.6', 'Iris-virginica']\n",
      "['7.4', '2.8', '6.1', '1.9', 'Iris-virginica']\n",
      "['7.9', '3.8', '6.4', '2.0', 'Iris-virginica']\n",
      "['6.4', '2.8', '5.6', '2.2', 'Iris-virginica']\n",
      "['6.3', '2.8', '5.1', '1.5', 'Iris-virginica']\n",
      "['6.1', '2.6', '5.6', '1.4', 'Iris-virginica']\n",
      "['7.7', '3.0', '6.1', '2.3', 'Iris-virginica']\n",
      "['6.3', '3.4', '5.6', '2.4', 'Iris-virginica']\n",
      "['6.4', '3.1', '5.5', '1.8', 'Iris-virginica']\n",
      "['6.0', '3.0', '4.8', '1.8', 'Iris-virginica']\n",
      "['6.9', '3.1', '5.4', '2.1', 'Iris-virginica']\n",
      "['6.7', '3.1', '5.6', '2.4', 'Iris-virginica']\n",
      "['6.9', '3.1', '5.1', '2.3', 'Iris-virginica']\n",
      "['5.8', '2.7', '5.1', '1.9', 'Iris-virginica']\n",
      "['6.8', '3.2', '5.9', '2.3', 'Iris-virginica']\n",
      "['6.7', '3.3', '5.7', '2.5', 'Iris-virginica']\n",
      "['6.7', '3.0', '5.2', '2.3', 'Iris-virginica']\n",
      "['6.3', '2.5', '5.0', '1.9', 'Iris-virginica']\n",
      "['6.5', '3.0', '5.2', '2.0', 'Iris-virginica']\n",
      "['6.2', '3.4', '5.4', '2.3', 'Iris-virginica']\n",
      "['5.9', '3.0', '5.1', '1.8', 'Iris-virginica']\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgkAAAGVCAYAAAB0LmJdAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAA9hAAAPYQGoP6dpAAC6zUlEQVR4nOydeXxTVfr/PzfpnpaWtClpKVAoywzaUqHIouxFBUZGxS8u2GJdGUcQZCkgyqIDtqCgqAPqWCwuo/PTURGqAhZBBRUVWwdlKVQoTWi6p0nbbOf3R7i39yY3adImbdKc9+vFi+bec889uXnOuc8551kYQggBhUKhUCgUig2S7m4AhUKhUCgU34QqCRQKhUKhUEShSgKFQqFQKBRRqJJAoVAoFApFFKokUCgUCoVCEYUqCRQKhUKhUEShSgKFQqFQKBRRqJJAoVAoFApFFKokUCgUCoVCEcUnlYR7770XL730kug5hmHQ1NTktXtv27YNVVVV3Od169Zh2bJlXrtfd+Ds+brCzJkzUVZWJnpu8uTJ+PTTTwEAu3btwunTp7lzu3btwu23397h+/oyVGZdp76+Hvn5+S6Xd/T8vC1P5eXlePXVVwXHkpOT8euvv3rtnt0NlWPX8ZQcu8Lx48cxb9480XPl5eWIi4tz2Cb+mNwRfFJJ6E5sBZViz759+5CSktJuOVslgeId/E1m3R1cuwsxJYHiPagcOyYjIwNvv/12u+W80SaXlYTm5mbccccdGD58OEaMGIEbbriBO7d7926MGTMGI0eOxKRJkzhNe9euXZg+fTrmzJmD9PR0TJo0CRcuXAAAlJaWYsKECRg5ciSGDx+OTZs2ud34M2fOYNasWRg9ejRGjBiBV155hTvHMAzy8vIwZswYDBw4EAUFBdy5I0eOIDU1FWlpaVi4cCEGDBiAX3/9FRs2bEBlZSVuv/12pKen48SJEwCAyspK3HzzzRg+fDimTp2K2tpau7a89dZbuPnmm7nPhBAMHDgQJSUlOHPmDK677jqMGDECqampWLNmjU8+3507d+Lhhx8GAJSUlIBhGOzfvx8A8OSTT+Lpp58GIJxNnTx5kmvbvHnz0NLSAgB4/fXXcfz4cSxatAjp6enYt28fAECr1eKuu+5CamoqMjIycO7cuXbb1VF84Zna0pNklm3zunXrcN1112Ho0KF49913uXM//PADpk6dioyMDIwcORIffPABAGDBggWor69Heno6MjIyAADPP/88Ro8ejWuuuQbXXnstvvvuO7efrbPf9MYbb3Qod0888QQGDx6MMWPGYPny5VybFixYgJMnTyI9PR2zZ8/myn/wwQcYP348Bg4ciGeeecbtdroLleOeLcfjxo3D0aNHAQCPP/44kpKSuHP9+/fHxYsXcejQIe4eAPDyyy9j8ODBmDBhAl5//XXuuFib2Oc+YcIEpKSkYMGCBe22SQBxkQ8//JBMnz6d+1xTU0MIIeTrr78mM2fOJC0tLYQQQg4fPkzS0tIIIYQUFBSQsLAw8vvvvxNCCMnLyyMzZswghBDS2NjIXaPX60l6ejr54YcfCCGEzJ8/n2zfvl20HQCIVqslJpOJZGRkkN9++40QQohOpyOpqankxx9/5Mpt27aNEELIyZMnSWRkJDEajaSlpYX07duXHD58mPteAEhpaSkhhJABAwZwfxNCyNq1a8mgQYO473vHHXeQjRs32rVLr9eT2NhYolKpCCGEfPnll2TkyJGEEEIWLVpE/vGPf9g9O197vmVlZWTgwIGEEEKef/55Mm7cOJKbm0sIIWTs2LHk22+/tXtGI0eOJLt27SKEEHL06FEikUjInj17CCGETJo0ifubbW90dDQpLy8nhBCSm5tLHnroIbt2eApfeKaE9FyZZdu8bt06QohVfmJjY8mFCxdIXV0dueaaa0hlZSUhhBCNRkP69+9PVCoVOX/+PImNjRXUU1VVxf199OhRctVVV9k9P1sKCgrInDlzCCHt/6aO5O6TTz4haWlppKmpiZjNZnLrrbeSUaNGEUIIKS4u5v5mGTBgAFm8eDHX5l69epGKigrRZ+MpqBz3bDles2YNWb9+PSGEkGuuuYZce+215LfffiO///47GTp0KCFEKIu//PILSUhIIGq1mhBCyN/+9jeuHWJtmjRpEpkzZw4xmUxEr9eT5ORkbix3hSBXlYkRI0bg999/xyOPPIJJkyZh5syZAICPP/4Yv/zyC8aMGcOV1Wg0MBgMAIDrr78ew4YNAwA89NBDWLt2LQghaG5uxiOPPIITJ05AIpHg4sWLOHHihED7ccapU6fwv//9D3feeSd3TKvV4uTJkxg5ciQAcHs4f/7znxEUFAS1Wo3a2lqEh4djwoQJAIBbb70VMTExTu81Y8YMyOVyAFatr7S01K5MeHg45syZg7feegvLli1DQUEBcnJyAAATJ07E8uXLodPpMGnSJGRmZtpd7wvPd9CgQQCAc+fO4cCBA9i0aROWL1+OxsZGnD59GqNHjxaUb2xsxK+//oqsrCwAwNixY5Gamur0WV5//fUYMGAA9yy3b9/utHxn8IVnyqenySzLAw88AMAqP9dffz2OHDmCmJgYnDt3DjNmzODKEUJw6tQp7vfn8/PPP+Mf//gHampqEBQUhJMnT8JgMCAkJMTp92Rx5TcVk7vi4mLMnTsXMpkMADB//nxuxcwR7G+kUCgwaNAgnD9/Hn379nWpnR2BynHPluPMzEw8+eSTWLBgAYKDgzF37lwcOHAADMOItvfQoUOYNWsW+vTpA8D6277//vsO6weAO++8E1KpFOHh4UhPT0dZWRnGjRvn9BoWl5WEQYMG4eTJk/jyyy9x4MABrFixAidOnAAhBPfddx82bNjgalUAgNWrV6NPnz74+eefERQUhNtuu41bqnYFQgji4uK4ZSkxwsLCuL+lUilMJhMIIWAYxq22itUjRk5ODh544AE89NBD+PTTT7Ft2zYAwJw5czB+/Hjs378fL730ErZt28Ytv7P4yvOdNm0aioqKcPbsWUyaNAkWiwUffPABrr/+egQF2YuLt56lJ/CVZ8rS02TWEQzDgBCCtLQ0HD582O58eXm54LPBYMCcOXNw6NAhjBo1Co2NjYiOjnZLSWjvN3X0PLz5bD0FlWNhPWL4sxyPGzcOv/76Kz755BNMmzYNmZmZWLduHQAgOzvbrrx1UcI9OiOzLtskVFRUgGEYzJ49G1u2bAEhBBcvXsTNN9+MwsJCXLx4EQBgsVhw/Phx7rpvvvmGM157/fXXMXXqVDAMg7q6OiQlJSEoKAinTp3i9r5dZdiwYYiIiEBhYSF37OzZs6J7Vnz+9Kc/QafT4ZtvvgFg1cbr6+u587169UJDQ4NbbWEZO3YsLBYLVqxYgenTp3Ma8JkzZxAfH4/s7Gzk5+fj2LFjdtf6yvPNzMzE5s2budnJlClTsH79elGNtlevXrj66qs5g5rvv/9eoOl35ll6Al95piw9TWZZ3njjDQDWQfPrr7/G9ddfj/Hjx+PMmTP48ssvuXInTpyAwWBAr169oNfruYGqpaUFRqMR/fr1A4AOrS6195s6YsqUKfjPf/4DvV4Pi8WC3bt3c+e6W35ZqBy3jz/LcUhICMaMGYNnnnkGmZmZSEtLw8mTJ3H48GFMmTLFrvyUKVOwb98+zsjzX//6F3fOtk2ewOWVhNLSUqxcuRKEEFgsFmRlZSEtLQ0AsHHjRvz1r3+F2WyG0WjErFmzuKWrSZMmYd26dTh58iSio6M5wVqzZg2ysrLw9ttvIzk5GVOnTnWv4UFB2LNnD5YsWYItW7bAbDZDoVC0awEaGhqKd955BwsWLEB4eDimTJmCPn36IDo6GgCwaNEi5OTkICIiArt27XKrTYBVo12xYgWKioq4Y//5z3/w9ttvIyQkBIQQ7Nixw+46X3m+06ZNw4ULFzilYPr06diyZYvDZbrCwkLk5ORg69atGDlypGDp86GHHsLSpUuxefNmbNy40aX7exJfeaYsPU1m+e277rrroNFosH37dm6Q3LNnD5YvX44lS5bAaDSif//++OijjyCXyzFv3jykpqZCJpPh+PHj2LBhA6699lr0799fYCToKhMnTnT6mzpi9uzZ+PbbbzFixAgkJiZi7NixqKurAwCkpaVh2LBhuPrqqzFo0CB88sknbrfLE1A5dg1/luPp06fjq6++wnXXXQeGYTBq1CiUlZWJbsekpaVh9erVGD9+PJRKJWbNmsWdE2tTp3HZeqED8A2LfInGxkbu7y+//JL069ePmM3mbmxRx/DV5+vP+Ooz9VWZhQNjLH+CfbZms5nk5OSQJ554optb1HmoHLtHT5Bjb+HySkJP4oMPPsDWrVthsVgQGhqKd999FxIJDRlB8V2ozHqP7OxslJeXo7m5GSNHjsSKFSu6u0k9FirH/gdDSAesICgUCoVCofR4qApHoVAoFApFFKokUCgUCoVCEYUqCRQKhUKhUERx23DRYrGgsrISUVFRbgfGoFBYCCHQarVITEzsMsMlKrsUT0Bll+KvdER23VYSKisrOf9RCqWzXLx4UZDQxJtQ2aV4Eiq7FH/FHdl1W0mIioribtKrVy93L6dQAFjzPvTr14+Tp66Ayi7FE1DZpfgrHZFdt5UEdqmrV69eVFgpnaYrl06p7FI8CZVdir/ijuxSw0UKhRIwaA1aqHVq0XNqnRpag7aLW0TxFp35rT0pJ/4uc1RJEEFvMCF55V4kr9wLvcG7Gd4oFErXoDVoseDAAuR8lmM3aKt1auR8loMFBxb4/KBNaZ/O/NaelJOeIHNUSaBQKAGBzqhDbXMtKpoqBIM2O1hXNFWgtrkWOqOum1tK6Syd+a09KSc9QeaoksBDbzBd+WfmHTNzxykUiv+ilClRcFMBkiKTuEH7RNUJbrBOikxCwU0FUMqU3d1USifpzG/tSTnpCTLndu6GxsZGREdHo6GhoccZ0CSv3Ov0fPmzs5yep7hOd8hRT5ZdiuvwZ3Es7gzWVHb9h8781p2VE2/V1Rk6Ikd0JYFCoQQMqiYVNHoNNk3YJDi+acImaPQaqJpU3dQyijdQypSiv7WrqwAdvdabdXU1AZkq2hEnN9wIwLrFkPHMAQDA8TWZiAiRdmezKBSKB1A1qXDLx7eg1dyK2LBYwbmlh5aipqUGodJQfPTXj5AQmdBNraRoDVrojDrRF6hap4YsWIaokPb9/LUGLcobyrHqyCrB8VVHViF/Yj6So5Md1qM1aHG+4bzotXkT8zAweqBLbeC3W6wuX99qAOhKgoCIkKAr/6S8Y1LuOIVC8V+qm6vRam6FmZhR1VyF+PB47J6xG/Hh8ahqroKZmNFqbkV1c3V3NzVg8ZQ3gNagxf2f34+soixu73/3jN2cbUBWURbu//x+h94N931+H7KLskWvzS7Kxn2f3+eyRwJ/q8G2LrHv6WtQJYFCofRY+D7qigiFYAWhuqUapZpS1LTUcMdiw2KhiFB0eTspVjzlDVDeUI7TdadhJmZIGSnyJuYhPT4deRPzIGWkMBMzTtedRnlDuei1Z+rOOL32TN0Z0WttsVUQCm4qQHp8up0xoy8rClRJECEiJAjlz85C+bOz6AoCheKn2M5KZcEyKCOViA+Ph4SRwEIsyD+ez70M4sPjoYxUQhYs6+6mByye8gZIjk7GkN5DuJd67uFcnKg6gdzDudzvPaT3ECRHJ4teO7T3UKfXDu09VPRaW2TBMsjD5Xbt5n9Pebjcp2WOejdQugVqIU7xNmKzOFmwDOUN5XjkwCOoN9RzZZ8c+yQmJk10ab+byq738YQ3AGtXkHs4166e9uwKWHuGFYdX2F3bnj2DWF2esLHwBNS7gUKhUK4gNistqy/DY18+JlAQAGDjdxtRpa/qssGa4hxPeANEhUQhTZEmWk+aIs3pbx0VEoVURarotamKVLfkJCokymG7lTKlz8scVRIoFEqPxVZRyCrKgqZFAwCQMlI8OfZJblk5uygbJZqSbm4xBXDsDeDu3n1n6vFUG/wdqiRQKJQejdisVMJIUDijEHOHzUXhjEJOUcjal4VSTaldHf6QiKen0BlvAL6hqm09z17/LPpE9BGtx/b3LasvQ9a+Ns+InZk7oYxQoqKpAnfvvRv7zu0TvbZUU+q1WBuqJpWobHr7vgGrJNAkThRKYCA2I4wNjUV8RDwAIE2Rhh2ZOwAABAQWYrG73h8S8fQEOuMNwDdULdGUCOpZO24tnvr2KdS21NopCra/b1l9GebumQu1Xg1lhBIvTXsJL//yMhiGgTxUDk2zBrlHclF0rkhw7bHKY8gqysItH9/i8Rc2G+MjqyjLbrWrRFPitfsCAawkUCiUno/tS2fb5G1QhCmgadEIXjbJ0cmIj4gHAcHKIyv9MhFPT6Az3gB898nlh5cjMiSSM1J86tunYLAYYLQYYbFYkCBLgDxcDp1R5/T3ZRiGq1elUwlsWXKP5GLevnmoaKqAWqfGw/sf9lqsDX6MD/62WImmBNlF2V6N8RFwSgJN4kSh+Df8JWVb+Eu/YrPSaQOm4Z2/vGM3K1XKlHh75tt+nYinJxAVEoUdmTtEnzWrKOzI3CFq7MdXJCqbKtFoaMSyjGXIPZwLlU6FBFkClBFKaFo0IITg7yP+jkcPPmr3+6bEpOC9v7yHBFkCVDoVcg/nYlnGMkgZKSzEAgkjAQMGBARV+ir0Du2Nan01LLBAykhROKMQqYpUjz6XVEWqYFssuygb7596n1MQvHVfIABdIGkSJ9+AupFROgK7pFzbXGv3ImGVAnm4nNs+cLUs+9JxxfWOyq5v4+w3BOCya6VYPexLWgz2RZ2mSPPk1xHAXznoyH2pCySFQunRuBORryOzUn9OxEOx4uw3dOf3FSu7esxqh/ddPWa1VxUEwGo/Y9sGb9834FYS2C0FR0mcaITFroHOxigdxXYbYdOETVh1ZJVHtgXoSoL/4+g33D51O5pNzS4FSFLr1GgyNGHhlwt9ZiVBa9DiuPo4lhxaYreSsHXyVmQoM7wSCKxHrSS44rFAkzhRKP6NWOwDTysI/piIh+L8N5z76Vzcs+8eVDRVIDEyESkxKZAyUruET2qdGln7snDHp3cIDF5ZBYG1SWDpHdobEki8GmtDa9Aia18WFhUv4mwQ+DE+FhUvQta+LK943/QoJYFCofQ8xAwVXV02tvV/d2T0yL4Y/DkRT6DjzH0yPiLe6tkACySQYOXolWg1tXIzcjbh04/qH5G1LwtqvRoGiwEJsgTkTczDluNbOAXBQiwgIGDAID4iHnWtdYiLiBMoCo7iGXSUH9U/oqyhjPu8dfJWzB02F1snb+WOlTWU4Uf1jx69L9BDlISOeCzQJE4Uiu/jKHWwWqfG8q+WC8ou/2q5XRm+/7uzNMRNhibUttQiRBKCl6a95JeJeAIdZ+6TOzN3IlgSDACwwIL8H/I5jwWWpKgkbPp+E9R6NUIkIUiQJaBwRiEGRg/k6t06aSu3ivDq9Fc5jxilTImd03dCykgRKg1FXHicR7/bMPkwhEvDuc/5P+TjRNUJ5P+Qzx0Ll4ZjmHyYR+8L9BCbBOqx4H/QfV3/oLuT06h1aswvmo9KXaXAQp2d7QHgZncAoIxQYvfM3QBgN6sUO6aUKQUzUPbFILYiwX5XKru+izN5Lasvg0avwfqj653aGSRFJuGlaS9Zs4ZeqYdfb0lVCZpNzRiTOAaAUDZKNaWIC49DQmSCx7+bqkmFU7WnkPdDnp1NRe7oXAyTD2v3vh2RI6okULoFOtD6Pu64G3pLUdAatLj/8/txuu40zMSMBFkCTBYTNM1t+RcG9hoIrVGLy/rLAABFuAJBkiCodCq7WaUnjB6p7Po3J6pOIKsoi/v85Ngn8fSxp7nPu2fsRnp8eje0zDVs2+9OewPWcPHkhhtxcsONOL4mkzt2fE0md5xCobiPO+6G3myD1qDljLVUOpVAQTATM1rMLXh+8vNIkFlnUZpmjaiCAHjP6JHi+2gNWpRoSuxCdG/8bqPg86ojq1BWXybYkuLbspTVl6Gsvs0+wDaAl6pJ5VKwL1faa1tPdySd6hFKgrc9FmieB0ogIpZquTNRCF2NlMgvy2+DreuZmZi5NqQp0pA/MV9w3h3/dxoLoWejNWhx3+f3IbsoW9RjAQAG9BqARFmi1RNiz1xkF2VzcsnashyrPIa5e+Zi7p65OFt3VmD3crbuLOZ/Nh+3fHwL5hfNF33Bu5oDRMx+hq+cSxkpUmJSkBiZ6HWj2h6hJFAoFO/gqZm3M6PB9gwMlTIl8ibmCYzMAOtKQt7EPM6uwNUZFk0BHHiUN5TjTN0ZbkVqxegVnMcCS4W2AquuXQVlhBIGiwEqnQrZRdk433CeW1F7eP/DMFgMMFgMePjAw5xHTJWuCo8cfASVTZVoNbeiUlfZqdU321W8Uk2pQEEwEzNaTa3YPHGz171vepSS4GmPBZrngULxzMzbna0L27IlmhLkHs4VXUnIPZxrl/HPWXwDGgshMEmOTsbQ3kO5F+yzPzyL0KBQTvGUMlIM7T0Uo5SjsHvmbigjlAiRhNjnbrjiQhkbFosqfRXUejUU4QowDMNtcRXOKOz06putcr7sq2UICwrj2s9fQfO2902PMFz0FtQg0ntQ4y//wVkUQlmwzKk1OQCkxKTY1ZMgS8C6cevw9LGnRQdPflkJJLDAYlc/O2DaDpy2HgvueDe4MohT2fVPtAYtyhvKvRZx0ZFMiZ13FVfrcdXTKGANFykUindwNvOeXzQf939+v+gMvKy+TLB3C7TNjtjseg8feNjhi5ktq4xQChQEKSPFtsnbBDYKFmJN/dteauHOpCGm+D9RIVFIVaSKroqlKlLtcngM7j3YrdwN/NU1T9m9uFqPUqb0mocRXUlwAs3z4D3obMz3cTTDtjWgEpvF8+MY8GMPqHVq3L33bs5DAbB34eLPij489SHWHlvLnVs7di1uH3a7IBueBBK8MOUFTO4/WfQ78GdYnoj7QGXXf3Fnhu9uFsjuXElwFbqS4GFongdKIOPKzHtI7yECC2t2/1WtV3OR6VQ6FXcua1+WQEEAhEaDfCPGsvoy7CzdKSj7zHfP4OAfBzkbBSkjxVC5dS9ZDNsZVlRIlMPB1ZuzMYoQvqeLrdeLrUuhp/IR2Cq92yZvQ3x4vKg9SvGFYoGRriB3wxWbBBZFuAIJsgSBDY0n7F5s27szcyeUEUrRemzdMm3r6cwzDJiVhOqmFmQ8cxAAcHzNNMRFhrl8rd5gwvCnPgdgjclAFYTOQ2dj/oErM2+dUWc321GEKVDbWutw1sXC2hskRSYhb2Iecg/ncjYLhBCo9WokyhLxUOpDePq7p+0i4+VNzMPA6IFd+nKnsts5+EG6tk/djrVH13IBuwBwQbo2jN+ARw8+6pGAXbYv3GcnPIuH9j+EVnOr1QixuYpThn+v+R0LixcCsCqOz016jpNLvn1MfEQ8JJBArVdDGaHkjBddtZFxthJgW/6laS/hqW+fgkav4foFW4/OqMPcPXMBAO/95T0M7j3Yrh72GZIWQlcSvAHN80DpyTiLX3C+4Tz+aPyD+6xqUnHJazR6DZoMTaL7ps9PeR47pu+wc1tkkUCC2NBYWGDhMvGxPux8BSEpMglvzngTc4bNwXOTnhPUsSxjGdIUaXT272fwvVceOfgIqnRVVvfafVmcDGj0GizYv8BjAbtsV8UkjAStZmuCp5qWGsSHx0MeLkd5YzkWH1rMXbf62tWC3A07p+9EiCQEIZIQ7Mzcid0zrasE8bJ4vDLtFSRGJiJUGopEWWKn7F5s2ysLlqG2uRYqnQoMw0AZoYQ8XI4mQxMW7F/AuWU+cvARjwc96/ErCdVNLQCAWp0RN2w9DAD4YslEyGXWZB/urChQPAedjfkGzkIv/1L1C7KKskBA8NoNr2FA1ADc8vEtaDW34qmxT2HDsQ0IlYbi1emvYknxEmha2rYREmWJiA6NRpW+CjUtNXb3jQ2LRXxEPBpaG1CpqxRc9/K0lwWzS0d7vImRiXjzpje7PAgSld3OY+vpwg+1HR8eDwkjEcyWPfEb266K8e1apIwUS0ctxXM/Psd93jZ5G2fnwr9WzGuHtWVR69QghFhf5J3Md2LbXmfeQfyVDGfhxgM2d4MzqBujb0IHWt/AmXHivL3zUNVcBcBqsLV27FqsO7pO4G0gYSSIDIpEo7ERAMCAQVxYHDQtGkHiJTESZAlYOXolHjv0GHeMNWLkD5C2bVyWsQz5x/NR2VTp0ZeIq1DZ9Qxiih+frvht+YoCi5SRonBGIdIUaV67b0dxZsgIoF0jR2q4SKFQ3MJZ6OWq5irEh8dze6zrjq5DbHis4HpCCKcgANbZ1Ws3vgZFmMKpggAAJrMJz/7wrOBY7pFcqHVqzsBQTImZNmAa3rzpTRoEyc8R26bi0xWhstMUaXZujavHrPZJBQFw7hLprXDjPV5JOL5mGo6vmYYvlkzkjn2xZCJ3nOI+zvawvWllS/EOzkIvvz3rbRTOKOSizdl6JhAIFyJbTC3QG/WQSNofWupa6jhDL8A6g6tsEoazpbENei5i4bH5iIXKLtWUQtWkcql+23GK/5kdi0o0JXYJnjZ+txElmhJXv0ancCefCXvMUUhxb4Ub92sl4WKtjku8dLFW3CgjLjIMcZFhnA0CAMhlwdxxMWhCJ8c4i8EvFkCHxZ3kJpSux9ksRGy2JYaUkWJZxjKsOLyCS9sMWLckxDDBBAYMZwnOD2fLJsiJConCjswdosvOrKLgzVTVFO9gu7+uCFfYlbFdJSrRlCCrKAu3fHxLu4qC7TjF/8y6KGbvyxZsNfSN7MutmmUXZXtdUXAnnwn/mJhrJd/o09Phxv1aSaB0Pc5i8HvbypbiPcRmIcu/Wg61Ti062xLDTMxYfGgxZ0gVLg2HlJEiLixOUI6NnwBYVyL4cejZRE71rfVgzaVobIOeha2CQAiBplkDZYRSEH8AaFMUDl04xL3QW82tqG6udnoP23GKn6SJfZmebTgrsEVgwAjiIWQXZXOePN7AnXwmYttu6fHpXFRStV4NlU7FRR5lz3lCUfBLJeFirQ4Xa3WobGjhjlU2tHDHxYiLDOPcGJ2tINCETs5xtofN+guzYXc7m1qY0jXwByBlhBLx4fHW43o17txzp51hlytsnrQZr93wmsAHnZ3d2G5RLMtYxtkfsEGSYsJiwDCMg9op/gx/C+mVaa8gXhZvlY+Zu/Hvv/ybkz8WAoLFhxZzXgeFMwqRqkh1eg/bcYqfpIkNiBQiDeHKs2PT5P6Tue21UGko4sLjnNylc7iTit3ZttuO6Ts4t8xXpr3i8S05v/Ru8JbHAvWEcJ3usLLtLL4gu76Go0RI2UXZUOlc2/sVw9Yli/3tHVmTPzfpOWw5vsUvlEkqu52H770i5upX3liOBfsXdNrrwJXQymLyVqopRVx4HBIiEzrzNTvcRrE2OQtsZuuWaVs/63ZJvRsoXUZ3WNlSPI/YDEUpU6JwRqHdjM52KRgAQiQhdjYH8jA51Ho1apprBImX+CsFUkaKAb0GQAKJYJvC1xUEimfgbyHZbicpZUqMTRjrEa8DsbHItl6xsSlVkdolCgLgehInZ9tuKTEpogoCW39ntuT8ciWB3VKobGjBHTuPAQDee3gsEqOt2wj95B1bVqEJnVyHriT0HBzNUE5UnUBWURb3edvkbXj62NOC4Ei9gnsJXCBjw2Kxfep2Lh1vbGgs/n3zvwEI0zTnjs7FMPkwnKw5KYhwt23yNkwb4NteR1R2vY+n4hd0dCWhK/F0EidnBMxKQj+5DP3kMk4pAIDE6DDueEehCZ1co7usbCneQWyGImbImH88H4oIBRezHoBAQYiPiEffqL5Ijk7G2vHWzI21rbW4rLssWLHIm5iHvB/y8FjxY8j/Id/uHlRGAhvbSIjLM5ZzK07ZRdk4dOEQV5bvcq3WqaFqUnHyU/xHMe7eezc3Fq0cvbLNJoGRIHd0LpcwKWtflsB125Ou3M6SWZVoSjD/s/mcEefOzJ0+N176pZLA0swzMOT/Ddi7MVK3Rs/QnVa2lK7BkRJY2VSJRkMjtk7eiifGPiG4pndob2ydvBU7MndAZ9ThqW+eAmA1Olv21TLojDrsyNwhSOJ0uu40KnWVXJa9xMhEuzgJlMCiVFMqUBB2ZO7A5398jriIOE5RWFi8EMUXinG27izncn2s8hjmfzYft3x8C+YXzceHpz7EokOLoGnWQBGuwMJrFuLZH57ljBYtxIK8H/JgsBigCFNArVdj7p65KKsvE9Rrqyi468rNd3M8W3dW4PLIftfKpkr0iegDQghe/uVlbJ+63afGS79WEpLkEaJ/dxaa0Mkx3WllS3Gds3VnBTMu/gzm0IVDgjgWtql5+QrC9qnbBb9fZVMllhxagn8c+4fgfnWtdVhyaAnK6suQ81kOVDoV4iPi0SeiD9R6a51l9WWcgmCbKc82iiIbJ4ESWMSFxyFUGsptLSRHJ6O2uRZV+irIw+Rcuae/XYeHDzzMuVw/vP9hVDZVotXcikpdJdYdW8eV1TRrkPdDHveZH1a8tqUWta21bWX1Gjxy8BGu3gX7F3TKldtZMqslh5ZwypDFYoFar0Ztcy0iQyJ9arz0S5sEZ7YDeoMJESFBgnNHVkwGwGBCfrGgLEDtDDpCd1nZdhZfkN2u4GzdWcz5ZA4ssODFKS8iQ5nBJXF6MPVBrD26FhJI8MHsDxAZEilIJQvAaRrfefvmoUpfxd0rWBIMo8Vo1wbW/z0mLAaNhkZUNlUKztW11MFoMdrtMbNLzaHSUHz014+6zHjMHajsehdVkwrVzdWcmyP/5RxrMoOAoDbIOm7HhsWirqWOyya6ZswaPPPdMzATMxgwAnfbXiG90Gho2x7724i/4dWSV7kX9TPXPYOXT7wsmonUUcIkV3CWzCouLA4MGGhaNHb1upMMylUCJsFTe66K7kDdGrsHOtB6Fr7idujCISwsXsidWzpyKd49/a7gRQ0AG8ZtwKu//BMVehWSIhJQMLMQALgsdgAwv2g+tyWQOzoXjxU/JkzwBIngM4siXAFNs4ZLyGRrnCiWoIk/mHZXhkdXoLLb9ahVJ5Cz9y5UBItP6myNEW0/O8ORISPQvgG2y+33gWRWQAAZLlIolDZsw7tO7j8ZL055kTv/3E/PodnYLLimV0gv/PP4FquCYDSi4NRPQOn/Q85nOVh2eBlkwTLIgmWIDo2GlJGioqkCG7/fiGBpW3hzKSPFoJhB6BPex65NbAS9vIl52HJ8i+DcluNbsHniZqdBZHxVQaB0D8qWRmzSOI6yKOYu6Yh7r7rXaVlvuHL7QjKrjuKXKwl0u8F9nG0ReGNZqz3obMxzOEr3/OHpD7H26Fqn1yYYTShUWfMs5CT0QUVwkOhMytFMTRmhhAUWwRYEC+sFodarkRSRgE1D7saqM+9YFZMrXg6sjQJLd7ujuUJPll1fGye4e9OVBI/gNysJHfU0YK8b/tTnACDqqhgXGWbnxhgbGYrYyBC7soGkILiTSITiH7DGiGLhXb/840vsLNlpd83MgTMFn00McC44CFkJ8VYFISxOEFRp7fi16BPRx27ANRMz4sPjQUBQpa8SDbxUpa+yhuoOjkLBqZ+Q/tFjKDj1E5JCorlQucszlguu8+UZVU/HV8cJtU6NnG9XoSI4CAkmExSmtndGbFgs5/UgZaRYO3atwM2RnyckOiRaUO/ikYu5slJGim2Tt3F9KLsoG1n7suw8fDriceAsmVV8eDznhukLngxi0O2GAMCdRCIU/8B2QLdVFB479BgqdZV21+07v0/wWRMUhIcT+kAdHAyl0YSCiVu5l/TZurP4+4G/o0Zfw6VzZpEyUpgtZmgNWvSJ6GMXdTGICUKwJBghkmDsOH8GSpPVuFFpMqKg7BSSIhIQFRIlsDoHPJPaltIxfHGcsEsGFZkITVAQlGHxiI+IR01LDSywcIoCa7QoYaxujgQEDBjEhsWiwdAgqHvbT9s4BcFMzNhyfAvyJ+ZzuWfYXDQF4zchXdeIgvGb3FYUnCWzSpAloKq5CgzD+LSi0KVKQkcTKDm6DgBObrhR1FXR1o0xkN0a3UkkQvEPxAZ0pUyJZRnLRMv/39D/E3y+/+r7ER8UKThmCY+BJkgKVZMKJZoSzhXMBJPoSkJNaw0igiI49y3+jOty82XIQ+V45aq/IcVoEFyrNBmQP/QeNLQ2WI0iIxKwe8RSJEUk+OxAGQj44jhhlwwqSmmVs7+8jZ2ZOzmX653TdyIxMhGh0lAkyhKxddJWbhXh1emv4l83/osrmzfBmmlUAgkXgpx1N0yOTsYr017hyu5IvAnKV6cAb94M5atTUNB3lluuic6SWbH3VUQosGP6Dp9xebSlS20SOppAiSZe8gxdGf6zPXryvm5XYWuLsCxjGZZ+tdTuhf74yMfx/un37fZDbV3CAOsKQZAkCEazkXMrc7a3axvvwNZLISkiAQWnfuJWEgBAHRSMnGEjrbYJIdEoKPsdSpPRejzlT6gwNPi04trTZdeXxgnAeTIovsu1WqfmPHOUMiVKqkrQbGrGmMQxdmVLNaUIDwpHZEgkJ7N8e4uy+jJAexkpb8wCCM97h5FC/fCXkMlTXLbNaC+ZFXvfrrD58BubBEr3QBMv9SxsZ35sOl0JhHux/z71b0SFRCEpMgmPj3ycO95oaIQiTIH48HgEMdbVNTMxo9Xcyi3hJkUlQcqIDxNSRoJgSTASZYl2gbW4YDAyBWQ3bgLY7QpGCtmNmyAPjUZSSG8UnP1NdCvCF2dUgYKvjRPOkkHxExspZUokRCZw59Pi0zgFwbZsqiIVg3sPFsgs/+WcEpOCFJNJqCAAADFD2ax160XeXjIrtq7OJmLyFl267n5yw40AHCdQ8vR1FCFi8fhXHVnlszM2SvuwWwz8OATPT34eA3oNQImmBK+VvsbNCLdM2gLFucN4w2RC/ZVgNEHmVqy87mls/H4jLusvC+q2wIIKbQXMxAIJIbAwbYpHvMmEqqAgxIf1xpZJW+zkh1UUuJnR0JlA7TlAPghRZQex48RB6BhAaRauUihNBhSkPgrZoCk+OWAGAnScuII8BWAkdisJkA9yqxpf9RhxlS5dSehoAiX2fDPPbqH5ip3C8Kc+R/LKvahuanHLayLQcjk4S8pE94D9F7VOjfzjwiRJW45vQWRIJG4behs3o4+LiEMyEwrZ50+iv8kMpdGIBKMJKmMjHjv0GC7rL9sZJ7LGYAAECgIASAiQEB4PRYQCydHJom0TzIyi+wIDJ1j/3vMYoixmOwUBAMBIoUwY5dODZk+GjhM8ovsCN78gWAXDzdusx13EVz1G3IFuNwQAzpIyBewA0ANgf9fKpkokRiYKXLhsvR52ZO5AlFaNKIsZO9RV2K2qQr5NcBozMSMhLBY7E2ciKVxhF0lRYTJhd6UaSUYT1MFBIIwEG8ZvcO2F3nAJOH8YuPid/RIuCzsIA9ayDZc68FQoHcXvxomKH4FvX7L+3x6s/LkrUyOzgcWlwPxPrf+PzHbrcl/0GHGXbjHzZz0NXKW6qQUA0GxsG1wqG5oB3r7rpfoWhAe36Tx8Twj+KgU/EFN7ZXsKrIUtANG9YzZ2P90D9h8cBVC6Ku4q7njOZznCJeIry6dRxAIdgFWKWEGdUjDYUvY/pP32M/JCQpDdVwn+XD+IAEqTGQWqKuQM/jMq9Go8evDR9pehfyoE9jxmVQ4YCaz9lmcvzUiAOW8A/a4Fyg4C265uK3vzC24PzJSO4VfjxH//BvzyTtvnEXcDt/5TvKyt/LkrU9F93Vo94MN/dmyf7EweiO7ALyIudjZXA18hCVRPCV/bF+vpFuLehl3GZJMv8X9XVoFgkzYJftefCqHetxQ5ylhUBAcjMbgXwmUKlDech5lYkGQ0Iq+qBrnx1vOANeZBrLEFl4OCrCGcVVUAI0XOsGsglyns78Gn4VLbS5+FYQDCALC0rR6MzHZQVmqdwXVwkPYGPVl2fW2cEKXiR+D1qfbHH/gSSBolPOYjMuUrHiMdkaOeN22miBIVEuWwc/uyFuuPdMVAGxUShR2ZO0TvY2c0yL//sBuQU3aNIKmTLFiG80fykXv+P6gIDkZ2Yh+YGQZJRiPWJt8ChfIayP77N+QkxKMiOBg5CfEoUFXZGxg2XAJqy6wrFoD1b121iIU4AW4vAGRxViMwdrCuLRO1JkftOZ9SEnoyfjFOXDgqfvziMXslwUdkivUYySrK4o75i2eZXygJx9dMAwDU6oy4YethAMB7D48BwOCOnccAAB8/eh3CgyW4YeuRK9eIez9QTwmKN+nwDL8DdGRAlwXLIJcpAIlU0L60Ybeg4NuXMT+hD+qlEsSYTChQVUF50/8BUUrAQqzbDAnxkJstkBEGUQmjAPb+/CVdbhuQXPnbdntBat1asB2kPWRNTunh9B8nfrzfWPtjPiJT/uwx4heGi3GRYYiLDINc1paBLkURiRRF295Y35gwJPWO4D478proqIeFu7Bx9W3/BqwCw1qz8v+m+D9eM1Rqz/CKf95JWXYFghucWOMvnQZKsxlvqi7jo4uVeFNVBaX5ysBaWwZkroPSAhSoqrDjcg2i/rLVeu78YWsdnIIAWBUCwvsbV2wR4NxC3APW5JSejdaghbp3X6sNAp8Rd0Pdu69gLNUatFAHSUVlSh0k7bJx1989RrplJYF1XQSsM3v+y7m6qQUZzxwEYF1BiIsM487VNhkEf4fzXvTNBr6JFbhskI7q9aaBIn82uX3qdqw9upabWQLgZpMbxm/Aowcf9djMktL9eMVQqT3DK0ezeAdGWtwKhK3xF+zjFuD1aW11Za6HMvEa6yyMb2Bou1JgBwHmiGwviDEyG0iZxsVUoAoChcVulW70A9Ythn5joe7dV7BKB0BYNqWUkyl1kNSjK3rOcGRgbDtG+PKKgl+sJLDIeZkc5ZEhiI0M5T7HRoYKXvztKQEezeVgM3PjzyYfOfgIqnRVqGiqQNa+LGQXZaOiqQIavQYL9i/wCxcYinvYRkLMKsrquILQcEk4SycWYM/itlUC2/P8WbxtWT4VP9opCOLw6jqwrm2Z1u6eTmC3FwZOcO2lz8ZUoApCz8CdVTAn6Iw61Oo01hfrvmyopVJAmQq1VGq3SmdXVq8BQKDWa9rKaiuhqy1rvw0dPQdh7gaHUUl9xWPEAV26kuDM/bCmqRXhIVLU6tpivLN/1zYZII8MEZyzdXmsaWoF3yXSlXoBCFYqOoTILE85MlugKbLpQdV667JSfHg8CCFcUhxf1iIpHcNjhkqODK8ufg/UxoobBtqWFTPScmT8xa4K2O7jsnX97yOgV4L4Pblr+CsLEmHsA3kKffkHEu6sgrXjnqg89QUKTv2EHGUcKvQq5Oy9C5s01ViliLOmOeePpT8VOi9rNKHgwi9Q/j4FSLsTKPm3eBuctc+FtnfUwNiX8KkET91Bp1we23GvEXN74RPICkJPdiMDPOjyJCZjYK64EV4ZnAjfBsAGR+5ejtzI7noPCJEBwRHAvzKdKAM292SkwP37AaMeqPwZOLC2rX3OBmE/pKfLrsdoz/3QHfdEXlm1VMp52rAkGU0omPUulAnpLpS1uvGKRvzktwFw3D5n53xYCaYJnroaZ+41EE+UwsdfXGAo7uFRQyVbYz62y/K3HxjecYb1JoBzw7+kUaLGXxh2k3WpP2mU9b5iQwR3T3bl7spqQdIo63YEqyCwZX95x/F2CaXn0s742O55B3UpzWZs0tQITm/SVEPZonWxbI1jBYHfBmftc6ftfo7PJHjibwuwbo5fLJkIuSxYsN3AnrN1eTyyYjIABhPyi12ut9O0414j5vbCZ9WRVcibmIeB0QMdLjepmlSobq5GqiLV7lypphRx4XFIiEzo3PegeAyvGCrxjfl0GuD/5QjP28YdAFwz/Lv1nwDP+MvOxxxwbJNIWPfGtv+s9xUZPO2upbEPAoL23A/dcU/klVVLpXbRQlcp4lAQFgUlr6xawkDHMCJlY9tfSWDb4Kx9PuBa2RX4TIKnfnKZnZujXBaMuMgwDFX2QlxkmMAGQR4RDLmszZAxPESKWJ5hoyv1dtoewYnLFv9lESwJhoT3qOPD46GMUKKiqQLZRdm47/P7RN1xVE0q3PLxLcgqykKJpkRwrkRTgqyiLNzy8S1QNak69z0oHsNrhkqsMV+/MW3uhCy2hoHuGP4ljQLG/V08Up3AOFEMEQNJdjB3Rg8dTCk2tOfS6o7L65Wy6qAQbvsg0WjCYIMBUkJQERyEnG9XWVfpovtCfePTyE7sg7l9lagIDkaSsS3viDUgWB+r4SMjta6gibXBWfsCyF3XL4Ip+TQiLlt8BSE+Ih7V+mpYYIEEEsSF9UZVcxXiw2K5LHtn6s6gvKHcbrWgurkareZWmIkZ2UXZKJxRiDRFGko0JcguyoaZmNFqbkV1czVdTfARvG6oxA5OexZbZ+S2SZHkKYBWbTVM7D9OfHWAHxnR0aDmbEXAkVFj7TmrcmLbvrQ7gJL3hO3tgYNpQONIptpzaXXD5dU2Wmh+xkqs+P5pmFuqIWWk1lW6j+cgb8RjWFbxCVRX0qErw+JRcMNzULZoURAWhZxvre7IOUNHoGDSViiV6cDUNW1tANr60shsIP4q4Wob+11TplltEPhtd6Vv+Rk+l+ApLjLM7hzrFRFu46rYbLAx5oJ93AVn9XoMmwQg/EQp26dux+qvV+N03WmYiRkS7WXEM0C9vhoWCQMpI8XQ3kNF0+2mKlJROKOQUwiyi7KxesxqbPxuI8zEDCkjReGMQtGtCEr34fXQtrYDqyBmgQ22iW9ctSYXXQq+kogppr+9USN/dUBs4OcPwj1k8KRcoT2Zai9BkosJlMSihRbED+cmZFJCENpUjeVH10IVHIQQSQjkYXLsnrm7bUUPECarYkOIs22w/S62Rrcd9YTwY3pkgidfSNLEj9+vNWhRfukHrDj4d1QEtykwSUYT8qe9jOS+o53OLPkrByysgpCmSPPq9/AW1ELcQ4h6P9jAJr5xN9nNT4X2KxaCAdHBuR4OlV0eXZxASSwvivrsF8g5tMjOg2H79XmI7DfG9RwqrvQlW/zM24EmePIh+LPJqJAopCIImzTVyEpsE9hNmmqkIrgt/r0D0hRpWD1mNZ4+9jR3bPWY1X6rIFA8iCuGgqc/B4w6B8mWnBgROlsKppERKUCXJ1ASW6VTVp3GJk2Nzdhag8F1FcCf/ipaj+iKnit9yRbOo4H4RCIpb+AXSoKYV4QjbwZfRR3WC6sUcYJjrEWujKcd22q4ap0a5Q3l2PjdRsG1G7/biP5R/ZEcncwJPP9a23r8IgUsxX3kKWg3LPLhPOs/RmJftj0jQmdLwS4uE1N6MD6QQEkdP1Tcg0ExBG5t7ol9l/YIAG8Hr3g36A0mJK/ci+SVezl7AkfnL9bquL+rm1pE62tLvtQ2uDnyZvBmToaOotaprcYywUF2Frnzv8nF/Z/fj5zPclCiKUHOZzlYcGABlxTq7k/vxoP7H+RsEPpGWgdlMzHjwf0P4u5P74Zap+aMJRccWICy+jJBPWzMczEfff51NNGUH8EmZlKXun6NXUwFKZC51jqD4od5diFELoUCoNut/NU6NXJ+2XrFg8F4xYPBaPVg+GVr52KSiHk+dMQTws/xvTeqv+CiFaut33z+yOUCi9xKXSUu69UwE4vA7qC8oRyPffkYNC0aAFYbhG2TtyHvhzxB/ZoWDe7YcwdCg0Kh0qlgJmYs2L/AGgLa1GKNTR6lFGQmZI1+bKMC6ow6uprgD4gkZnIZfkyFHh4ZkdJFuLv1VPGj0Pvm1GfAmS+AITdYz7N/D7vJaTV2MUmGzIfywg8o6D8aOWfetI53n95l9WAIVwjHa2feGLbeDLZGt46McHvoFpxHlQRnuRmE5dqOVTa0rR44yqnQthrBj9ri3JvBq7hhxcr3dHBkkdu3tQWXQoJhhnW1YFnGMqw4vAKaFg0YMJAwEs5I8U+xf7IL91vbWgu02uSE4Mcmv/kFz2cmpHQPLidmckJMfyBKCRTOto+MyMLGPkiZ1mMGO4oXcXXryVbBjYgD9NXWv4//q+348X8BSWOAB75wWJVgbO07C8r//g0gFih/fAMFV9+KHGM55C2XINs5pS2MeEc9FPjfLcC24Dzq3eDJ3Ax8D4X26u1Sb4YOWPOKWuSqTiBn710CbwcpITAzbYpQUmQS8ibmgQEjcHNsNyeE0YQC1eW2iGJX2semSO10PgEPQC3ERXBlderbl4AvnhA5wdoaMFf+dJCkCQDmf2ot++bN7bdp/qfW2AcUDiq7HcRRvhBn3PWe0xUFrUELXW0ZlDun2Mm6WiqFzGJBVHuvOD/zUOgMNHdDV9CBmN1RIVH2gXVaGrFJUy04trq6VvB504RNSFOk2cVBaDcnhKZaGHL0SvvErqP5I3yEnwqtA9SbN1v//6lQvFz/cQ4q4A2EmeutL/f7D0C4+gZrbgf5IBoZkdL1OMw86oSz+52ejgqJgrK5UVQZVprN7SsIQEDmY3AHj67TO8vNwId//r2Hx+KOnccAOM6p4Gq9XYKHrHnFvB02xskFn1cdWSU6y283J4Qizn4lQT5I9DpH96B0IbYhkJ0t9bOJmRxuORDgwPq2mZHIaQDikRtpZESKN3Go4Dph8PT2y3TEK4FPAHgodAaPriQ4y80g/Nd2PjG6zfbAUU6F9urtUjxgxVpWX4asr5dzec23qTXcVoMEEmy6fhOXNXB+0XyUatoGfP5WQ2xYLHqFtC0ZcTkhgoNwd0IflAQHc+3jbzV0OjMhxbO4O4MZMA52KwRi19aWwd41krTVOzLbqkzM/9T6/63/FH6mRosUTyKWeTQiTrwsYLVJaMd4EYALXgk2mVED0EOhM3SLdwPfLbLZxrBRbzBh+FOfA7CuINQ0tWJC/iEAwBeLfWRvtBNWrGX1ZZi7Zy4MFgOUEUrkZaxE7vfPwNxSDQkksMCCtd+uxSvTXsFT3z6FSl0lsoqyUDijEPER8QIFoabFmgI1JiQG4cHhUOlUSJAlQB4qhwa1uCcpAW9N3Ib4+Ks8n5mQ4jncWZ1iVx2cxUVwZ2Zka2jVAw2vKD6EWObRU59ZtxXYVQP2b1cUBJb2QoEDAe2h0Bm8oiQ4y83AnmdJkkcIyorFVWAJD5H6RMhlAB4ZTBmGQUTMAMijEmGSBMECC6r0VQCAuIg4bJm0BVlFWTATM5YfXo5XrnoEcpMB5rBYtPAG/kZjIzakP4b8kpcRJgnB5dbLAKyvkeawSFEPCwACRaFDmQkpnsFR0iYx+XIYFU4CwGJ/rav1UihdRZQSUKZa/wesygCrEDRcAkIirgQJg727ZLvwlGcxBdjROT5UURbQpSsJzlwk9QYTIkKCBOfOXNaiQd/mFsl3l+wn988XWkpMCt77y3t45OAjUOlUWPjlQjw59kmsO7oOVboqJMgS8Mq0V5ASY+0khTMKsfzwclQ2VeLRr3PxZHUt1sbJURccjLiwONS21sJCLFjy3To8WluP7fIYWBhr4qgdmTswJmEMAHg3MyGl87g6gxGNsMgADxwAjHo6M6L4Ns7cx23P9R0NVHzXdq1tsjJX66V0ii5N8OQtF0l/RMyN0ZE7oqMEJgWTX0SVVIrsrx4TuE5KCUHhpBeQNnCa979IB6FuZB2k4RKw9SoIQyszwP0HrfkZelCKWl+Fym4HceY+DriWXIlNVuZqvbQvCKAukH6EO+6IbAITQVlNDZSaM0hDsJ3r5OrqWqQhBJQeiJgxIiHA69Pad5+kULoTZwa6riZXunjMvXopnaZLtxucuTLytxvYcx//fTwa9EZkF/wAwOouyfeG6Gps0z/zl+/L6ssAWLcTxJI02S7nu+qOWHSuCJYQ4CWRBCb5vRTQmRrtXCc3xsnxJxgw0El7nSWDcva9bT+78l0pHsShu9cVxYFGSqT4Ku0Z6LrixthvrPv1UjqFx1YS+EmbqptaRBM8OXNljIsMQ0RIEJp55eWyECh5SkFYkAQT8g9hQv4hpwaO3oCfJOls3VlBwqSzdWcxd89czN0zF8cqj9klabJNoMTfaugT0QfMFfccW3fEfef2YcWRFVj5v52oCA5GotGElFY2OVQw7vnxH3jw21UwMwykhCDGZAKuuFJmH1mKrH1ZyPksB2X1ZYL28tt0tu6s0wRPtsmh+J/FElLRZFFO8ETyJDs3LZEuTMzA/z6iSZoovoUzF0Oxc0ljhNePuFvceJG6LnqVwErw5Czsra0VrU1ZnVHHJUl65OAjIGYz1C1VyPp0HiwSwGAxAAAe3v8wLLAAphaUX/oBK37aLEigpDPqBO6ID6U+hKeOPtXWjCuKwoOpD2Lt0bXccQYMVl71APLPvgezpRkAYLmiOTNgIA+Lhaa1BorQWNQa6mEmZpQ1WFc3FuxfAIZhoNKpkF2UzeV3MFlMnAEl2z7bFQD+9875LAf5E/O5z/yEVOcbziP3cC5NFuUITxpW8Y0RgyOAf2Xaz8C+WA3sX0MNuCjewcUEd3aIJVBi60qZZrUj4BvZVvwoLOusXmqg6xU6rSSIeSzwEzXxj7Ouj2Iukmya6GZj22BXpzMgjJfbIJznOilWr1OcDdK2SUeSxgCXfhCUVY7MFsQVSDCZoACgbrG6LMaGxaKupQ4WWCAlBMvKT2KF9u/WgEk8g0StQWvnjhgTFoNFxYu427eYW9oUBEKstuwMkP+/17Gspg5L+8QJDBXloXJoWmu4+1Tpq5BdlI0QSQiiQ6Oh1quhjFAiPjyeUwgU4QpOcXCWv8E2nsKKwyuwLGMZln61lEtfvSxjGacg0GRRIrgTUdFV+G5afDdHPnTrgeINOqPw2l7bXubRpFEuuj6Cui56iU57N7jjseDMI6Ezng/tejo4s37VqttPOsKzlBVLzMTHLkmT0YSCWe9CmZDOHRNL+FR8oVigKAAACEHe5Wokmc3IjY8VeDeIJYPiv5xLNaWIC48DwzDOk0G5+FIX88aQMlJuJcGduoAAsxA/f1g8mZInkyc1XLJuMXyx2rv3oQSW7NrSGU8CsWttoV4JXoV6NzjCmfWrK0lHeJayYomZ+NgladJUQ9ki3J8XS/g0pf8U3HvVvYJj99Y3YmZzM9IMBjvvBrFkUPw6UxWpSIhMaD8ZlIsJnsTqWT1G+EKiyaIcIJZMydOGVdF9gatu8f59KIFNZzwJXPFgoF4JPkenlYSTG27EyQ034viaTO7YF0smcn8fX5PJlXHG8TXTcHzNNMG1n/x9PL5Y3Pa5I/UCcD5Iu5J0hDfQiiVm4mOXpEkRh7NBUoe5EVhjwOILxdj1v12Cc7tieqE4PAxqqRSrbLwbxJJBid2j3WRQItexbWqvno3fbXSpDQENu9+auR5t3U3iHcMqasBF8TadUXhp5lG/pNNKgpjHQngwv1riUiImNrETPwtkYu9wJMnDuc/8c24leHI2eIolHUkaI1pWrVMj59tVqAgOstokmNo8LGLDYiGBhPM02KauQpLRhIrgINxxaCGy9mWJvoxzPsvBXZ/eJdhq4FYUGAaL+ihwZ6ISFcHBdsmgpIwU2yZvc5ioib9FwNoksAQxQZAyUrvr2vPGSIpMwrbJ27ithvbaENDw0z/vfwqcm6KT3EydxjZpEzVapHiSziii7SZiokqtLxI43g3OrF9v/Scw/K/CxCIVPwIXjgH9rVa1/BdlgiwBxGyGpqUKyrB4WGBG1ZVkS1ZFwYIt/QYjf8RjWPrb61DpVFDr1cj6dB52/+VtLr6AmK3Ai1NexJT+UzAyfqRVcWAY1ARJERsWi7yJT3LJoNiX9JbjW5A/MR8rDq8QJGoCIFAQGIZBld4a9tlkNkHTogEAgaLArwcQ98Zgy7AKAtuGvIl5nPEiTRYFe2NFfgAkbxsUUgMuiifgezBo1W3eX53xJGC9G3hjq10ipvOH27wmnHlRdNTDguIWHlMSIkKCBMGS2mA4DwhXZv1xkWF2hoj8z50Kx+xo8ORb3B5/Q9TiVnb1rZxXwvap27H26FoEBYWgoO8sNB1cjzsS+wAAXpb9Gesbf4G8RYPkDxag8KpbkG26iBqJBOqWKuR8cjs2TXsJq46sQkVTBeKNJmiCpCAAXhxwK6b0nwIAmFJ9EXmXq5Ebb91m2KScioF9r4U8KhEICuNeyvJwOZKjk0UTNbHtfWnaS3jq26cgZaScApG1Lwu1LbUwWAyQMlKEBYVh2VfLUKmrdOqNwU8WxW/DwOiBNFkUn/b2X9m9Vzq4UXwR/phoC5tDoSOy68gzIrqve54PNFdDl+HR3A3teSj4ZL4FNyxuteG9hBEMa8ug3DkFIBaUBVkVoBSTCWqpFDKLBVFXHq1aKoWOYfCoUmGTf8GEAtVlNAGoCA7C5FaTXRzzovAw9DZbMNZotmtDe9EOnUWIVOvUaDI0YeGXC9vNH+GNiIs93kK8PbmiVtx+S8DLLiCeQ6Ej9bqTu8FZWdqfXIJ6N3QENyxu+V4JUSFRUDY3ctemmExIuWKjoDSbOQWB/ZxiMonkX6iG0mzGYLMZk1taReOYz2huwViDQbQNSplS8DK2/WzXXt6LXylTYnDvwS7lj7C91p02BCy2+69grImYALr3SvFtXBkTxXIodKRed3I3OCtLvSK8hkdtEpzlZvBZHMbC5+HI4taVa68g5qGwShGHAtVlKM1m+/t0QSxyV/NHUDqI7d4tQCPCUXwfV8Y1sRwKHanXndwNXTw+Uqx4dCXBWW4Gl7wQuhitQQt1kFTU4lYdFAyVRAJ1ULDorE+tU0Mb3suhta6WYazXjrgbZcGhyEqIt3oohERj3dh1iAuLQ0VwELIS+li3Kq7MLksNtVBJJV53ZbP1WNiZuRPKCKVDLwm+SySbp8FRvTRvA4/ovtZARqw9DPs3heKr2K2C2eAoh4K79baXu8GR5wN19e1SfO/N3UWwiYpqm2utM+eUtpjh6iAp5pvOoL6lHjGhMXhz2A3gz6vZF6w8XI4dmTsQZWPpq52wBAsOL0OtuQVrx8zH35u+g8FihDIsHsvHPoHFhxaDgKB3SG+oUYe5/fvj/SkvQxcWieyiLIRKQ/HRXz9Cgm0ccw9hqyCwho0MwwgUBb6XBPtdAQifG2/Fwe650G0H51DrbIqvYrsKplW7lkPB3Xr5ci92ju/50F5ZilfwipIglpvB17BNXFRwUwGUAydwL7pK/WVIwaCy+bLApc/WdVFn1CHKxmtCV/8HaltqUGFsxJpv1nDObxYJsP7oepArR+oMddYTjASnjPVYXfwIzMSMVnMLqqt/Q0LyVOfC38GXDN9DgVUEaptrodKpkCBLgDJCCXm43M6wUWfUcWVtXR1FnwtVEhxDrbMpvg5/XGNjyni63vbOuVOW4hUC1nCRTVzEDwJ0oupE2wzbaEThJRWSjEbx847yFPz3b1C+dTsKyn5DktGIy/rLkIfJERsWiyp9FWpbaxETEiO45L6r78Pqr1dbYw8QgsKKSqS+Ocf6InEEP1DPtqudl7UhKiQKOzJ3cO3nPwuVTgWGYfD3EX/nFAT+d233udEET+3jKOETTe1MoVB8DI+6QPojYkGNkoxGFKiqoDSboZZKkXPFnoA77+hFWPGjIFmU2LXOkBKCwsrLSDNY0047dOvpTJIVJ4g+Cwff1Z2yYvR4NzJndEXCJ4rXCGjZpfg11AWyA4glLtqkqeE8DpRms73roqNERjbJosSu5WOb0Gl1dW2bggA4duvxkguQ6LNw8F3dKUuxoSsSPlEoFIoHCHglQdQNUBELtVQKlUSC4rAwe9fFI6tQfKEYqiaVsDKbZFFibo98bBM6bYyTozg8DFq+P70z10s+HnjJOHKJdDVxFE3w5CLUOptCofgJAa0k2Fr5756x27rXHhyMrIQ+uLlfIhZdiZIoON9UgUXFizD7o9lCRYGXLIq/1RDMBEPCe6lLIXQt6hPRx5oH4UpCpyxlPLSSIMcvDi+8ZBw+i3YSR7VXluIAmoiJQqH4AT1PSWi4ZN3zbccIzPZFVzB+E9J1jSgYvwlJkUlQBwehVSLhouStGHQr0s9+jRWDbuXqaDG34FTtKeE9b/0n1Pf8P+Sk/BkVwcGID4+HBRZYiAVSRopeIb1ghlnQlurmaiy+ZrH1A8OgLCwUP97xmvMXhwdfMnbP4qYCpMen2xkoqnVqt8pS2oHGTaBQKD5Oz4qT4IZbmcANsO8sKF+15mBQMhIU3Pg05l/agxp9DVotrQCAJb+8iNXVtdgYJ+cUh8HRgzHq8hmg4Fb7ZFCnk4HmWrx0JZnT6brTMBMzQiQhdm1JikrCu6fe5T6HS8MxrO84u3J2eMgFyNYlkh9y2VniKFfKUigUCsV/6TneDR2w+LdN0sS/Tv3wlyCRfXDqzKdY/MsLMLN2ArB6IWwb8RhG9ZuEqJfHiN7TNhlUeUO5IA0zAC7VMktSZBJyR+dimHwYEiITOv9M3MA2iRMfZ4mj2ivrCGohTvFXqOxS/JXA9m7ogMW/bZIm/nXKZi0SIhMwubkVq6trBadXV9dicosBUVq1w3vaJldKVaTaeQOsHrNa8HnThE2Y3H9ylysIgH0SJz7OEke1V5ZCoVAo/kvPURI6avHfznUl0QrrFgOPjXFylPSKc+ueYt4AG7/bKPhMvQMoFAqF4kv0HCWhoxb/Tq4r0ZQg+8dNMDMMpITgSU0NpITAzDDI/nETSgw13LVcQieRe5ZqSjG/aD5n7Ldt8jZuq0HKSLFt8ja/MvqjCZ4oFAolMOg5NgksDZc6lvTD5rpSTSmyirK4F3nhqFVIa6xGSa84q+Jw5fjuGbuRzIRyCZ0KZhYKluJLNCXILsqGmZiRKEvE5kmbkXs4FxVNFZyikBSZhPyJ+ZzNgi+HNrZLjNXBBE90X5fir1DZpfgrgW2TwOKOWxnfddHmujiTCaFMkFVBmFGItKTrAWUq0pKuR+GMQkgZKUKloYgLj4MuvBdqiREVepVgJUCtU2P54eWcQrFl0hYMjB4IebgcSZFJKJxRiKTIJMjD5UiOTubcCH3ZO8A2MRb/u7KukbXNtVwyKAqFQqH4Lz1vJcFVnLlLXjmnYoDq4GCk/mkOUPJvQdnSftcgLjyOMzK0jR+wacImrDqyChVNFUiMTMTmiZuRpkgDIPQOsPUGcNU7oDtx9l1dXQWhszGKv0Jll+KvdESOAlNJcOYuCdifs8WBa2Vnkx75EzTBEyVQobJL8VfodoOrOHOXFDtniwPXykBKehRI35VCoVACFZ9VErxqQe/AdVEb1Qfq8F7252DNxdBe4iVHSY/K6ss6/F181ZOAJniiUCiUno9PKgmsBb2YOyC7zL3gwIKOvyBF3B61M/Ow4Pv1yPlmFdQ3Pi04p06dg5yEPljgJPGSs6RHc/fMRXZRttvfxevPoYPQBE8USuCgN5iQvHIvklfuhd5g6u7mULoYn1QS3LKgdzGhkx0js4H79wM3bgTu3w9dv9Go1VZa73lpL9QPfQnM/xTqh75EDlSoCA5CbUxf6B46aJcPwlnSI2WEEgaLASqdyqooqE4A5w9DrTrRrjeAL3oS0ARPFAqFEjj4pJLAJgviv3ROVJ2wezkpT31hNTJ882br/z8Vun6TnwqBf2UCn68GXp8G5Y7JKDj9C5KMJus9v12FE7Io5HzLs9r/y7tQKtPtqmITJNka7illSuyeuRvKCCVCJCFQ6VTI2XsXTvx7DnL23tWuN4DLz6EL7QCcfVd/cOGkUCiuoTeYrvwz846ZueOUwMCnvRucWtCbzG4ndOIQ825g7ymVIiehDyqC2xJkuvIybi/pUVPtOSz8/H5hvUYTCma9C2VCutPm+prXBE3wRAlkAkV2k1fudXq+/NlZXdIOiufocd4NTi3oO5DQicOJB4PSbMYmTbX4PZ3QXtKjwSaTfb2aaihb2rcn8DVPAprgiUKhUAIDn1YSnFrQdzShEyB+LXtPqRSrFHHi9+wE6rBe9vUq4qAOa/+FSj0JKBRKV3Nyw404ueFGHF+TyR07viaTO04JDHxWSWjXgj5I2rGEToCIdwMDgBFsNXjSal+tU1ttG4KDkGQ0YXel2mr7EByEnG+dv+ypJwGFQukOIkKCrvyT8o5Z/x7+1OfU2yFA8Eklwc6CfvwmpOsaUTB+k/AFOewGqw3C/E+t/9t4HThlZDZw5ztAxv3Anf+GesEh5AwdwSkInrLat/sus95F+p0fomDWu+3WSz0JKBQKhdKdBLVfpOthLegBoKDvLChfnQIQC5SMBAU3Po2cS3vbLOhlUe5le2T579+AX96x/n38X5ClzYU8KhEIChO12mezG7prtS/4Lvx6r3x2Vq/DazvZJop30BtMGP7U5wCsS7URIY67lztlKZTuJCIkCOXPzuJWDWy9HfjlKD0Pn/Vu0Bq00NWWQblzip0Hg/rhLyGTp3TcQK7iR+D1qfb3vPdT6BRDOmW1L0ZnvAE84Ungi/REC3GqJAQGPVF2XYF6O/g/HZEjnx2ZokKiENXcKOrBoGzWAp15MV44Kn5PVQmikieInuuMJ0FUSJTDF7krXhMdvZbSNbgzw6KzMQqF4k/49ojEeiHYxkJwxYPBGf3HiR/vN7Zz9VICEnZFgE/GMwe4v/kzLHfKUii+BOvRoDeYOZk9viZTYNhI6Xn4pOEih0iOBZc9GJyRNAoYcbfw2Ii7rccpFAqFYocjbwf2OKVn0iW/bKf2X0dmAynTrEGS5IM6ryCw3PpPYPQDwMVj1hUEqiBQOog7Myw6G6P4G7bjd01TK3eupqkVEXLH4/nFWh0m5B8CABxZMRn95I6NrKmdjm/iH79CdN825aDhkjViojyl8wpDlBJQplr/7yo82X6KTyA2mLEzLEdlhf7lxOmAWN3UgoxnDgIAjq+ZhrjIMIdl6UBL8TbhPIU2nCq3PR6vjiAeN9L6qRDY85jVRoGRWLci3ImN4K26fPmeFAqF0gHExu+KWj1ajG02YrU6I/c3X3m9WGvNTFvZ0MId4//NX1Ggxry+jVefvkeNtBoutb1gAev/exZbtyLcnZF7si5fvifFq9jO2vmrA3qDSTC48Zddv1g8AeG8c80GC3ct/5rqJuugyh+IHQ3KdKCleBqx8fuGbUeEn7ce5v7mj+esrPO5Y+cx0bLUmNe38Z+Rw1lCJ3dfsp6sy5fvSfFJbAfaCfnF3N/8AZHdYhBc62BQpgMthULxBl5VEjxqpOVJd0gP1OV2kCNvuXNSuhx3lmEv1TVDLgsRLLVSKP6A2Pj9xeIJaDFaMPvlb6yfl0yEXBZsd+2RFZMBWLcY2BWE9x4ei8Roe3saaszr23hVSXDHoKtdWHfIPYutM/DOuEN2si6tQYsFBxagtrlWEC4ZaMu3IA+XY0fmjjZFwZPtp3Qb/C0GPs6WYd0heeVeHFkxWWARrqpvwdxXrQPt+w+NxaB4ewtxdqCtaWoVXBsbGdqhdlD8H9vtMAAOjVrFDF7FjGzlkSGobTK03YQQUUNaMS+GxOgw0eMdMealdB3+9St40h2yE3XpjDrUNtdyCZYKxm+CsqUR6rBe1myPTRVcuaiQqDaPhpRp1kRUnnbnpPRYYiND0cxbsYiJCBYdlLmBNqRtoA3vqEJOoVAoV+iSEYRNEOIR+O6Q3VQXP8FSRVMFcvbehU2aaqxSxAmySCplSurR4Gc4ciFkZzkVtc1c2fcfGsvN8L9YPAGqhhbML/gBALD9zjQADBb++xcAwAPXD8DrX/8BAFiaORgmswUvFJ8DAKyeMRQJ0WFY+O8SAMB5jY67R0WdHqqGtnvW6Q0CI0i2jWz7mg1tWx6ODCIpPRux7TBrbAOGV8bMlbXKj73Ba5vxbdt1tToDmk38LVOGM7B1tKLQ3tjftoLA8I4yVHZ9BJ9N8OQPqFUnkLP3LlQEtwlxktGEglnvQpmQbl1B2Ha1vR3C4tKAX0Xw1SQ5jpSE9pLbnNxwIypq9XbbDt6GbSNNvtN1+KrssrQnC96iozJGZbfr6Ijs+nZYZh9H2dKITZpqwbFNmmooW7TWD848Gig+hd5guvJPOKNij7dHTVMr6vSGdst5GraNFAqF4g3oOk4nUIf1wipFnODYKkUcCsKioASoR4Mf0Z4LYXuI+YV7gi+WTEC9zshta9jCb6M1VgO1EA90xLwFrN4GDOduy8oGf7vBVm7Ezn2xZAKajRb89SXn3g2dbS+VXd+BriR0ELVObTVSDA5CktGE3ZVqJBlNqAgOQs63q6DWqb2XoIoSMCT1jkBCjOMwzHxo8p3A5mKtDskr92L4U59bcyrwZMFqANu24lRWpcXwpz5HxjMHoTeYUMvLx8D+nfHMQQx/6nP871I9d65OZwB4O9RsnRnPHETyyr2obmqB3mBC8sq9SF65l2sTe666qUXwGXCcOAqwKu/JK/fS1bJuhCoJHYB1c6xoqrAaKc56F+l3foiCWe8iKTKJ83pQ69RWI8XFpcD8T63/U6NFn+TIisk4smIy3nu4LV34m/eNxsePjuc+f7F4At57aAz3uTBnNO/cRHzy97ayn/x9PN7knV/7lz9zf2+/cwSeu/1q7vOrWSPxPq/ej3n16A0mgXfDew+NEdzniyUTcXzNNBxfM829L0yhUCguQKcYHUAWLIM8XA4AgjgJyiuf2TgJsuArPsGe9MigeAWx7YL5b/wg+GxrlJhd8APvnDAuQmLvcAzu0xZMa/2nv3F/sx4PLCMH9BbM9of0iUL5s7OQvHKvXdTFO179TtgmmwiMtp5ENOFTz8dZngQ2qFFNUyvqmttCel+sa/OY+d+lRhhMbYqouqEZzbzAYOeq9dzfv1ysgyw0hPt8ubEVDTxbnEv1LQgPbpt78ttUptEBaFuFsA0xzsouDTHuW9Cn3QGiQqKwI3OHaMRF1j3SLuIihUKheIH28iSIsew/Jdzf8wuEynB2wXHB5/V7TnJ/byw6LTj30O4fBZ9ZWwWxdti2iYYY9w+oktBBokKiHCoBYqGaKb4Lf7/zk7+Px+yXv73y93UIC5ZwKwiuGHsBwpkOuw1QqzNygyLf2IvvW247+IkboE0BQLgXgyMDLzobo1AonoCOFBQKj96ytqXUxN5hgpepM0NAR+HG3UnSZF+nfX2xkSE2ZcTvS2djgYOreRL457f8Xxq3mvBmzmgYTGY8uPsnAEBhTgaiI0Lx1yv5GdbePJxbTVg9YyhkoSF44qNfAQCvZo1CWBDDrT58/Oh1CA+W4IatR7h28NsEENyx07pl5sgzgno7+BZUSaAELGKzbX7EQgrFH3AnTwLLkPhI7u+r+vYSGMcOVEQKcn4MT2hbMR0zKA5yniL954QohPNe3n1jhIo1X1FJUQjbI5c5DzEuPEZDjHcX9KlTAhbxRE1ts3x2AHNmCNjejNwTsyKxsOZdcV+K78OXxy8WT+hwPc0CRdmMito2Y8WqxmaxSxxeS1/mPQv/+zXZZEnyFOoxQPF5umtWRGdjgUeSPMKp8mibR4H/N18ukuQRV3I9WEnvL3eqpPJtemIjQ+2UWncVXH6b6LZY9+NfIwZNlkTxIO7MtqkhIMWX8JQ8itVz5rIWDfo290S+GyN/C4P2icDAfxI80WRJPQpfSpLjSiwBmoSGwuILsuspeXQ3GRS/Xton/I+eneCJJkuiUCgUCqVL8Z/1IJosieIlXNn7pIaAFF/CU/IoVs/Hfx+PBr2Riygq5k7pyTZQfBv/URLYZEl7FltXEGiyJEoXQg0BKb6Ep+RRrPyQPlECw0VH7pS0TwQG/vVrjswGUqZZtxjkg6iCQKFQKBSKF/Efw0VKj8IXjL8olI5AZZfir/Rsw0UKhUKhUChditvbDezCQ2Njo8cbQwkcWPlxcyGrU1DZpXgCKrsUf6Ujsuu2kqDVagEA/fr1c/dSCsUOrVaL6OjoLrsXQGWX4hmo7FL8FXdk122bBIvFgsrKSkRFRYFhmA41kEIhhECr1SIxMRESSdfselHZpXgCKrsUf6Ujsuu2kkChUCgUCiUwoIaLFAqFQqFQRKFKAoVCoVAoFFGokkChUCgUCkUUqiRQKBQKhUIRhSoJFAqFQqFQRKFKAoVCoVAoFFGokkChUCgUCkUUqiRQKBQKhUIRhSoJFAqFQqFQRKFKAoVCoVAoFFGokkChUCgUCkUUqiRQKBQKhUIRhSoJFAqFQqFQRKFKAoVCoVAoFFGokkChUCgUCkUUqiRQKBQKhUIRxWeVhHvvvRcvvfRSh6+fOXMmysrKRM9NnjwZn376KQBg165dOH36NHdu165duP322zt8365g3bp1MBgMLpVNTk7Gr7/+anf80KFDyMjI8HTTOOrr65Gfny84xn/ugQCVYcd4QoZdobKyElOmTHF4nmEYNDU1ibaps79fdyPWB53BfxZ8vC1P5eXlePXVVwXHOvObdwWHDh3CF1984VLZzj6/p556Cu+9957ouXXr1mHZsmWibSovL0dcXFyH78vis0pCZ9m3bx9SUlLaLWc7wPoD69evd3mA7S7cHaAo9lAZ7jyJiYkoLi52qaw/9Ct38Jc+KKYk+DruKAmdZcOGDbjjjjvaLeetNrmlJDQ3N+OOO+7A8OHDMWLECNxwww3cud27d2PMmDEYOXIkJk2axGmBu3btwvTp0zFnzhykp6dj0qRJuHDhAgCgtLQUEyZMwMiRIzF8+HBs2rSp3Tbs3LkTDz/8MACgpKQEDMNg//79AIAnn3wSTz/9NAChJnry5EmubfPmzUNLSwsA4PXXX8fx48exaNEipKenY9++fQAArVaLu+66C6mpqcjIyMC5c+fs2vH1118jNTVVcGzSpEn45JNPoNFocMMNNyA1NRVpaWnIyckR/S7JyclYtWoVJk6ciMGDB+P555/nzp05cwazZs3C6NGjMWLECLzyyisAgAULFgAAxo8fj/T0dFRVVeGdd97BmDFjcM011wi+hzt8/vnnuP766zFq1CiMGTMGhw8fBmAVvPT0dDzyyCMYMWIErrrqKhw/fpy77qWXXsKQIUOQkZGBJ598ktNcFyxYgPr6eqSnpwtWLI4cOYIJEyYgJSWF+y5dCZXhNvxdhu+66y68++67AIAXX3wRoaGh0Ol0AIAJEybgyJEjdrOpDz/8EH/6058wbtw47jk7ahP73DMzMzF06FDcdttt3aZEMAyDdevW4brrrsPQoUO57w0AP/zwA6ZOnYqMjAyMHDkSH3zwAQDxPvj8889j9OjRuOaaa3Dttdfiu+++c7stzvrJjTfe6FDunnjiCQwePBhjxozB8uXLuTYtWLAAJ0+eRHp6OmbPns2V/+CDDzB+/HgMHDgQzzzzjGhbMjMzue8LAMXFxRg5ciQAa98YPnw40tPTkZqaKvpdnfVtANiyZQuuvfZajBw5EjNnzsTFixdx4sQJ7NixA4WFhUhPT8eGDRtgMplw4403IiMjA1dddRXmzZsHvV7v9DmeOnUKw4YNAwAQQhAXF4cnnngCAHDw4EFMmzYNgHBFq6GhAbfffjuGDx+OG2+8EWfPngUA0TaxPPXUUxg1ahQGDx7coXcDiBt8+OGHZPr06dznmpoaQgghX3/9NZk5cyZpaWkhhBBy+PBhkpaWRgghpKCggISFhZHff/+dEEJIXl4emTFjBiGEkMbGRu4avV5P0tPTyQ8//EAIIWT+/Plk+/btdm0oKysjAwcOJIQQ8vzzz5Nx48aR3NxcQgghY8eOJd9++y0hhJABAwaQ0tJSQgghI0eOJLt27SKEEHL06FEikUjInj17CCGETJo0ifubbW90dDQpLy8nhBCSm5tLHnroIdHnMXToUK69ZWVlRKlUEqPRSJ5//nny4IMP2j0nWwYMGEBycnIIIYRoNBrSv39/cuzYMWIymUhGRgb57bffCCGE6HQ6kpqaSn788UdCCCEAiFar5eqprq4mFouFEELI+fPnSUJCAjEYDHbPgU9xcTEZNWoU1/Zx48aRhoYGQgghZ86cIYmJicRgMJDi4mISFBTEfc9//vOf5IYbbiCEEPLLL7+QxMREcvnyZUIIIY899hiJjY3l2sH+zTJp0iQyZ84cYjKZiF6vJ8nJydzv1VVQGRbizzL8+uuvc/eePXs2GTduHCkqKiJarZb07t2bGAwGgRxevnyZyOVywe/Ib4dtm+bPn0/GjRtH9Ho9MZlMZPz48eSdd94RfQ7eBgBZt24dIcT6O8XGxpILFy6Quro6cs0115DKykpCSNtvoFKpRPtgVVUV9/fRo0fJVVddJbgH//uzFBQUkDlz5hBC2u8njuTuk08+IWlpaaSpqYmYzWZy6623cuMPfyxiGTBgAFm8eDHX5l69epGKigq7tr399ttk1qxZ3Ofs7Gzy4osvEkII6dWrF7l06RIhhBCDweDwuznq22+//TZ58MEHiclkIoQQUlhYSGbPnk0IIWTt2rVk6dKlXD0Wi4VUV1dzfy9YsIBs3rzZ7vnZ0q9fP/LHH3+Qn376iYwbN46MHTuWEELIypUrycaNGwkhwnHk8ccfF/S3fv36ce2wbdP58+cJAPLRRx8RQggpKioiQ4cOFW2HM9xaSRgxYgR+//13PPLII3jvvfcQHBwMAPj444/xyy+/YMyYMUhPT8fChQuh0Wg4rfv666/nNKaHHnoIxcXFIISgubkZDzzwAFJTUzF27Fj88ccfOHHihNM2DBo0CABw7tw5HDhwAJs2bcKXX36JxsZGnD59GqNHjxaUb2xsxK+//oqsrCwAwNixY+1mT7Zcf/31GDBgAABg3LhxDveF7733XuzatQuAVSOdN28egoKCMHbsWHz22WdYunQpPvnkE8hkMof3uv/++wEAcXFxuPXWW3Hw4EGcOnUK//vf/3DnnXciPT0d48ePh1arxcmTJ0XrOH/+PGbMmIGrr74at9xyC6qrq/HHH384/Y58PvvsM5w9exYTJ05Eeno6t3928eJFAMCwYcM4rZ//PA4dOoSZM2ciPj4eABzONvnceeedkEqlCA8PR3p6usNn6y2oDAvxZxmePn06Dhw4ALPZjN9++w2PP/44Dhw4gK+++grjxo3jfluWY8eOYeTIkYLfsT1uu+02hIeHQyqV4tprr+1yeeXzwAMPALDKz/XXX48jR47g22+/xblz5zBjxgykp6cjMzMThBCcOnVKtI6ff/4ZkyZNwtVXX83N4N1ZHXGln4jJXXFxMebOnQuZTAaJRIL58+e3e6958+YBABQKBQYNGoTz58/blbnttttw7NgxqNVqaLVa7NmzB3fffTcAYOrUqcjOzsYLL7yA8+fPIzIyUvQ+jvr2Rx99hAMHDmDUqFFIT09Hfn6+Q5kkhGDr1q245pprkJaWhr1797Y7DgDAtGnTcODAARw4cAD33HMPmpub0dDQgAMHDiAzM9OufHFxsaC/3XbbbU7rl8lk+Otf/wrA+TjgjCB3Cg8aNAgnT57El19+iQMHDmDFihU4ceIECCG47777BEscrrB69Wr06dMHP//8M4KCgnDbbbdxy6jOmDZtGoqKinD27FlMmjQJFosFH3zwAa6//noEBdl/JYZh3GpXWFgY97dUKoXJZBItl52djWuuuQZbtmzBm2++yS3ljBs3DidOnMCBAwfwwQcfYM2aNfj5558hlUrbvTfDMNzSkytCBlhfvFu2bMEtt9wCAJDL5S49RxZCCG666SYUFhbanbtw4YLD50EI8dqz9RZUhoX4swz3798foaGheOutt5CRkYFp06bh2WefhdlsFh1gCSEutYVPd8urM9jnnJaWxm0P8ikvLxd8NhgMmDNnDg4dOoRRo0ahsbER0dHRMBgMCAkJceme7fWTrh4rwsLCcPvtt+Ott95C7969kZmZidjYWADWraUff/yRm8w888wzuPPOO12+PyEEa9aswX333ddu2XfeeQdfffUVDh8+jKioKLz44ouiv4ktmZmZ2Lt3L2pra/Hiiy/izJkz+PDDD3H+/HmMGjVKtE3uYPsMzWazW9cDbtokVFRUgGEYzJ49G1u2bAEhBBcvXsTNN9+MwsJCbuZpsVgE+9bffPMNZ1j1+uuvY+rUqWAYBnV1dUhKSkJQUBBOnTrF7cu2R2ZmJjZv3owxY8YAAKZMmYL169eLDgy9evXC1VdfjbfffhsA8P3336O0tFRwvqGhwZ3HwNG3b19kZGRg8eLFUCqVuOqqqwCA01rnzp2L7du34/Tp06JWwwBQUFAAAKitrcVHH32EadOmYdiwYYiIiBC8tM+ePYva2loAQFRUlKDNdXV1SE5OBgC89dZbqKurc+t73HDDDfjss88E1sTff/99u9dNnjwZ+/btQ3V1NQDgzTff5M716tULer3epwZVgMqwLf4uw5mZmVi7di0yMzPRu3dvSKVSfPjhh6LPcdy4cfj5558FvyMf2zb5Gm+88QYA68v/66+/xvXXX4/x48fjzJkz+PLLL7lyJ06cgMFgsOuDLS0tMBqN6NevHwBg+/btbrehvX7iiClTpuA///kP9Ho9LBYLdu/ezZ3rjPwCwH333Yddu3ahoKCAW800mUwoKytDRkYGli1bhttvv93hmOaob8+ePRuvvPIKJ7NGoxE///yzaJvr6uoQGxuLqKgoaLVabnWuPTIzM3Hw4EH88ccfGDp0KDIzM7F+/XpMmjQJEon963natGmC/vbf//6XO9fZ5+gIt1YSSktLsXLlShBCYLFYkJWVhbS0NADAxo0b8de//hVmsxlGoxGzZs3ilqgnTZqEdevW4eTJk4iOjuYGjjVr1iArKwtvv/02kpOTMXXqVJfaMW3aNFy4cIEbCKZPn44tW7aIDgwAUFhYiJycHGzduhUjR47kBmbAury0dOlSbN68GRs3bnTncQCwLrHPnTsX//znP7ljhw4dwvPPP89pbps3b0Z0dLTo9QMGDMCECROgUqmwaNEiXHvttQCAPXv2YMmSJdiyZQvMZjMUCgX3kli6dCmmTp2K8PBwfPHFF3jhhRdw6623om/fvhg3bhz69+/v1ncYMmQI3nrrLTzwwANobm6GwWDAyJEjufs5YsSIEVixYgXGjh2LhIQETJ06lfuecrkc8+bNQ2pqKmQymUsDSVdAZdgef5bh6dOnY8eOHdxzmzZtGv71r3+JbsfEx8fj1Vdfxc0334zY2Fg7tzTbNvkaoaGhuO6666DRaLB9+3buZb9nzx4sX74cS5YsgdFoRP/+/fHRRx+J9sENGzbg2muvRf/+/QVGgq4yceJEp/3EEbNnz8a3336LESNGIDExEWPHjuUUwbS0NAwbNgxXX301Bg0ahE8++cStNrHydv78ec4Q2Ww2IycnB3V1dQgKCoJCoeBerrY46ttZWVmoqanB5MmTwTAMTCYT7r//flxzzTW49dZbsXv3bqSnp+O2227DY489ho8//hjDhw9H3759MWHCBFy6dKndtvfp0wd9+vQRjDOVlZXIzc0VLf/kk0/ivvvuw/DhwzFgwABMnz6dO2fbpuzsbNcfohMY0pE1ODfYtWsXPv30U/y///f/vHkbvyQ5ORmffvoprr766u5uSofRarWIiooCYPXZPXv2LN56661ubpVnoTLsmJ4gw/4AwzDQarUO99X9AXassFgseOCBB5CYmOjQa6GroH27fdxaSaBQbFm5ciW++eYbGAwGDBw4EK+99lp3N4lCofgg2dnZKC8vR3NzM0aOHIkVK1Z0d5MoLuD1lQQKhUKhUCj+SY+NuEihUCgUCqVzUCWBQqFQKBSKKFRJoFAoFAqFIorbhosWiwWVlZWIiopyOzgGhcJCCIFWq0ViYqKoP7A3oLJL8QRUdin+Skdk120lobKykvPPpVA6y8WLF5GUlNQl96KyS/EkVHYp/oo7suu2ksD6xF+8eBG9evVy93IKBYA1H0G/fv04eeoKqOxSPAGVXYq/0hHZdVtJYJe6evXqRYWV0mm6cumUyi7Fk1DZpfgr7shujzBc1Bq0UOvUoufUOjW0Bm0Xt4hC8W9UTSqUakpFz5VqSqFqUrVbB+2XlEDGmfyX1ZehrL5MtAzbN3ylj/h9xEWtQYsFBxagtrkWBTcVQClTcufUOjVyPsuBPFyOHZk7EBXSdcuDFIq/ompS4ZaPb0GruRWFMwqRpkjjzpVoSpBdlI1QaSg++utHSIhMEK2D9ktKIONM/s/WncUdn94BAoKBvQZCb9JzZdi+ERkSiUZDI+LC47q9j/j9SoLOqENtcy0qmiqQ81kOp5WxD7uiqQK1zbXQGXXd3FIKxT+obq5Gq7kVZmJGdlE2SjQlANoUBDMxo9Xciurmaod10H5JCWScyf8jBx+BwWKA0WLE2fqzXJkSTQnXN87UnUFlU6VP9BG/VxKUMiUKbipAUmQS97BPVJ3gHnZSZJKdJkehUByTqkhF4YxCSBkppyi8f+p9TkGQMlIUzihEqsI+0yIL7ZeUQMaZ/Kt0KiTIEqCMUMICC6SMFBVNFcguykZFUwXX73ylj7idu6GxsRHR0dFoaGjwKQMa/gyFxVceMsWe7pAjX5VdX4W/csDCKgj8LQhn9MR+SWWX4irO5B+A3TnbMp7uIx2RI79fSWBRypTYNGGT4NimCZvsHnJPNqbqyd+N0vWkKdKwesxqwbHVY1a7rCAArvdLCqUn4kz+xc7ZlvEFeoySoNapserIKsGxVUdWCV6arDEJf4+If33OZzlYcGCBX75Me/J3o1jprBLo7vUlmhJs/G6j4NjG7zbi0IVDLtfhSr+kUHwdd/oO3zNITP5XHF4BtU4teo7Fl/pIj1AS+Es6SZFJ2D1jt2AviH3Y7hpT+dPMnBqK9Ww6qwS6ez1/q0HKSPHk2Ce5vdKFxQtRfKG43Tpc7ZcUii/jTt9hPYOyirJQfKFYIP9rx60FAKh0KszbNw9Z+7I4GwQAgv99qY/4vZJgOxAV3FSA9Ph0O6MRtU7tljGVv83MqaFYz6azSqA715dqSu2MFOcOm4ttk7dx9S0qXsQpCmJ1uNMvKRRfxp2+w/cMWlS8iJP/FaNX4Jljz3B1VumroNarIYGEM1IsnFGIpMgkrt/5Sh/xeyVBFiyDPFxu9xLkvzTl4XLIgmV2xyuaKpBVlCX6EvXHmbmr343if3RWCXTn+rjwOIRKQ+2MFCf3n4wXp7zI1bnx+40O63C3X1Iovoo7fYf1DJLwXq23DbkNSw4t4V7+eRPyECIJQbAkGINjBnPXpynSuPsM6T0EiZGJPtFHeoR3g9aghc6oEx0g1To1ZMEyu2AUJ6pOIKsoi/u8e8ZupMen213LF4RNEzZh1ZFVPv/ideW7dTfUQrxjdNZbwNXrVU0qVDdXi7o5Fl8oxsbvNwpmOGJ1dKRf+gNUdgMTd/peiaYEWfuyYIGFO8ZXusvqywAA8RHxdn2E7Rs6o87jfSRgvRuiQqKczqBsH7KrxlT+ODOnhmI9m856C7h6fUJkgsM4CFP6T8HmiZvbrcPdfkmh+DLu9L00RRqeGPuE4BjfMyglJgUpMSmifYTtG77SR3qEkuAO7hpT+ZMLFzUU8z/cNY51VQkUy72gNWhRqinF0kNLBceXfbUMu0p3idrXHLpwCGfrztrVIdaGUk2pz9joUCiehJX73MO5guOrjqzCd5Xfoay+TJBz4VjlMVHPoGOVxzjPBq1BK+j/tv3dHeN4bxrZ94jtBlcRM6bix8sWWyXwl2Awap0a84vmo1JX6fC7JcoS8eaMN32i3XTJ1v38Bq5uf4nlXtAatLj/8/txqvYULLCAAYOtk7di0/ebcFl/GYBVrt+/+X1u9lJ8oRiLihdBAgk+mP0B+sj64P7P78fputOcsRW/DVJGiqG9h+JfN/7LJ2ZA3oLKbmBh23ekjBRJUUmo0FZwgcaCJEGIDYuFPEyOKl0ValpruOuVEUpU6au4rYfYsFgES4IRGx4LAGhobUDexDzkHs7l+rvOqHM5v4k74whpIYG53eAq7hpT+dPMnBCC+tZ6q2HMxDzBd8ubmAcpI0V9az3c1AkpXsQd41h3vAXEci+UN5RzgxxgTRUbHxGPe/50D9eeiqYK/L9T/w9Am4IAABZYUKGtQHlDOacgsHKWHp/OyZeZmHG67jTKG8q79kFSKF6ElXu275iJWaAgAIDJYsJl/WX8Xvu7QEEAAE2zBmvHreWMGWtaaqDWq1Glq0JtS60gJHNtcy3KG8rdMo73tpF9QCkJUSFR2JG5Q9TACgAKbioQnbUlyhJ93oWLYRjEhMXATMzIPZwrEJTcw7kwEzNiwmLcyiNO8S7uWE27o+CK5V44UXVCYEQVFxYHMzHjvdPvCdr0/E/P47njz3EKAgC8OOVFTO4/GcnRyRjSewhXb+7hXJyoOsHJl5SRYkjvIUiOTu6S50ehdAV8uQfAyb8YBMJJGFv2tdLX8OTYJwXngqRByB2dy5WRMlIsy1iGFYdXuGX75m3394DabhDD0VKN1qDFfZ/fhzN1Z+yWUH011a0/eWPQJds2XN3SctdbQCz3goSRIC4sDlXNVYJ7zR06F8//9LxdvS9OeRFT+k8RtOF8w3nkHs61a2/exDwMjB7oM/3BW1DZDTwcyb0z2D5he40iTIEgaRBUOhV3zFbx6Mh47co4ErDeDZ3B0VKNzqhDo6ERZmLmBmcWVnPzJQUB8E9vDIrrxrHueguI5V54YswTeG7yc3b3yknNwb1X3Ss4fu9V9woUBLYNaYo00famKdJ8qj9QKJ7Ckdw7g+0Tttc8P+V55E/MFxyz7acdMY73lpF9wK8kAP41A3cFGifBd+7pCt4yjnWUxTE2LNZuJeHB1Aex9uhauzpsVxK82V5/gcpuYCIm985wtJKgjFCCYRi6kuBP9KQZOI2T4F+4YxzrjpvTscpjDnMvVDVXIS4sTnAvvoLAX1Hgh192t73u4E95UiiBB1/uWdsER8SFxSE+Il5gkJgYmYhtk7dBEaaAWq+GSqdCgiwB2yZvE9gkbJu8zaX+ZNtf+O1LkCVgZ+ZOj9nOBZyS4GgwUsqUWJ6xXHDM1tCET1cNXO4Mnv7kjUFxL++IO7lEvlN9hwf3PyjIvTAxaSJiw2K5a6pbrB4QD6U+JKhr/bj1WJqxVBB+eVHxIhy6cMhr+Rj8LU8KJbCwVRDYfgVAEH6Z/VzdUo1qfTUkjIQrGx4Ujn8c+4fA88FkNmHj9xu5FQQzMWPL8S3In5jvtD/Z9hdbBYEQgpd/eRnbp273yPgfUEqCs8GoRFOCx796XHBs4ZcLkV2U3W0DlzuDJ02o43+447HgjptTeFA4GFi9WOShcsRHxEMWLENseCw3qDFgEB4UjlRFKld2QK8BmJ48HYA1qiKrKEggQVJUktfyMfhjnhRK4MDKfaIsEUN7D0ViZCKG9B6CpMgk7Jy+k8vD0CeiDwbFDIIEElhggQQSSBkpBkYPhLZVC02LBhZigYSRQBGmQO+w3qhrqQNgNWZMkCVAHi5HcnSy0/5k2190Rh3k4XJOQVDr1ahtrkVkSKRH8qQElE2Co6BJtmlxn5/0PDZ9vwlqvXWwSpAloHBGYbuBl7qqvWLHZcEytwLzdDd0X9eKOx4L7tjOlGhKsPjLxdC0aLiyuYdzUamrhCJMgW1Tt3EhYs/WnUWpphSZyZl2snHowiEkRSVhcO/BbrfXHfzJLojKbuDByj0/pwLbD9g8DLJgGWTBMpxvOI/lh5ejsqkS8eHxePq6p7Hu6DrOBkERpsCasWuQ90MeKnWVUEYosXvmbq4Ofn931J9s+8uTY5/E2m/XQq1XiwYEZOvpiBwFlJIA2D/cZRnLsPSrpYKl2TRFGtQ6NbL2ZQkUhfyJ+Q4HLrHBk+8VYftjuzqgujN4+lNCHTrQdgx3jAb9zcDQX9pLZZfSHmKyzJ/ps3RGvjvSX6iS4CJiD9c2LS5bLmtfFmpbamGwGLjjYi9n21k8e6xKVwWGYaCIUNgFanJ1Zu8vg6c70IG247jjveIPni58/KG9VHYpriAmywA8Kt/u9hfq3eAiYv6kz016TqAgsOV2z9yN7VO3C47b+p6K7anqjDpU6ao4S1aNXmMXXtfVfVZ/SjJF8R5agxYlmhJR75USTYnAPuZs3Vl8ePpDu7LLv1qOD09/KEjaBNgbwXaHtwH1zKH4I2xf4f9foilB7hFhMqhlXy3DkuIlgmN8+XalX9kmhLLtL7lHcj3eXwJSSRB7uFuObxG1Iq3SV+HpY08LjtsOykqZEi9NewnKCKVAUeCHQDZbzB22Z6CDJ4WNAMq6VNl6r2QXZeO+z++D1qDF2bqzuO2T27D26Fqu7M5Mq4GVWq/G2qNrcdsnt3GKgq0RbHd4G1DPHIo/wvaV+Z/Nx32f34f5RfORvS8b2UXZqGyqBGBd9ZVAgsv6y6huqQYA9A7tjRBJCCffJZqSdvsVv1+y5dn+wrpSVjZVYv5n8z3aXwJOSXB1MHJnUNYatHjq26fAMAynKGQVZUGlUyE+PB5SRoqq5qoOxV+ggycFsCaZOVN3xmlypTN1Z1DeUI5STakghvyDqQ9iUMwggXUzAUGpplR0ZaurvQ2oZw7FX2H7SmVTJc7UnUGlrhJnG84KAiNVNFUI8qYAQF1rHWLCYrj3BT/Bk6N+xe+X/PdS3sQ8bDm+hRsbKpsqPdpf/EpJ6OwSqDuDkTuDMvvjqXQqWIjF7r62yUBc3SqggyeFJTk6GUN7D3WaXGlo76FIjk5GZnImBkQN4K5de3Qt3v7tbdS11nHHgpgg9JH1EV3Z8nbCGFu85VpJoXgbvozy4ye4ggQSrLx2Jden2USCzkKvF9xUgERZoiAhFBvRMSkyCYUzCj3eX/zGcNGdnNmODAHdqeOy7jJu++Q2bkZm61kAWH3NP5z9IQb3Hgy1To3somxBqE2Wjobc9MR39lWo8Zf7aA1alDeUc1niWJIik5A/MR/J0cmcHGgNWhwoP4Cnjj5lV0/v0N4ChcEXvCOoZ47v3ZPiOu6EbO4T0QcMGIGXQ6IsEW/OeNPlyeP8ovmo1FVyx2xd5B31lx5tuOiJJVBHqaIB+6RNzaZmLsgMAEG4ZhYGDJpNzdxnR/qWmZitvrBubhW4015KzycqJAqpilRRI9ZURapADqJConDr0FtFkza9OPVFu+vFBqeuNJh1N3kVheJLiPUVR2yZtAWbJ20WHMubmOdyv1LKlMibmCc4xu+Xnu4vfqMkeGoJ1NXBKFWRit0zdztcPpIyUuyeuRupilSrZvfZfKj1aijCFaLlCYh9joh9WS4pCnTw9H884S2galLh0IVDokashy4cgqqpbRVLa9Diw9MfYtf/dgnK7vrfLiz8cqHgWO6RXJRoSkTbteLwCrt7eWN7i+ZuoPgKfFm09Vwoqy/jgifxj5+tO4vlXy13Vi3HisMr7MqK9StHfUKtU2PZoWUOr/d0f/EbJQHo+kRMaYo0bJ28VfTc1slbOZdJQgjqW+ohgUTg0cBHa9CCEKuisGK0deCt0lehydDk0TZTfA9PeAuomlSY/dFsLCxeKGrEurB4IWZ/NBuqJhW0Bi3u3nu3w6RN9a31CGKCsDNzJxIjE1HZVInsomyBosDfPguRhHg0YYw3ng+F4gn4sni27qzAc2He3nn4vz3/h7l75uKY6hhyPsvB/Z/fj3v23oO5e+YKtg8cIWWkUOlUUOvVTleXHfUJtU6Ne/beg8vNlwEAm67fJLjeFS8Jd/ErJQEQX9ZxJxGTqkmFUk2poAyrsZVqSgWzMbVOjY3fbRStN/+HfO7HYxgGUcFRsMCCKn0VEmQJWDd2naB8iCQEDMOgRFOCJYeWcNfxtyvE2kvxfzyxVXaq9hRazC3c5xWjVyA9Pp1TOAGgxdyCU7WncKD8AMoby7nj68etx7w/z0NMaAx3zERMuKy7jM0TN3M2M9lF2ZzHA9++Rh4mx6CYQV4zmKW5Gyi+Al8WHzn4CKp0VahsqsTp2tOoaq6C0WKEwWLAgv0LUNFUgVO1p3C5+TKMxMjVYZv0icXWNo1hGNEVcjbOjm2fYIP7sQoCALzw0wvIm5gn8LrzdH/xOyVBLGaAq4mYVE0q3PLxLcgqyuJmTazGdvendyOrKAu3fHwLVE0qu7DMttgOaIRps0ewWCxI6Z0CeaicO1ZvqMfesr1cjgjAuhqRqkh12F5Kz8ATW2WjlKMwOGYw93nJoSV4/9T7nMIJAINjBmOUcpQgaRMAvFb6Gs7Vn4PeqOeOMWCQqkhFmiINhTMKuQFs2VfLcK7+HGqardnq2Ljytl4PnrSe7mpvCgrFEXxZVOlU1mi54Qo7F0Z2DOcfD5YEo094HwyTD0NiZCJSolMgZaQYHDMYiTLr52BJMJcMShGhgCxYJtqvxPrEufpzqG2pBQDER8RDGaGEWq9G7uFcLMtY1uYlEencS8Jd/Ma7ARDPY7D8q+UuJ2LS6DXIKsoS5GmIj4jH3Z/eDU2LBsAVW4MZuxEeFI7/++T/YIKJO/5o+qN44ecXuPYMiBqAd//yLqr0VZi7Zy4MFgOXAYxFHipHbWut6PdpL2lTTx4UA9FCvLPeAlqDFsfVx7Hk0BLBjETKSLF18lZkKDM4GxU2adOrpa/axY//W9rfkKpI5ZI2AUCpphTLvlomsJjmKwi238Mb3gb+En48EGU30HDHWwGw9qtXpr2CyJBIQRKo8oZyJEcnc5+r9FUA2pJBtZfPx1EOiMIZhQBgdy4xMhFv3uTYS6JHezc4ihmwe+ZuKCOsD0SlUyG7KNvhLCRVkSqYNWUXZeNwxWHBS1weKoeZmPHQFw8JFITCGYV4IO0B5E1osyr9Q/sHvij/Ao8efBQGiwHx4fH4x/X/ELT7hakvYPE1iwXHHrvmMTprCkA66y0QFRKFKf2nYPWY1YLjq8esxpT+UwSDy+Deg3Hr0Fvt7pc/MR+3Dr1VoCAAVkNdW4vpzZM2O/R68IbBLA0/TvEV3PFWAKz9anDvwVzfYP9nvY7YzykxKUiJSRHtQ46OifVhdmXP9lzeBNe9JFzFb1YS2osZ4EoiJhZ+amgWKSOFPFTOrSjwWT9uPW4behvXhj8a/kCDoUFQJkGWALPFjPrWekEbFGEK1LbWis788n/I9/lZk7cIxNmYJ2bKjmTXNjmZu/fzhVm8L7TBFQJRdgMNd1cSvCWnzvoEYL+S4I0skH6zktBezABXEjGxpCnSRGdjz095XnCM3dfdcGwDSjQl0Bl1qGyqtFMQAMBgNqCquQoGi4GzWlWEKaBp0XDbG0+OfZJbxVhcvBj3X32/XXsBUHuEHkhZfRmy9rV54/CtmrP2ZXFuVYB1q+DQhUN2dRyrPIZ5++aJylPWviwcqzzGlXUnnLcvhP72hTZQKIBQFvtE9IE8TO60vISR2BkYujqGO3P9LdGUYP5n8x2mBXA0nni6v/jNSkJ7uDMLcXUlgb8KIGWkeHzU49h8XBgEw5ZgSTD+c/N/oDfqOfsHtq53/vIOyhvK8eD+B0WvVUYo7dJK91QCaTZWVl/G2azw9/n5xrEhkhC8f/P7IIRgzidzYIEFL055EVP6TwEAfFf5HR7Y/wBX57PXP4tZKbNQoilB1r4szg7m9emvY0D0ANHtK7EtOwAul/XWbN7RvXzVTieQZDfQsFUQaltqYbQY27/wCgmyBBBCEC+Lb3cMd7Y6Xqop5d4ffDsDW88j2/Gkvf7So1cSnOHOLISvINjOxjQtGijCFNz1mhYN5KFy7nx7CgJgDXkrC5YhLjwOodJQSBkpFGEKJEQlQBYsQ3J0MmLDYrnyinDr/VhLVX5aaUrPwzaOhu3nCm1bMphFxYtQfKEYAHCy+qSgnMFs3dKKj4hHXESctS4wCA8KdysXgi/kTfCFNlAogFAWn7nuGYGXEIuUkYoel4fJUdNcA7Ve7ZILojPX32VfLePeUZsnbhb0iVemvYIQSQhCJCHYMX2H1/uL368kONKeztadxSMHH4FKp+qQd4MiQsHVGxMSg3pDvUvt4XtYqJpUqG62pgaNC49DQmSCnWtlgiwB+RPzseLwClHtsKcSaLMxW3nk5wFhLaNZY8LiC8VYVLyIu/beq+61i5xoW0d8RDyen/Q8RsSPAOBeLgRfyJvgC21wlUCT3UCDL4v8fuuMldeuxK5fd0GtV3cqyy+/TyfKErFl0haBmzwLuz2ZEpMiWmdA5m5whNgsRGvQYu3RtSCEIEGWwGlVceFxCJGEAACSeyVjYPRAyIJlSIhKgCJMASkjRag0FHHhcZxWpghTiCoIYpqkhJEgJjSG0+ASIhOgiFBgxeEVWHZ4GbQGLWTBMsTLrD6uCbIEqHQqLq10giwByggl4mXxdNbUwxjcezCXoc02WmjhjEKBt8GU/lPw4pS2/Ap8BWH9uPWidbw9821OQQDcC+ftC6G/faENFAoglEV+v3XGs98/67aCADiPIvzmjDdFFQQAnJeEozoDMneDI8QMGtllHLVeDUIINozfgKiQKDAMg+jQaABAq7kVOqOOu/6dv7yD3TN246O/foSEyAQA1rDJrHskuzXBKgdsdkg+FmJBTXMNt8wkFjGOvd/umbuRPzFfcH3+xHzsnrm7x9sjBCruuPhN6T9FNDnTbUNvo26CFEoX4swd0raPdqQv+rrrr98rCYD9LISvnan1ajx68FEuFoGYtsden6pI5RSEUk0p7tl3j2BrYmLSRCgixBM4sYmgqpqrkLUvy2nsA1YBEEvUwz9P6TloDVqUaEpEf/MSTYnAGtpZcqYXf3wRuUdyBceXfrXUro5fqn7B9h+32yV9UuvU+O/p/+KXql8Ex0s1paIW2TRMOCVQYEP224buV+vUgsimfGz76OPFj+Ns3Vk774LvVN+hRFPC9Se+V0OJpsSuTy/7apnD5E5d3R/93ibBGZ3xu/6l6hfcU3QPAGGchPs+vw+/1/7OlXtq7FN449c3UNFUASkjhQQSQRxvsfs524fyJStubxJI+7qs3JypOwMzMdv95lJGiiG9h+CNG98AANy19y780fgHd72YTUJiZCKWZyzH44ceBwGBhJFgaO+heOPGN3Cu/hwnu8EIxt45exEZEokFBxbgQuMF1LfWAwDemvEWBsUM4to2tPdQ/OvGf3FKKiun8nA5Xd3iEUiyGyiwIftbza0IYoJgIibOZu2uvXdxtmWOYA3PASAIQYiLiOPsyo5VHsOD+x8EAwaxYbHoI+sDAGhobcCK0Su4CKqJkYlYmL4Qq762TiT6RPTBWzPf4t4FnuiPAWmT4AhVk9VLwHYZZ1nGMhy9dFQww2LhJ3iSMBIuUQc/TkKVroorz4DBn+R/QsFNBUiMTISZmBEVKvzhbGMfOIoc6a3kOZTup7yhnFMQpIwUeRPzkB6fjryJeZznzJm6MyhvKMeB8gMCBWH9uPVYmrEUD14tdJv9S/Jf0CeiD/fZQiw4XXca5Q3l+OriV9xxI4z4z6n/QGfUCRQEADhXfw7nG85zbTtddxrll34Azh+GWnXCbquMQumpVDdXo9XcCjMxo9XSeiX2yD2Y+8ntogqChBG+Ovk5fkwwQa23GqgXXyjGggMLAFi3qKtbqlGlq0Jti9WrYVHxIm5cWDl6JV78uc0W6bL+MpeTqDuTnfVIJYGfyGnpoaWCc4sPLcZTR5/CzR/dLFAUSjQlggRPydHJGBQzCAC4EM57yvYIQjinxKQgOToZsmAZwqXhAIC6ljrB/VYcXoGsfVlc0ibq7hV4JEcnY2jvoZxCkHs4FyeqTiD3cC43QAztPRTJ0cmiyZlOVJ3A3vN7BXV+fO5jmIlZsP1lIRb8XPUz3vjfG4Kyr/36Grb+uFWgIMSExmBgzEBBG8zEjBUH/44T/56DnL13BdTKFiWw4YfsBwAQAgsI6nh9hkURrrAzZAyThuGFyS+0XQ+r4sAqAXyCpEHIHZ0ryBa5Zswa5P+QzxmwK8Ks/bqmuQbn6s91a7yQHrndwA9EAQDxobF47k/3YuFvr6He0MiVY7cRbGMn2LpAOoJ1d6zSVwmCM8WHx+O5yc85dGv0J3cvbxFoS7ZagxblDeVYcXiF3fZX/sR8JEcnt5ucKVGWiL8M/As+PvcxLuvb0sXGR8RDo9cIjGmljBT3XXUfXvv1Nbu2xITGCBSGpMgk5I1chtyDj6IiOKjtuNGEglnvQpmQ7olH0GMINNkNJErOH0T2V4/BzNh7rzGwBrpjkzQB1m2/VaNXYZh8GBIiE0QD9bGwwfL47pS2CQH5Qc5ssxB7QkHw+e0GZyEoXTHIsDUo4cPfKlBEKAQBi2paqnH6wGpoW4XhlDcc24D3T70vUBAKZxQiVZEqmNk7ghAiCHzBwi5F8fUvftAc6u4VeLDJXsSsmNkkMCyOkjPlTczDwlELsWXSFsHx5yY9hzVj1wiOrR6zGotGLcLMgTMFx2cOnCkavjwNwdikES6rbtJUQ9lCjRYpgUMagrG6Wjxr75qxa/DcpOcEx/Im5GFy/8mcwbtYyH+WzZM223m0PTH2CcFn1qtBKVNi86TNoue6mi5bSWgvQVN7Bhl8wxLbZDas9hYqDcVHf/2IM9JSN15CTUu1QCuUEoKokGjUGxsF9TtKkmMb2IbFNgV0iCQEMaExkDASgfYXSKGW3SEQZ2OeSLiUNzEPuYdzBcfjI+JRra8WzEjoSoL3CETZDRScrSRIIEFcRJxgJcG2/7q7ksBu89nWB7ifvMkVfHolwVkISlcMMviGJdlF2SjRlAAQ/iit5lZUN1cjKiQKWyZuwbY/32enFS6tqcPTQ+bhsWseExxfPWY14iPiBasZxyqPOXR9sQ2wtH3qdrw962077W/zpM0onFFIFYQA52zdWWQXZTtM1nK27ixX1lmYcds64iPiUaWvggUWSCARhBnnKwj8FYX61nrEhMYI6z2yFBXBQUgymrC7Uo0kowkVwUHI+XYVNaKl9BicrWYXXyhG9pGlVgWBnTvz5tAWWFClr0J8RLxo6H9nCgIALux+giwB2yZv4/qplJFi2+Rt3ZK8yRW6TEmwjSyV81mO01gCtvANS1hFwdFWgdagxbLDy7D4tzewMU6YwSs/tjcWnvwnXvj5BcHxjd9txLy98zgDw+9U3+HB/Q86/MEtxCL4/PSxp1Glr6KxDyh2lNWX4Y5P7+AGCL5HCxt1845P70BZfZlD75f8ifmCQYX1jKjWt20RxEXEYWLSRNx31X2C+z949YNYMmoJYkJjuGP1rfU4X39e4GEhZaTIn/Yy0u/8EAWz3qXeNpQeBbuaLSbPhy4cEhoZMgykjATr05cIDAwBoFpfDSkjFbzP5u2bh6x9WXarAi9OeVFgzAgAJrMJeT/kCQyGtxzfgryJedx4oNaroYxQ+oT3W5faJDgLQenKMkqaIk2gKDx97GmBgsBuFeiMOqib1KhqrYGZYSAlBE9qaiAhBOAtI0kY4cyrqrkK6iY1dEYdwoPCBfdOuDLDijeZBMfXDr4bSREJorM8OshSbLHd3bP97Mj7he8hMaT3EAyMHoi48DiEBYVBAgniI+KhlCkhC5ZhUr9JXH3BCMb/JU6ArPIX9I9QChSFQTGDMDB6IIb0HtLmYdF3NDBwApQJ6dTbhtKjcLaa/Y/v/sGVC5GEXHmn7MZt6fdj5/Sd3DkGQJg0RBC6PykyCbFhsVxCv5ToFK7/Tuk/BTsyd1y5lkFcWBziZfGQh8m5kOxsHxsYPbDLkze5Qrd4N5yoOoGsoizu8+4Zu5Een+7y9e/vfxxPV+7nPj+ZOB1zpz/PfXbVuyEmNAbbp27H0kNLUdVs3WeSMBK8NeMtKCIUuHvv3dA0WxM/KY1GrKqpw5I+CliuKBpykxnvVapRFRSE7MQEmGHhvCNSFak+m+rWFwi0fd2y+jIs2L+Ai/jJD6akjFBix/QdXCx2R94vrIcE3xOCTSKmiFAIvGJ+qfoFhy8exu1GBgmfPwkQC7QSKXQ3Po2jvRMxKGaQIBmUbb0sgeJt4w6BJrs9CWeB7JQRSjwx5gkMkw9DdXO1IG/Cd189jfBvXgQDgjgzQcKsrcDIbK5OWbAMTYYmVDdXIzk62a7/fqf6DuFB4YiPaMvLw5ax7WMdTd7kCh2Roy5XEjoTBREQNyyREoLCSS8gbeA0AEIjx9iwWE4BcEZsaCxqWmsggQQfzP4AsmDZlTpaIDcYoOEZdEmuPLIwQvDRxUpEEoL7lH1wJjycRq1zkUAcaDsr+27TcAnYdjXA3xpjpMDiUiC6r+fvFyAEouz2JNzuhz2oH/m04SLg3CDLlSX5Ek0Jso88LthCkBICM8Mg+8jjnDFjQmQCPvrrR9g9Yzeemyx0WZGHyQX/s0gl1n2jeFk8IkMiwTAMYkJjYCYWMOExgrK9JWGwMAxizGYwDIMoQvCG+jJ2j1hqVRCaG4Hzh4GGS9wyEVUQKF2eyKW2TDiwAQAxA7XnvHM/CsUPcLsfBng/6jIlobPhiEs1pVeMFC3WlYPKy5jbpENh5WWrokAsyC7K5uIosGmabQ0JQyQhiI+IR22L0OuhqrkKCbIE7J6xm/NTfXPGm0iQJaDK1CQoW0NakWAy4U1VFZRm65ZGFCRITZ6KqF//a9U637zZ+v9PhTT2AQWAtQ+IGbZ6w15Fa9BCHd4LsAkfC0YKdXgUTdpECVjc7ofyFNF+BPkgl+/Z2RhB3UmXKQmdDUccFx7HGYYUptyDNKP15ZxmNKMw5R5IGSlCpaGIC48D4HjVQq1XCyzC+RCzvSeDo90YEt7bKiiA9f+bt1n/3vNYm9ZJLMCexdblKkpA09lVNHfgrLi/WQX1jU8L5FR94wbkfLOK8+KhUAKJDvXD6L7AzS/Yj/cubjU486pg2+PL/bFLbRI6G46YNdJKVaRaX7y156zaXHRflGpKERceh4TIBIcGg3w/VgkhnAEiAChMJmiCgpAUkYCC1L8DMQOQ843VoEURruAMGAFwn5PCFSjocyOUKZlA0ijrFsObN9s3fP6n1nbWllm1Uj/bx/IGgbSv60geXTJsbbjkttzY1Tt+E5QtWqjDopDzbQeyjTpqQwfa1hMIJNntSYj3i0aow3q19Ysr478yIcNeptl3TnAEYNS5LPed6v8exudtEjobjjghMqHN4jS6LzBwAvcjpSpSudCYjlYtWHcvCSSQ2tQdBEAplUFeWw7Ze/Mhe3Uq5GYzlBFKBEmChGUlQVAGR0FeVwHZoU3AvzKBnwqtQgObSF0MA1T+ZLcFQQkcOryK9lNhh+TGLibJt6twQtZBBcFRGzrYNgqluxD0w76zoHx1CvDmzVC+OgUFfWchKSSaG/9FZTq6L1B33jreuyH3nY0R1N30yARPgONVi7N1Z/HwFw+gqqUGSUYjNmlqsEoRi4rgYCQYTXhFXYXBV2IhnA0OwSND0qBqrkJSRAI2Dbkbq868gwq9CgkmE15RtZUFIwXu3w+8Pg0A/5EyVkWhB1jGepJAm425vYrmAYvqTntTOGrD/futA2WAynSgyW5PQmvQQldbBuXOKTbyK4FaIoHMYkYU+0q0lelO9sku924SwedXEjqLO8YfYqsWap0aC79cyCkIBaoqpLcaUKCqQpLRCFVwEBYqFVBLpVBLpVjYJ9aqIIREo+DUT0j/6DEUnPoJSdIIqILaygKwWrtePAahggDr5wC2jKVYcXsVzQMW1Z32pnDUhgvHqExT/JKokCgomxtF5NcCpdnUpiAA9jLdyT7Z5d5NHsJvlARPGH9wy03hChTwPBOUZjOnKMjNFsgs1n9yswVJoXIUlP0OpcloLWsyoqC8DElGE1cWgFWj7DfW3goWkk5bxlK6ny63ThaxqNZKgqAOF9+SE2tDp70pHFl19xeRcyrTFH9BVK4lsN8qlkIb1YfrW7beQmqplOuTrvT/rvRu8iTdpyQ0XOJiCbhCZxNEAVYtckfmDhSkPcYpCCysorBDXYUoQhBFCHaoq1CQMJNTELiyJiMK+s7Cjss1Vs2TtXZNGmW1guUeqwSY/YJzy1g3nwOl6+kW62Qbi2qtJAgL/jTK6rHgQhs84k3hyKqblfMOWntTKN2KqFy/AMx+UXBMOzMPC75fj/lF83H/5/cLvIXUUilyEvrgvqHpmP9Nbrv9vyu9mzxNUPtFvMBPhW2ugozE+gNdCXHpCNb4g33QOZ/lCEJqurq3ExUShaiEDFi1RuHWgNJsERyLIkBUSiZQvNGmFgbK8UuA8UsEHha809ZqWMV0ZDaQMs2+bAeeA6XrsVVQxayi2XIuxcNw1SuAJze68CjUXvG2cdgGixm6c19Cx/PMSYpMQsGQ+VB+X4iCIfORc+ZNax1770ZBnxugTJlufek7apsj2XV0nELxNcT628hsoP4icPITYPjsK7JcBtz5DlBTBvQfC13vvqjd+y4qmzW4rFfDTCzIubQXedn/Qe73z6CipRpSQw3MrWZIIHHY/x15Mdi+z3zVeLHrDRedGX8A7Q6e7Rp/uDIAN1wCtl4Fe/sBG8WBYYA7/w28e4d9HQ98CUQphfdyx7ClB4X67Aj+Zvwl6OhGEzZpqrFKEWdNr+yut0AHFUOnbQiJ5rbFtBIpFvwpA7VSKQrqDFBWHG+rIykDOSGNkDc3cKtmGHE3cOs/qdLqIv4muwGNI5nOTwEcxMsBYC3bdzTUquPISYhHRXAwpGBgBhFkTTUTc7v9n12JrG2utSvX1WH7/SJ3g8NYAuMXAUdfcmmAcpggytVBzlEbxMi4Hzj+L/vjV90GnPxIeK/eyY7jJAyc4FobxMr2QPxxoFWrTiBn712o4OXxSDKaUDDrXSgT0tuvwBMeC47aoNYItsW0kiDobnwGyqKV9nVIpZBZLEIjrbveA/59V8Aqre7gj7IbkDjqbxOWAofzXa7GurVgVRRscXWC0NkYQZ7CP7wbxIxGIGlTEACnkQodGn+oTrge7dBRG8SMsfqOgij/+9D+XsEy1w26PBDqk9K1KFsasUkjnH1s0lRD2eKiLYInPBYctcHGbibKYoKy7CvxOsxmoYIAAGf3U48FSs/CUX87+Ylb1SjNZmzS1Iiec9U7obMxgrqTrlcSxIxGxv/dpQHKqfHH4SVQS5h263DYBtbAkDMkYKzGWDH9XPtexAwY9a4bdHUy1Cel61GH9cIqRZzg2CpFHNRhLnZwDyiGDtsQZDPLYaTAn11cLQOAwdOp0krpWTjqb8Nnu1WNWirFKkWs6Dl/8E7oLN3j3TAy27qMOf9T6/9j/tbuANVugqiWauQk9GmLWyBSh9M2jMwG/jiKNpsEYv3shrsM5IPE63X1OdD9X59FrVNbDQSDg5BkNGF3pRpJRhMqgoOQ862LA4WIYqidmQd1kG38z7Z78i2mnbYh5U9QB4Vw9eLmbcA184CkMcJKk8ZYbRD4jLgbGHYTVVopPQtHE7GpTwARcU4vBSMFksYIthqkV8Z86ZX6pIxU1DvBn5M5ieE7ERd/KrQu2RNz24/Je2m6ZPxhNmPH7z8iymISrcMpFT8Cr0+1P/7Al0DV/+zbBjhtL8U5/rSv651cCOegjeqDBd+vd8mgSWfUtd+GiAQUpD4KZcIo4cv91GfW7YTB063KAGCV94vHrLE97LwbqMeCM/xJdilwLNPfvgT89gnw59nAVbfy8jLoAfkgqIOkyNl7NyqaNZAyEpiJBUmRScibmIfcw7moaKqwM16UBct8xkhRjI7IUfe4QIrRjksVG+NAzPiDdSeRBcsQ1dxoX4crHg8Xjoofv3gMGPd3QBYPnPkCGHJD20BLXcACAjYIFwBh7oUrn9mO7yiDqR3RfYHovtDp1ELXSpHEL6xboyzuz8I2mMxASyOUEYq2NgRHQiYNFfkCCqD3QOv/LFFKQJlq/d8Ot+YNFEr342yMv9LfOCp+tI73/ccB4x9tux4E0GmAmrOAQQeZhIE8LBYWSTCiQ6OhNWjt3BcjQyLRaGjk+r+du7RYn4Yb7tI+gO+sJHgLVz0enK0k/PA68Ms7bcdYlzFKh/G32Zi3rJNtVykEsT94bo1gJNDOzIdu+M1QnvrCTqbVRi1knz+JKItZKOf//Zu97A4YJ94nqAukS/ib7PZ43JHb9vqDDVqJFLobn4bsmmy7/s/2e51RJ+j/Tvt0Nydz8g8XyK6kPZczvvYJAFuH29dx13uO4yTwl2kpbkEH2jZEY39EJKDg1E9CrwWHyZUkACEQxviQWgPDiMmuLTRpk1tQ2fUh3HErdjQRZCSiCkK79TnBF5I5ieEfLpBdiTOXM9tUt985WBk484X48YvHPNtWSsAimvhlyN12bo2OkysJI4VyZR3Jri1scjLqAknxN9xxK3a0pexMQXBWnxP8NZmTGD1bSXC0R2zQ2cdUOPoyRD0WHMVJYFcfKJROIhr748w74m6NosmVHHjbDLnBtQY4Sk5GXSApvo47bsX9x4nXYRczx/a8+/3AX5M5ieFbCZ7cSXbkqCz/uKNkTzVi2qcFGL/Q3l3GUZyEEBeN1CgUJziM/aFXibs1iiZXsk9Og5u3WQ1sxdwdZ2+nSZsoPQN34s0kjRLvD/zrbelAP/DnZE5i+E6CJ8B14xNHhiq2xzPX2+83sbMxsTwNYxZY//E9FhouiddBZ1gUPnyL6fZsVa7YwqjDewkTMYklfhmaioI+N0KZktlW78hsqwz+tscaMOmaedbj/IQ1bN+59Z/A8L8CZ/YDQ6Y798yhSZsovowjDwa+3NZfAC79CLQ0Ws+xqwcXjgLhvYE+VwE3/MNatu8o6yRQnmK1ybl4DAiLAVrqrcdCZG73A39P5iSGjyR4cmB45U5iJEeGV5lrgf1rwaVlnP2iVaDsEjwxwJL/iQtEOzEcKO7To4y/xCymHXm/8BRZQSImMZ/qT26HvPFK+nIwbcrw6zcAFd+11Zk0xjp48hPWRMQBK8qox4IX6FGy6y+4Ise2/cJl2K060uk+4kvJnMTwjzgJooYmIoYjrLGI7UvbkaGKqEGXGTj3FeyiKPZOBux8wYn4/QA6w6I4puJHoYIAWD+PfsB+RaHhksAWJspiDf6le+igfewPkxkFZb9DZjZdybNArIoqI7UfCMUGRn018OU/gCNb7HOMpEyjMkzxH2z6jagcn/qsgwoCIHgXdLKPuBzPx09iJOD/t3fvwVFU+R7Av5NkxiSTMCYmJoREQUEF2csbgvI2Bbj4LCzAK0+rQCx8YGEhUfe6gIDrrnV97ars7sVFjAsXXfcK3siKulJcpADxsbAqG8AyiUggkMl7JpncPzrd6Zk5PTM90zPTM/l+qrY2tD2ne2ZO9/z6nN85B2ZZ4CnQNMe+tJIRL9Mot2qv97YvKwBXi/4kLUc/aXVG3lxJLdAkXL4EAW62pwOFrYJpWuurUNjh9l6IqatT6mII1T/f44gFSnyhjGAIdSRPKCK8RhJ5MScRcyzwpJV4pZ4xMVgyos3uX+7g28X71lcxSYuMoZUxXVLqv01PJrbWvnoWbRp8K0csUOIL5boJdSRPKHiNeIlP4qJW871oW6jJiLlXSU/66jIazwDH/+J/fHm+enYhUKTkjGnfnARR8qIcIPvmtwRaJdR33xH3AEf+FFpOwrQnpMSsUI5HZFahXDfXzpSug3BzEiyQ8uJ4jfgx94yLWkmKZU8BH64NLZFQT1IZxUzSJX9pLZgkorXgjGiEhFa5R98E/rkLGHxLz+gG9YI18pz0SrmfSaN6OEtoxJKu7iaKQIuPySMffvwK+H4/UDAUyLhUum6a66TRPbkDpFFs6ZcCrRelLmp5BAOgWuCpOfA6PwksMRIX9dDqiyoaKY18CKUV4M5XpCSyUG/gROEoHhV63fJdcAYIf42FE5XSNTFyoRQYqIMDgKMbKHmIrhvAu47LvquU6vrZY971/9/mAV/92ft6GDBRek3VXl4rAuZuSQi06BJ/7BMan8ZUtOq5L71rLOiZ155CxrprIqI6rkjp7kYIYV0GoFdcK8m3doNWkqK7JXrH1DPrI5ERtEZI+NK7xoKeee2JEpGojis8oa/LwGtFk7m7G+Ss1ljNdsimWYoHrRESvtRrLIRyTcT6+iGKNVEdV4TYkiBfD7xWhMzdkqBnXu5IaU3YwRYFijatOeUjXWMhltcPUTz41nGZJRW47QX/+j/s38XXA68VTcbmJGjNrR2pQFmtwn3DOIdTn0rLRvtatKsnsYUMw35dAdFIBq26r/ua4FBfo7DumpBcx62ZUne0uq771v+goySS91qJ7+iGaDbVa2W1GnkObJqlaBAFrVqLQYlGSGjV/VCvCb37EsWCUQ+UcjlWO4AuILvQvzzf+h/oeuC14seYICGUubWjLdJz0DPRDVEoREHr9wc4bwf1bkY9UIqGPjKXzHDGBAmBMkNj9SNrxDlwIScyiiho/Z+H4LewmNZiUETJyKgHSt9yZFzEzHDGJC7qmZM+Wow6By7kREYQDs3SSP8RLQZFlIyMGmoYaOgjhy4aypggwajMUK05CkKZu4DZqWQmoqDVd6VTmWgxKKJkZNTDnPD6iqA80mRc4mKkTfVa/VR6+q/YXUBmoZXjIspJYFcD9RZG5X75liPjw6HhzDEts9b0sXqmoKWEYrphZHqyrUX7ar3+20pprftB06WV6gDtRZv0lEtxY7q6m4j0LnKm3qa+JgDvoY/yAk1We1Iv1BSuxF3gSaufKtAUtPziySh6WqtE+wLi16sXbTr8x56RDKKhjnrKJUp0oS5yBnhvKx4H1BwSXxMc7RAV5ggStOYo0DMFLVE49GRbC0csPOw99av8evvl3jc3QHskg/AcHpbWt5eTHZm1Tcms+oj4evHb72DP3+prAuBohygxx7TMWkmHeqagJQqHnmxrYUa1YBGZrk6pi0FENJJBeA4e+I2GYNY2JatQFznzFWiBJt99KCzmaEkAtJMOmYxI0aRnpk3hYjKCRWQsqVIOwuE/+pchGskgPIcU75aEQOdFlOhCXeTMV6AFmkT7kG7maEmQac1RwLkLKFr0DJ0V7StaRObW56UkRdGiTaKRDMJzeAG47UW2olHvoLXIme+24nGhLdAk43UTMXOMbggHs74TmukyxCNdMClQtrZoJEOk5VLcmK7uJhPR9eK7LZQFmkQLPVFY9Sgxg4RoLiZFMcEbLSUq1l1KVOHUI3N1N4RCKxs90GyMREREpFviBQlGzf1NREREASVekGCGxaSIiIh6gcQLEriQExERUUyYZ54EPTh3AhERUdQlZpAAiOf+JiIiIsMkXncDERERxQSDBCIiIhJikEBERERCDBKIiIhIiEECERERCTFIICIiIiEGCURERCSUuPMkEBERAejq6kJ7e3u8T8N0rFYrUlNTIyqDQQIRESW02tpaOJ3OeJ+G6VgsFhQXFyMrKyvsMhgkEBFRwuro6IDT6cRll12GPn36xPt0TKOrqwt1dXWorq7GoEGDwm5RYJBAREQJq6OjAwCQnZ2N9PT0OJ+NueTn5+P06dNwu91hBwlMXCQiw7S4OtB/zW70X7MbLa6OeJ8OCSTrd2SxWOJ9CqZjxGfCIIGIiJJeLIOjd999F2fPno3qMWKFQQIRRazF1dH9v07Vtk5lO8Ufv6PYSaYggTkJRBSxIf/xgd+20U9/qPx9+plZsTwdEuit35EcAPkGR7JMm76fwQMHDmDlypVIT0/H5MmTccMNN2DDhg3o7OzEgw8+iNLSUlRWVuLYsWMoKyvDmjVrMH/+fDidThQUFGDbtm04cuSIVxnr1q3DqlWrcOTIEbS0tGDz5s0YPny4Ie8/UgwSiIgoaRkdHL3//vv4xS9+gVtuuQUejwcTJkzAJ598grS0NEydOhVz5szBzJkz8eijj2Lo0KH49a9/jVmzZmH58uVYv3493nrrLfzrX//yKgMA1q9fj8zMTHz11Vf41a9+hTfffDOyN24QBglEFLHj62YAkJ7Q5Bvw4SfLkGmLbCIXMg6/I2OsWLECmzZtwo4dO1BWVoYTJ05g+vTpAIBz586hrq7Oa/+qqiosXboUADBmzBjs37/fq4x58+bh5z//OZ577jl88MEHSElJiXgCJCMxSCAiTS2uDuVJ7Pi6GZpNs6LtmbZU3U25FD2i70IOFuQAIhkZHRw5HA688MILcLlcGDVqFAYPHoy//e1vsFqtcLvdsFqtsFqt6OyUujQGDhyIQ4cOYdSoUTh06BAGDRrkV8a4ceOwa9cufPbZZ/j666/x0EMPGfPmDcArmIiIkpbRAexrr72Gd955B83NzVi8eDGGDh2KsrIypKSkID8/Hzt27MDNN9+MlStXYsaMGbj//vtxzz33oKKiAoWFhXjsscfwu9/9zquMnJwcFBQUYOrUqSgtLY30LRvK0tXV1aXnBU6nEw6HAw0NDZzdKkKhPqWZpVwjxaMese6GTp3sJXr6MmOdipVEr7vJ9t22tbXh1KlTGDBgQMDJlBLhvmg0388mnHqU/J8SEenWWzPhe4Pe+t1m2tKS9r1FE4OEODB6SE60yyUiot6JvxpxEK1Ivrc+IZDxmAmfvPjdkh4MEojIT7Bkr3NNbRj99F4AwOEnb0Jelv6FdUR9xFr9xkYcL5LzSjSi9/BDfTMmPvuJxiu6lM+//5rdXq+j3o01IAZ8L1g5kj/f1K5ctPtWT8FlWZdEdJxg5SbDzY+IiGKHvxJxIP84t9h65kvPMGBMebByOT876eWb7HWuqQ0AUN/sVrap/w7lCV+UO3O+yYUWWwdaffJpzje1AwBa3Z6wjxeqZMjpEb2HEz81IsOaiu/Pt2i+rr5J+kx9P39ZIrz3RPLFF1/gwIEDuP/++0Pa//Tp03j00Uexc+fOKJ+ZP37zUaR105G3t7p6bnytLo+yPdLERd9y5Rs7YFHtyxsA6Sc3+atN/89Plb9DyXsR5c5MfPZjwbE+9NsWzvFClQw5PaL3cPtv/y/o66Y//6nftkR77yFpqAHqq4DcqwFHv5gc0uPxICXFey3F4cOHR2VtBnlGAyOXzeavQwj09J2qt4to3fhEN0m9XQKh3nx9zyNpbgBERFo+3wq89zDQ5QEsKcCtLwAjF+ouZsWKFVi0aBHGjh2LyspK7N27Fz/++CNqa2uRlZWFbdu2ob6+HgsWLEBhYSHGjBkDp9OJjz76CGlpaXj22WfR1taGXbt24Te/+Q3ef/99rF+/HjabDffddx/mzJmDhQsXoqamBna7Hdu2bfM6/t69e/HEE0+gq6sLy5cvx5IlS7B48WJkZGTgu+++w86dO5GTk2PUp8YggYhCd/jJmwBITf7yE/2eRyYh124NuQxRdv2+1VORYUtBq6tTyac5/GQZWuXWMbcn7ONFcl6JlvUveg9/XXGD0t2w9I0jwtftWTkJuVlWv88/kd57QA01PQECIP3/eyuBq2/S3aIwb948bN++HWPHjsWOHTswbNgwDB48GPfeey/efvttbN68GXfddRdqa2uxd+9e2Gw2jBkzBgcOHEBaWho8Hg8+/VSqyx6PB+Xl5di/fz+ysrLg8Xjw9ttv44orrkBFRQXeeOMNvPTSS1i0aJFy/Mcffxy7d++Gw+FAaWkp5s2bBwAYPXo0XnnlFUM+LjUGCQEE6js9XtOgbPu65iKuzs/q/ldPM8++1VOQYUtFq8ujPNEffrIM9d39rN+dacADf/4KAPDcXUPxs+IcXGhxYe7mg93Hage6i9VqUVBnLP91xQ3ol5OB2gttuO23+wEA/7PiRuR031AzbGkh3/wiTXJkkmRyEuUA5NqtunIDRHXhsiyb0kLXs18q8rqTbnu6zPQfL5LzSrT1J0TnOqggG5m2NGQEuN6LczOEn38ivfeA6qt6AgRZVydQf1J3kDBhwgSsXr0a7e3tqKqqQnp6Og4dOoStW7fC7XZj4sSJAIBhw4bBZrMBAJ5++mncd999SEtLw9q1a5Wy6urqUFJSgqws6UafkpKCqqoqjBkzBoC0INSePXu8ju/xeJCXlwcAGDRoEGpra5V9oyFJakB0hNp8P/e1g8LXi4YbZdpSMfr5fX7bV+38R8DXh9IlIOp7lIMFwHsRl6S6AcSZmQOiaJ2bOsFN/XekQxXlREX578xc83yWiUT9OX5dfVF58NDS4uowVb01XO7VUheDOlCwpAK5V+kuymKxoLS0FGvXrsX06dORnZ2N8ePHY8GCBQAAt9uNmpoarzyESZMmYcaMGaioqMDmzZsxadIkAEB+fj6qq6vR3NwMu90Oj8ejLAg1e/ZsZUEotZSUFJw7dw4OhwMnTpxAUVGRsj0akrhWJLcf6psBALUNbUH21CfSDO9kyBCn4NTDdcMduiuaJlf9tKv+Oy8rPWa5M8kwfa/6s0u3+rcgyA8McgApX5fJ8N6FHP2kHIT3VkotCJZU4Nbnw05enDt3LiZMmIBvv/0W/fr1w7Jly7BlyxYAwKpVq3D99dd77X/HHXegtbUV7e3t+MMf/oDz588DkH7YN2zYgGnTpiEzMxNLly7FnDlz8M4772DSpEmw2+1488034XQ6lbI2btyIWbOk7+iBBx5ARkZGWO8hVLxjq2jNZ3DibCNufzl4hjAg9a3KrQ37Vk/FZVk2tLg6hFnhkZyb9qQo2kK5AQTL8JZpPZUmQ4Z4qMwcEMV66u9IhyoaMbSSxJ/jsdoGv/3+UX0RfS/NVP5tlnobVSMXSjkI9SelFoQIRjeUlpaio6Ona2br1q1++6iHK37wgf99ccqUKQCAWbNmKT/6soqKCq9/5+bmKuXddNNNOHjQu2Xo9ddf13X+eiRpbTCGfLFkpIWevJNhS/H6O2kvODJ1QBSvqb/V9AxVNGJoJYk/x8f/csxv2xyf7gez1Nuoc/SL2dDHZMFfMGg/HVXXS5OP/OjsadLfeMcQ9MvJxOm6Jjy16xsAwEt3D8cVuVJUru6frW9y+W1rcXVi+7JxAIDjPzZi7XvHAQArp12FIUUO1Fxsw9pd/wQA/OneMejbJ114bntWSskxF1rdmPvaZwCArUvGoNCR7pX8KLdmhCrUzHOtJ49kyBAnIiKJaYKEeCZ/6Xk6evzd437bri3IxnRBMqJom1a5z3900m/bov86JNxXXca+1VOUvwfk21GSa/fKUJazxoHQPmPRtmAT3aifPJIhQzxUZg6IonVuWuVGOlTRiKGVJP4cN955vV9rwo5l49D30kyvUVdmqLdkPsl35yaKETMFRFoBoNwaBgD1Te3IK+yDc01tyr7qEQhf/nBBGSHz1xU3YFhJjma5h06dV8o9VnMRk68tUMqQtbo6kFeQjXNNbcqiQerjiUZCqFvdMqwpAXMR9DxYmHkESiR83xfg3+Vw8myj3+t8uxu4wBNpiXsNMEPyl9bTUc0F6Qb7U2M7lm2VJiHZvHAU+nd3LVxT2EcpQ36iP1XXjIVbpBaA388fiSvz7Ghzd+K27puv1lPX5vkj4Mi0obq+Fat2fqUcqyBbyhzvl5MpfCIUJSP6bgv0GauTKtU3BXUZ6teH+lSatFnSRJRQGl2NaHY3o9Be6PffzjSfgd1qR7YtOw5nlhjiHiSYIflL64lQNO+AHCwA3ucmGm2wdNvnwnJFE8Qs23Y04LEimeNAT3eKiJmemM0ongFRsHyaC609We7fn29Bq7sTF1tcyrb6ZjeOdU8MVtfUs/0ftU60uTvR5vYuV25BOHmup4Xi5LkWOFt/AABc7ujJmP/J2Y4vf7iABp/jybk6UM0vX3uhDa2uTu+WBNXkPuq6pufBwgwPIdEgel/V9S349oz/SIbDpy/4bfP1+el6jOyfm3QLPDW6GrH8w+Wob63HlplbvAKFM81nsKRyCXIzcvFq2athBwqVlZVobW3FnXfeGXTfYAs7vf7667j22msxfvz4sM4lGhLzm6eoSIabQm+jJwAUTcmrHkGg9sRf/Cf30ipXTr71tUzH8dSTfomOpw7C9DxYmOEhJBpE70uUAwUAX9T4dzf4Ej2kJMPn1OxuRn1rPaqbqrGkcokSKMgBQnVTtbJfuEHCzJkz/baJFnUCgi/stHjx4rDOIZri/ktgpuQv3ydC+dzON7UrLQX7Vk8Ja/IY0UWmniBGPb5ZlLgVydOq6DMWCXZTYBcCESWSQnshtszcogQESyqXYNPETSjfV47qpmoUZxX7tTAE47vA09KlS/HYY4/hgQcewJAhQzB69Gjk5+dj/vz5WLp0KYqKimCxWPDII48AgLKw08iRIzF27FgcPXoUd9xxB8rLy/HLX/4So0ePxi233IINGzZg9+7dsFqteOWVV1BTU4ONGzeiqakJs2fPxpo1a6L1sXmJe5Bg5qZsZVSArWe0QEaUzs2IOfG1mOGzpOjQCrLl9UHUQ2R/v2AULu9zCS62uLBoy2EAUiD640Wp66CuyYVH/1vKh9lw51AMzJfyaeR9Dz9ZhmM1FwFIXQxyC8JTtw5Bnl2qY5c7MpXjbV4wCgV9LkFDiwsLVcdD93K2sFiUgFheY6TV1ak8EWs9LOh5sDDTQ4iRRO9rz8qJ+PZMAx7sXg9GNrxfdtDWhM3zRyjdDcm2wJNvoLDgf6Xpk8MJEAD/BZ7WrFmjLNFcXV2N/fv3IycnB7NmzUJFRQUGDRqEyZMn+5Vz8eJFlJeXo6SkBCNGjEB5ebny37788kscPnwY+/fvh8VigcfjQf/+/fHxxx+jq6sL48ePx8MPPxz12RYBEwQJZib3+7W6emaRa3V5hP2k8kVbXd+i3OT2rJyI4tyePtpIz8XI7OzDT97Unc2cXDfP3kYryM7rTqpVjza4vM8lGFaS4zcCQTQyYWhRH2V0g7pced906zll+5C+2Rh3lbTgjDxdOAAM7puNkly75uJM6u1FOenIy0oPaYGhYA8Wwa4VszyEREJ0/lrdDTf/rG/QIGHCNZcn9QJPhfZCbJq4SQkQAGDTxE26AwTAf4GnSZMmoampCQAwcOBAZZnms2fP4pprrgEAjBo1yq+cnJwcXHnllQDg92P/zTff4MYbb4SlO28nJSUFR48exVNPPQW3242TJ0/i7NmzyuujyTQ1wIxN2cEWeBLND6AOCopzM3VfZNGcoz7YZ5xMNwUiItmZ5jMo31futa18X3lYLQm+CzypqfMQCgoKcOLECQwcOBCff/45br/9dr9ytFx33XXYvn278m+Px4NnnnkGL774Iq677jqMHTtWab2INv4imFyyZmeTsXwDQPkpPUNVPxpaXPjyhwv4ydmzQmBbh0d5+h9WkhN0OK1s3FV5wu0luXa/7VqBr2i7nocFPUN9gcRNvgvm+LoZwhZBeWXHr6sv+r3m5XnDcU2hlKinHsptxoe1SKmTFIuzir1yEtTJjHqoF3jat0/cgrNu3TrcfffdKCwsRFZWFqxWK9xut3BfX8OGDcOIESMwfvx4ZGRk4OWXX8bs2bMxd+5cXH/99bDb7brONxKWLp3hiNPphMPhQENDA/r06RP8BQks2PwAsfiBlic20ZKoF3Q86lFvqrvB6o1IotYlWayuFTPV3XC+Z1+J/r23tbXh1KlTGDBgANLTvXO4fAME0eiGcHMTgnG73bBarfB4PJg2bRreeust9O3b19BjBOP72YRTd6OzAHWSyLSldf8vVbUtVdlORETmZbfakZuR6xcIyMmMxVnFyM3Ihd1q/JP5wYMHMXnyZIwbNw5lZWUxDxCMwl86k0vW7GyKLtEc/luXjIYj04afnO3KHAbb7ytFkSM5lmHujddKoPes7m6Y6zMNs7q7IZll27LxatmrwhkX5UAhWjMuTpgwAX//+98NLzfWGCSEIJ79dGYeIkrmJRo6O6SfA3lZ6V4jEIoc6SjJjV3/ZjT1xmsl0HuW/9vPii/12+eawmyvXIRkoNVznm3L1gwCjO5iMBsjkhuT9+ohIqKkl5Ym/Yw1NjYGHDHQ23R1daGurg4WiwVWa/irqTJxkeLCTMlfRHqw7ppPTU0NnE5nvE/DdCwWC4qLi5GVlQUgvHrElgQiIkpoRUVFyMvLi9ncAYnCarUiNTWynBwGCURElNAsFgsuuUT/mjoUnO4gQY7U2LRDkZDrTywjf9ZdMgLrLiWqcOqu7iChsVGaA7ykpETvS4n8NDY2wuFwxOxYAOsuGYN1lxKVnrqrO3HR4/GgtrYW2dnZzCSlsHV1daGxsRFFRUXCddejgXWXjMC6S4kqnLqrO0ggIiKi3oHTMhMREZEQgwQiIiISYpBAREREQgwSiIiISIhBAhEREQkxSCAiIiIhBglEREQk9P+VZgX7WsEywgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "from typing import Dict, List\n",
    "from scratch.linear_algebra import Vector\n",
    "import csv\n",
    "def parse_iris_row(row: List[str]) -> LabeledPoint:\n",
    "    \"\"\"\n",
    "    sepal_length, sepal_width, petal_length, petal_width, class\n",
    "    \"\"\"\n",
    "    print(row)\n",
    "    measurements = [float(value) for value in row[:-1]]\n",
    "    # class is e.g. \"Iris-virginica\"; we just want \"virginica\"\n",
    "    label = row[-1].split(\"-\")[-1]\n",
    "    return LabeledPoint(measurements, label)\n",
    "    \n",
    "points_by_species: Dict[str, List[Vector]] = defaultdict(list)\n",
    "with open('iris.data') as f:\n",
    "    reader = csv.reader(f)\n",
    "    \n",
    "    iris_data = [parse_iris_row(row) for row in reader]\n",
    "    \n",
    "for iris in iris_data:\n",
    "    points_by_species[iris.label].append(iris.point)\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "metrics = ['sepal length', 'sepal width', 'petal length', 'petal width']\n",
    "pairs = [(i, j) for i in range(4) for j in range(4) if i < j]\n",
    "marks = ['+', '.', 'x'] # we have 3 classes, so 3 markers\n",
    "fig, ax = plt.subplots(2, 3)\n",
    "for row in range(2):\n",
    "    for col in range(3):\n",
    "        i, j = pairs[3 * row + col]\n",
    "        ax[row][col].set_title(f\"{metrics[i]} vs {metrics[j]}\", fontsize=8)\n",
    "        ax[row][col].set_xticks([])\n",
    "        ax[row][col].set_yticks([])\n",
    "        for mark, (species, points) in zip(marks, points_by_species.items()):\n",
    "            xs = [point[i] for point in points]\n",
    "            ys = [point[j] for point in points]\n",
    "            ax[row][col].scatter(xs, ys, marker=mark, label=species)\n",
    "ax[-1][-1].legend(loc='lower right', prop={'size': 6})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ac595e47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "105\n",
      "45\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from scratch.machine_learning import split_data\n",
    "random.seed(12)\n",
    "iris_train, iris_test = split_data(iris_data, 0.70)\n",
    "print(len(iris_train) == 0.7 * 150)\n",
    "print(len(iris_test) == 0.3 * 150)\n",
    "print(len(iris_train))\n",
    "print(len(iris_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1c890bb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9777777777777777 defaultdict(<class 'int'>, {('setosa', 'setosa'): 13, ('versicolor', 'versicolor'): 15, ('virginica', 'virginica'): 16, ('virginica', 'versicolor'): 1})\n"
     ]
    }
   ],
   "source": [
    "from typing import Tuple\n",
    "# track how many times we see (predicted, actual)\n",
    "confusion_matrix: Dict[Tuple[str, str], int] = defaultdict(int)\n",
    "num_correct = 0\n",
    "for iris in iris_test:\n",
    "    predicted = knn_classify(5, iris_train, iris.point)\n",
    "    actual = iris.label\n",
    "    if predicted == actual:\n",
    "        num_correct += 1\n",
    "    confusion_matrix[(predicted, actual)] += 1\n",
    "pct_correct = num_correct / len(iris_test)\n",
    "print(pct_correct, confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9fc332b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Curse of Dimensionality: 100%|| 100/100 [00:46<00:00,  2.17it/s]\n"
     ]
    }
   ],
   "source": [
    "def random_point(dim: int) -> Vector:\n",
    "    return [random.random() for _ in range(dim)]\n",
    "\n",
    "def random_distances(dim: int, num_pairs: int) -> List[float]:\n",
    "    return [distance(random_point(dim), random_point(dim)) for _ in range(num_pairs)]\n",
    "\n",
    "import tqdm\n",
    "dimensions = range(1, 101)\n",
    "avg_distances = []\n",
    "min_distances = []\n",
    "random.seed(0)\n",
    "for dim in tqdm.tqdm(dimensions, desc=\"Curse of Dimensionality\"):\n",
    "    distances = random_distances(dim, 10000) # 10,000 random pairs\n",
    "    avg_distances.append(sum(distances) / 10000) # track the average\n",
    "    min_distances.append(min(distances)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7801346d",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_avg_ratio = [min_dist / avg_dist\n",
    " for min_dist, avg_dist in zip(min_distances, avg_distances)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b946db5a",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3304cb73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'first', 'dsa', 'hour', \"today's\", 'is'}\n"
     ]
    }
   ],
   "source": [
    "from typing import Set\n",
    "import re\n",
    "def tokenize(text: str) -> Set[str]:\n",
    "    text = text.lower() # Convert to lowercase,\n",
    "    all_words = re.findall(\"[a-z0-9']+\", text) # extract the words, and\n",
    "    return set(all_words) # remove duplicates.\n",
    "print(tokenize(\"Today's first hour is DSA\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0f99bbf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import NamedTuple\n",
    "class Message(NamedTuple):\n",
    "    text: str\n",
    "    is_spam: bool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1de52b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple, Dict, Iterable\n",
    "import math\n",
    "from collections import defaultdict\n",
    "class NaiveBayesClassifier:\n",
    "    def __init__(self, k: float = 0.5) -> None:\n",
    "        self.k = k # smoothing factor\n",
    "        self.tokens: Set[str] = set()\n",
    "        self.token_spam_counts: Dict[str, int] = defaultdict(int)\n",
    "        self.token_ham_counts: Dict[str, int] = defaultdict(int)\n",
    "        self.spam_messages = self.ham_messages = 0\n",
    "        \n",
    "        \n",
    "    def train(self, messages: Iterable[Message]) -> None:\n",
    "        for message in messages:\n",
    "        # Increment message counts\n",
    "            if message.is_spam:\n",
    "                self.spam_messages += 1\n",
    "            else:\n",
    "                self.ham_messages += 1\n",
    "        # Increment word counts\n",
    "            for token in tokenize(message.text):\n",
    "                self.tokens.add(token)\n",
    "                if message.is_spam:\n",
    "                    self.token_spam_counts[token] += 1\n",
    "                else:\n",
    "                    self.token_ham_counts[token] += 1\n",
    "                    \n",
    "                    \n",
    "    def _probabilities(self, token: str) -> Tuple[float, float]:\n",
    "        \"\"\"returns P(token | spam) and P(token | ham)\"\"\"\n",
    "        spam = self.token_spam_counts[token]\n",
    "        ham = self.token_ham_counts[token]\n",
    "        p_token_spam = (spam + self.k) / (self.spam_messages + 2 * self.k)\n",
    "        p_token_ham = (ham + self.k) / (self.ham_messages + 2 * self.k)\n",
    "        return p_token_spam, p_token_ham\n",
    "    \n",
    "    def predict(self, text: str) -> float:\n",
    "        text_tokens = tokenize(text)\n",
    "        log_prob_if_spam = log_prob_if_ham = 0.0\n",
    "        # Iterate through each word in our vocabulary\n",
    "        for token in self.tokens:\n",
    "            prob_if_spam, prob_if_ham = self._probabilities(token)\n",
    "            # If *token* appears in the message,\n",
    "            # add the log probability of seeing it\n",
    "            if token in text_tokens:\n",
    "                log_prob_if_spam += math.log(prob_if_spam)\n",
    "                log_prob_if_ham += math.log(prob_if_ham)\n",
    "            # Otherwise add the log probability of _not_ seeing it,\n",
    "            # which is log(1 - probability of seeing it)\n",
    "            else:\n",
    "                log_prob_if_spam += math.log(1.0 - prob_if_spam)\n",
    "                log_prob_if_ham += math.log(1.0 - prob_if_ham)\n",
    "        prob_if_spam = math.exp(log_prob_if_spam)\n",
    "        prob_if_ham = math.exp(log_prob_if_ham)\n",
    "        return prob_if_spam / (prob_if_spam + prob_if_ham)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9142aef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [Message(\"spam rules\", is_spam=True),\n",
    "            Message(\"ham rules\", is_spam=False),\n",
    "            Message(\"hello ham\", is_spam=False)]\n",
    "model = NaiveBayesClassifier(k=0.5)\n",
    "model.train(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1b4c7f9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'spam', 'hello', 'rules', 'ham'}\n",
      "1\n",
      "2\n",
      "defaultdict(<class 'int'>, {'spam': 1, 'rules': 1})\n",
      "defaultdict(<class 'int'>, {'rules': 1, 'ham': 2, 'hello': 1})\n"
     ]
    }
   ],
   "source": [
    "print(model.tokens)# == {\"spam\", \"ham\", \"rules\", \"hello\"}\n",
    "print(model.spam_messages)# == 1\n",
    "print(model.ham_messages)# == 2\n",
    "print(model.token_spam_counts)# == {\"spam\": 1, \"rules\": 1}\n",
    "print(model.token_ham_counts)# == {\"ham\": 2, \"rules\": 1, \"hello\": 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5b9b4540",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"hello spam\"\n",
    "probs_if_spam = [\n",
    "    (1 + 0.5) / (1 + 2 * 0.5), # \"spam\" (present)\n",
    "    1 - (0 + 0.5) / (1 + 2 * 0.5), # \"ham\" (not present)\n",
    "    1 - (1 + 0.5) / (1 + 2 * 0.5), # \"rules\" (not present)\n",
    "    (0 + 0.5) / (1 + 2 * 0.5) # \"hello\" (present)\n",
    "]\n",
    "probs_if_ham = [\n",
    "    (0 + 0.5) / (2 + 2 * 0.5), # \"spam\" (present)\n",
    "    1 - (2 + 0.5) / (2 + 2 * 0.5), # \"ham\" (not present)\n",
    "    1 - (1 + 0.5) / (2 + 2 * 0.5), # \"rules\" (not present)\n",
    "    (1 + 0.5) / (2 + 2 * 0.5), # \"hello\" (present)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "221799f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_if_spam = math.exp(sum(math.log(p) for p in probs_if_spam))\n",
    "p_if_ham = math.exp(sum(math.log(p) for p in probs_if_ham))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "13cf3ea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8350515463917525\n"
     ]
    }
   ],
   "source": [
    "print(model.predict(text))# == p_if_spam / (p_if_spam + p_if_ham)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2eeab58e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\AppData\\Local\\Temp\\ipykernel_9148\\2898610848.py:19: DeprecationWarning: Python 3.14 will, by default, filter extracted tar archives and reject files or modify their metadata. Use the filter argument to control this behavior.\n",
      "  tf.extractall(OUTPUT_DIR)\n"
     ]
    }
   ],
   "source": [
    "from io import BytesIO # So we can treat bytes as a file.\n",
    "import requests # To download the files, which\n",
    "import tarfile # are in .tar.bz format.\n",
    "BASE_URL = \"https://spamassassin.apache.org/old/publiccorpus\"\n",
    "FILES = [\"20021010_easy_ham.tar.bz2\",\n",
    "         \"20021010_hard_ham.tar.bz2\",\n",
    "         \"20021010_spam.tar.bz2\"]\n",
    "# This is where the data will end up,\n",
    "# in /spam, /easy_ham, and /hard_ham subdirectories.\n",
    "# Change this to where you want the data.\n",
    "OUTPUT_DIR = 'spam_data'\n",
    "for filename in FILES:\n",
    "    # Use requests to get the file contents at each URL.\n",
    "    content = requests.get(f\"{BASE_URL}/{filename}\").content\n",
    "    # Wrap the in-memory bytes so we can use them as a \"file.\"\n",
    "    fin = BytesIO(content)\n",
    "    # And extract all the files to the specified output dir.\n",
    "    with tarfile.open(fileobj=fin, mode='r:bz2') as tf:\n",
    "        tf.extractall(OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a7dda958",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob, re\n",
    "path = 'spam_data/*/*'\n",
    "data: List[Message] = []\n",
    "# glob.glob returns every filename that matches the wildcarded path\n",
    "for filename in glob.glob(path):\n",
    "    is_spam = \"ham\" not in filename\n",
    "    # There are some garbage characters in the emails; the errors='ignore'\n",
    "    # skips them instead of raising an exception.\n",
    "    with open(filename, errors='ignore') as email_file:\n",
    "        for line in email_file:\n",
    "            if line.startswith(\"Subject:\"):\n",
    "                subject = line.lstrip(\"Subject: \")\n",
    "                data.append(Message(subject, is_spam))\n",
    "                break # done with this file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bf905736",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from scratch.machine_learning import split_data\n",
    "random.seed(0) # just so you get the same answers as me\n",
    "train_messages, test_messages = split_data(data, 0.75)\n",
    "model = NaiveBayesClassifier()\n",
    "model.train(train_messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "51bcc9ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({(False, False): 670, (True, True): 86, (True, False): 40, (False, True): 29})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "predictions = [(message, model.predict(message.text))\n",
    "               for message in test_messages]\n",
    "# Assume that spam_probability > 0.5 corresponds to spam prediction\n",
    "# and count the combinations of (actual is_spam, predicted is_spam)\n",
    "confusion_matrix = Counter((message.is_spam, spam_probability > 0.5)\n",
    "                           for message, spam_probability in predictions)\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "276334f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spammiest_words ['assistance', '95', 'attn', 'clearance', 'per', 'money', 'rates', 'sale', 'systemworks', 'adv']\n",
      "hammiest_words ['spambayes', 'users', 'razor', 'zzzzteana', 'sadev', 'apt', 'perl', 'ouch', 'spamassassin', 'bliss']\n"
     ]
    }
   ],
   "source": [
    "def p_spam_given_token(token: str, model: NaiveBayesClassifier) -> float:\n",
    "    # We probably shouldn't call private methods, but it's for a good cause.\n",
    "    prob_if_spam, prob_if_ham = model._probabilities(token)\n",
    "    return prob_if_spam / (prob_if_spam + prob_if_ham)\n",
    "words = sorted(model.tokens, key=lambda t: p_spam_given_token(t, model))\n",
    "print(\"spammiest_words\", words[-10:])\n",
    "print(\"hammiest_words\", words[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d340a69",
   "metadata": {},
   "source": [
    "# Simple Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "947f27d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Should find for a line y = 3x - 5\n",
      "Co-efficients of c and m are: \n",
      "-5.0 3.0\n",
      "True\n",
      "Check whether alpha and beta lies in context or not\n",
      " \n",
      "Checking whether 22.9 < alpha < 23.0 and 0.9 < beta < 0.905\n",
      "\n",
      "Co-efficients of c and m are: \n",
      "22.947552413468976 0.9038659456058725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 13196.619: 100%|| 10000/10000 [00:18<00:00, 531.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guess(alpha, beta) is : \n",
      "[22.947552155340915, 0.9038659662765034]\n",
      "Final alpha beta are as follows\n",
      "22.947552155340915 0.9038659662765034\n",
      "Alpha lies between 22.9 < alpha < 23.0 \n",
      "True\n",
      "Beta lies between 0.9 < beta < 0.905 \n",
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def predict(alpha: float, beta: float, x_i: float) -> float:\n",
    "    return beta * x_i + alpha\n",
    "\n",
    "def error(alpha: float, beta: float, x_i: float, y_i: float) -> float:\n",
    "    \"\"\"\n",
    "    The error from predicting beta * x_i + alpha\n",
    "    when the actual value is y_i\n",
    "    \"\"\"\n",
    "    return predict(alpha, beta, x_i) - y_i\n",
    "\n",
    "from scratch.linear_algebra import Vector\n",
    "\n",
    "def sum_of_sqerrors(alpha: float, beta: float, x: Vector, y: Vector) -> float:\n",
    "    return sum(error(alpha, beta, x_i, y_i) ** 2\n",
    "               for x_i, y_i in zip(x, y))\n",
    "\n",
    "from typing import Tuple\n",
    "from scratch.linear_algebra import Vector\n",
    "from scratch.statistics import correlation, standard_deviation, mean\n",
    "\n",
    "def least_squares_fit(x: Vector, y: Vector) -> Tuple[float, float]:\n",
    "    \"\"\"\n",
    "    Given two vectors x and y,\n",
    "    find the least-squares values of alpha and beta\n",
    "    \"\"\"\n",
    "    beta = correlation(x, y) * standard_deviation(y) / standard_deviation(x)\n",
    "    alpha = mean(y) - beta * mean(x)\n",
    "    print(\"Co-efficients of c and m are: \")\n",
    "    print(alpha,beta)\n",
    "    return alpha, beta\n",
    "\n",
    "x = [i for i in range(-100, 110, 10)]\n",
    "y = [3 * i - 5 for i in x]\n",
    "\n",
    "# Should find that y = 3x - 5\n",
    "print(\"Should find for a line y = 3x - 5\")\n",
    "print(least_squares_fit(x, y) == (-5, 3))\n",
    "\n",
    "from scratch.statistics import num_friends_good, daily_minutes_good\n",
    "\n",
    "\n",
    "print(\"Check whether alpha and beta lies in context or not\\n \")\n",
    "print(\"Checking whether 22.9 < alpha < 23.0 and 0.9 < beta < 0.905\\n\")\n",
    "\n",
    "alpha, beta = least_squares_fit(num_friends_good, daily_minutes_good)\n",
    "assert 22.9 < alpha < 23.0\n",
    "assert 0.9 < beta < 0.905\n",
    "\n",
    "from scratch.statistics import de_mean\n",
    "\n",
    "def total_sum_of_squares(y: Vector) -> float:\n",
    "    \"\"\"the total squared variation of y_i's from their mean\"\"\"\n",
    "    return sum(v ** 2 for v in de_mean(y))\n",
    "\n",
    "def r_squared(alpha: float, beta: float, x: Vector, y: Vector) -> float:\n",
    "    \"\"\"\n",
    "    the fraction of variation in y captured by the model, which equals\n",
    "    1 - the fraction of variation in y not captured by the model\n",
    "    \"\"\"\n",
    "    return 1.0 - (sum_of_sqerrors(alpha, beta, x, y) /\n",
    "                  total_sum_of_squares(y))\n",
    "\n",
    "rsq = r_squared(alpha, beta, num_friends_good, daily_minutes_good)\n",
    "\n",
    "assert 0.328 < rsq < 0.330\n",
    "\n",
    "def main():\n",
    "    import random\n",
    "    import tqdm\n",
    "    from scratch.gradient_descent import gradient_step\n",
    "   \n",
    "    num_epochs = 10000\n",
    "    random.seed(0)\n",
    "   \n",
    "    guess = [random.random(), random.random()]  # choose random value to start\n",
    "   \n",
    "    learning_rate = 0.00001\n",
    "   \n",
    "    with tqdm.trange(num_epochs) as t:\n",
    "        for _ in t:\n",
    "            alpha, beta = guess\n",
    "   \n",
    "            # Partial derivative of loss with respect to alpha\n",
    "            grad_a = sum(2 * error(alpha, beta, x_i, y_i)\n",
    "                         for x_i, y_i in zip(num_friends_good,\n",
    "                                             daily_minutes_good))\n",
    "   \n",
    "            # Partial derivative of loss with respect to beta\n",
    "            grad_b = sum(2 * error(alpha, beta, x_i, y_i) * x_i\n",
    "                         for x_i, y_i in zip(num_friends_good,\n",
    "                                             daily_minutes_good))\n",
    "   \n",
    "            # Compute loss to stick in the tqdm description\n",
    "            loss = sum_of_sqerrors(alpha, beta,\n",
    "                                   num_friends_good, daily_minutes_good)\n",
    "            t.set_description(f\"loss: {loss:.3f}\")\n",
    "   \n",
    "            # Finally, update the guess\n",
    "            guess = gradient_step(guess, [grad_a, grad_b], -learning_rate)\n",
    "   \n",
    "    # We should get pretty much the same results:\n",
    "    alpha, beta = guess\n",
    "    print(\"Guess(alpha, beta) is : \")\n",
    "    print(guess)\n",
    "    print(\"Final alpha beta are as follows\")\n",
    "    print(alpha,beta)\n",
    "\n",
    "    print(\"Alpha lies between 22.9 < alpha < 23.0 \")\n",
    "    alpha, beta = guess\n",
    "    print(22.9 < alpha < 23.0)\n",
    "    print(\"Beta lies between 0.9 < beta < 0.905 \")\n",
    "    alpha, beta = guess\n",
    "    print(0.9 < beta < 0.905)\n",
    "   \n",
    "if __name__ == \"__main__\": main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5464166",
   "metadata": {},
   "source": [
    "# Multiple Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1eeb06fb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "least squares fit: 100%|| 5000/5000 [00:04<00:00, 1143.42it/s]\n",
      "least squares fit: 100%|| 5000/5000 [00:06<00:00, 745.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bootstrap sample [30.49402029547431, 1.0393791030498782, -1.9516851948558498, 0.7483721251697389]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "least squares fit: 100%|| 5000/5000 [00:06<00:00, 789.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bootstrap sample [30.149963287526045, 1.0005300432763113, -2.0650380122822547, 3.1771798548347974]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "least squares fit: 100%|| 5000/5000 [00:06<00:00, 740.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bootstrap sample [29.202826897693726, 1.0017089956376213, -1.529424842478737, 0.9528580285760827]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "least squares fit: 100%|| 5000/5000 [00:06<00:00, 827.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bootstrap sample [31.294812174718512, 0.9592647294941009, -1.9120875473727548, 0.039471107599515415]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "least squares fit: 100%|| 5000/5000 [00:06<00:00, 786.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bootstrap sample [32.12414422794996, 0.8569794405277469, -1.9936770520754088, 1.0416943131372982]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "least squares fit: 100%|| 5000/5000 [00:06<00:00, 741.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bootstrap sample [31.8691994453096, 0.7748022870492418, -2.0087625702876446, -1.2407036547656687]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "least squares fit: 100%|| 5000/5000 [00:06<00:00, 801.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bootstrap sample [31.081197596502076, 0.9983862543869182, -1.9833984114987815, 0.9567646217580406]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "least squares fit: 100%|| 5000/5000 [00:06<00:00, 825.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bootstrap sample [29.254530450577782, 0.9763387220017683, -1.7430339427043593, 1.9944240584590915]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "least squares fit: 100%|| 5000/5000 [00:06<00:00, 757.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bootstrap sample [31.649174199331632, 0.9389340937491032, -1.9733848473304207, -0.15249287969349373]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "least squares fit: 100%|| 5000/5000 [00:07<00:00, 691.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bootstrap sample [30.040109260720964, 1.0531247386421572, -1.769487856035439, 1.302971911084249]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "least squares fit: 100%|| 5000/5000 [00:04<00:00, 1231.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bootstrap sample [29.066927054721287, 1.2792640005590377, -1.9373399049478555, 0.9183668519320904]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "least squares fit: 100%|| 5000/5000 [00:03<00:00, 1423.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bootstrap sample [31.74047630333171, 0.9538879291586575, -2.0689725879612464, 1.4785830120835632]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "least squares fit: 100%|| 5000/5000 [00:03<00:00, 1570.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bootstrap sample [29.466540840626713, 0.9837739845117637, -1.9915052407093474, 3.150029950640154]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "least squares fit: 100%|| 5000/5000 [00:03<00:00, 1347.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bootstrap sample [30.975157055313737, 0.9420086669374397, -2.036767174663606, 0.6323599067111711]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "least squares fit: 100%|| 5000/5000 [00:03<00:00, 1296.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bootstrap sample [31.478778128163995, 0.8623617407485805, -1.8798782324632366, -0.11949170941208886]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "least squares fit: 100%|| 5000/5000 [00:06<00:00, 831.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bootstrap sample [33.87286992682308, 0.8824018752321864, -1.8978803929581158, -1.0333647107478698]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "least squares fit: 100%|| 5000/5000 [00:07<00:00, 703.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bootstrap sample [29.27220689831499, 1.0899411603739346, -1.8911943299601002, 3.162677841885803]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "least squares fit: 100%|| 5000/5000 [00:06<00:00, 757.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bootstrap sample [30.835778095616906, 1.0242186355671825, -1.920925108122249, 1.338379513362099]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "least squares fit: 100%|| 5000/5000 [00:06<00:00, 747.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bootstrap sample [28.211162672015906, 1.4583524403926378, -1.70241171517105, 0.9452040151872599]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "least squares fit: 100%|| 5000/5000 [00:06<00:00, 727.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bootstrap sample [29.93552336056075, 0.9470529669956465, -1.8491245571618216, 0.8573641103651929]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "least squares fit: 100%|| 5000/5000 [00:06<00:00, 753.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bootstrap sample [30.636052325886002, 0.996617691388968, -1.8308401560119623, 0.13862673979220536]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "least squares fit: 100%|| 5000/5000 [00:06<00:00, 787.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bootstrap sample [30.855945311129382, 0.992573130119498, -1.8348135093555478, 1.971164179774993]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "least squares fit: 100%|| 5000/5000 [00:07<00:00, 655.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bootstrap sample [29.77226728370608, 1.0493381798575807, -1.6999309651266665, 0.922165187757515]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "least squares fit: 100%|| 5000/5000 [00:06<00:00, 756.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bootstrap sample [28.784700358217748, 0.9629668755117147, -1.7818333154132007, 1.9051703206760755]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "least squares fit: 100%|| 5000/5000 [00:06<00:00, 762.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bootstrap sample [31.769457992268443, 0.9040180814550004, -1.867677593282121, -0.7957987643064022]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "least squares fit: 100%|| 5000/5000 [00:06<00:00, 773.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bootstrap sample [30.068360876258833, 0.9237365767889173, -1.7326788050658608, 1.9044381512517488]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "least squares fit: 100%|| 5000/5000 [00:07<00:00, 684.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bootstrap sample [29.24892452277486, 1.0251706036709463, -1.6396068581125107, 1.787503950512798]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "least squares fit: 100%|| 5000/5000 [00:06<00:00, 762.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bootstrap sample [26.16039041855174, 1.3566609275406476, -1.8807310983821035, 3.884946816272218]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "least squares fit: 100%|| 5000/5000 [00:06<00:00, 770.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bootstrap sample [31.9708823034869, 0.871715949016825, -1.8037586194211699, -0.23788897755135488]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "least squares fit: 100%|| 5000/5000 [00:06<00:00, 765.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bootstrap sample [30.580903591168784, 0.9610711598856189, -1.8984859248085817, -0.002318739578270305]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "least squares fit: 100%|| 5000/5000 [00:06<00:00, 802.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bootstrap sample [31.433330253362577, 0.8768141821390378, -1.7328584033279488, -0.10210988051437443]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "least squares fit: 100%|| 5000/5000 [00:06<00:00, 744.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bootstrap sample [30.98423686056694, 1.0361494661429191, -2.2200016449095226, 1.088674989556359]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "least squares fit: 100%|| 5000/5000 [00:06<00:00, 757.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bootstrap sample [29.28237674477942, 1.0858388836439417, -1.7428060284747304, 1.4397328297413252]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "least squares fit: 100%|| 5000/5000 [00:06<00:00, 790.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bootstrap sample [30.65460047430859, 0.9454408039075628, -1.7320071301269266, -0.14858621820891008]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "least squares fit: 100%|| 5000/5000 [00:07<00:00, 709.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bootstrap sample [29.118139496835955, 0.8938088016966338, -1.9153563192896763, 2.059834581148944]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "least squares fit: 100%|| 5000/5000 [00:06<00:00, 754.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bootstrap sample [29.954884631959384, 0.9940567914003663, -1.7605085370056381, 1.6096257131696925]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "least squares fit: 100%|| 5000/5000 [00:06<00:00, 750.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bootstrap sample [31.00016484254486, 0.9623683159561878, -1.9115208623969566, 0.7473190835230116]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "least squares fit: 100%|| 5000/5000 [00:06<00:00, 737.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bootstrap sample [30.82520474489788, 0.891259020802667, -1.7704690936074923, 0.7459655949536614]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "least squares fit: 100%|| 5000/5000 [00:06<00:00, 785.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bootstrap sample [29.366136812382027, 1.012558241060829, -1.6182773155952546, 1.017025703754098]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "least squares fit: 100%|| 5000/5000 [00:06<00:00, 786.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bootstrap sample [29.942959701435118, 1.0167217566773747, -1.5621167917565115, -0.10309047639854085]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "least squares fit: 100%|| 5000/5000 [00:06<00:00, 752.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bootstrap sample [29.962898858207343, 1.0652251821283685, -1.9269241476635839, 2.0385736378519934]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "least squares fit: 100%|| 5000/5000 [00:07<00:00, 688.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bootstrap sample [30.525302041791814, 0.96589441022932, -1.8870631894489636, 0.5367690208128783]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "least squares fit: 100%|| 5000/5000 [00:06<00:00, 779.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bootstrap sample [30.678532056325906, 1.0139828545599128, -1.7817299670979696, 1.6026393229652913]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "least squares fit: 100%|| 5000/5000 [00:06<00:00, 732.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bootstrap sample [30.09073747870904, 1.0047123547747134, -1.9560265455918167, 2.7525942961573504]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "least squares fit: 100%|| 5000/5000 [00:06<00:00, 721.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bootstrap sample [30.937038893678917, 0.9670590611928076, -2.1124811600264293, 0.3258045605146979]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "least squares fit: 100%|| 5000/5000 [00:06<00:00, 741.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bootstrap sample [28.78930855900357, 1.1730115746597933, -1.783513864062301, 3.262315830823608]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "least squares fit: 100%|| 5000/5000 [00:06<00:00, 746.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bootstrap sample [31.147549123095523, 0.9326436111603988, -1.7707952504307625, -1.0993590646043099]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "least squares fit: 100%|| 5000/5000 [00:07<00:00, 696.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bootstrap sample [31.813727613195653, 0.968378408538461, -2.019078886892217, 0.7501206686148617]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "least squares fit: 100%|| 5000/5000 [00:06<00:00, 770.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bootstrap sample [30.223398353230184, 0.9373764744862103, -1.532360716667537, -0.014699940752100762]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "least squares fit: 100%|| 5000/5000 [00:06<00:00, 775.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bootstrap sample [28.017775004448914, 1.0915988787946649, -1.61901910228325, 2.3971543445881216]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "least squares fit: 100%|| 5000/5000 [00:06<00:00, 754.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bootstrap sample [29.34266888649659, 0.9815156932180105, -1.9184777914462312, 1.5482939749639464]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "least squares fit: 100%|| 5000/5000 [00:06<00:00, 763.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bootstrap sample [32.539371666492876, 1.060883971208886, -2.2704689582768713, 0.36815976537615636]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "least squares fit: 100%|| 5000/5000 [00:07<00:00, 697.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bootstrap sample [30.106198499206915, 0.9657134612613776, -1.719152943653064, -0.626761920722129]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "least squares fit: 100%|| 5000/5000 [00:06<00:00, 727.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bootstrap sample [29.993282359977123, 0.9757399392816425, -1.9767875486880893, 2.048669364846275]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "least squares fit: 100%|| 5000/5000 [00:07<00:00, 708.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bootstrap sample [30.571136409586916, 1.0664888135315582, -1.661883517774428, -0.19985556821698391]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "least squares fit: 100%|| 5000/5000 [00:06<00:00, 740.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bootstrap sample [30.9490097252882, 0.9597396222139453, -1.9214823753987706, 1.258855034876941]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "least squares fit: 100%|| 5000/5000 [00:06<00:00, 763.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bootstrap sample [31.887007554673076, 0.9506671496957437, -2.152653973374404, 1.6869486505999165]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "least squares fit: 100%|| 5000/5000 [00:06<00:00, 749.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bootstrap sample [29.081704350215187, 1.0495038787355981, -1.6920009023683742, 3.6090800499492026]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "least squares fit: 100%|| 5000/5000 [00:06<00:00, 772.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bootstrap sample [31.47954683056297, 1.1296437640969315, -1.8930013630375888, 0.232897143800955]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "least squares fit: 100%|| 5000/5000 [00:06<00:00, 747.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bootstrap sample [30.6109739128054, 1.006589431991101, -1.8362432466801042, 0.44993972174552416]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "least squares fit: 100%|| 5000/5000 [00:06<00:00, 763.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bootstrap sample [31.80927695488258, 0.9821469730488939, -2.007959621103926, -0.241139874505021]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "least squares fit: 100%|| 5000/5000 [00:06<00:00, 721.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bootstrap sample [31.024210851804416, 0.9515774062029451, -1.9408222914617927, 0.6442854716394802]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "least squares fit: 100%|| 5000/5000 [00:06<00:00, 786.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bootstrap sample [28.90814123599003, 1.055627383881031, -1.79357549913758, 2.082266951237435]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "least squares fit: 100%|| 5000/5000 [00:06<00:00, 749.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bootstrap sample [30.025383087071763, 0.9490311032868946, -1.8905462953821095, 1.6149681025028517]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "least squares fit: 100%|| 5000/5000 [00:06<00:00, 743.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bootstrap sample [31.344911606937217, 0.9596230552550088, -2.0849440191827746, 1.0635864768954952]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "least squares fit: 100%|| 5000/5000 [00:06<00:00, 739.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bootstrap sample [30.887856658797634, 0.9739691303740716, -1.7504967811095185, -2.008668458011063]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "least squares fit: 100%|| 5000/5000 [00:06<00:00, 755.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bootstrap sample [30.52417209727789, 0.9468432200060536, -1.748958321470468, -0.4294754081344007]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "least squares fit: 100%|| 5000/5000 [00:06<00:00, 785.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bootstrap sample [33.73887281461898, 0.8342998931764719, -2.0056583070815237, -1.0048943591784747]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "least squares fit: 100%|| 5000/5000 [00:06<00:00, 791.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bootstrap sample [29.04731144829789, 0.9737448743420717, -1.7622553843049416, 0.974487119716568]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "least squares fit: 100%|| 5000/5000 [00:06<00:00, 737.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bootstrap sample [30.84908697552376, 1.1142041012783983, -2.055393538038613, 1.8606960468590932]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "least squares fit: 100%|| 5000/5000 [00:06<00:00, 720.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bootstrap sample [31.20227902410509, 1.0148203879553739, -1.8311398178678528, -0.12803605188562783]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "least squares fit: 100%|| 5000/5000 [00:06<00:00, 771.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bootstrap sample [30.449512425888518, 0.9188875408835144, -1.6623667661150154, 0.4156120951870569]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "least squares fit: 100%|| 5000/5000 [00:06<00:00, 786.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bootstrap sample [30.937436479376498, 0.9178249912706588, -1.9178839540557806, 0.8027340312172632]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "least squares fit: 100%|| 5000/5000 [00:06<00:00, 784.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bootstrap sample [33.0730481793411, 0.7669188362229072, -1.8621104803815114, -0.5344373694611131]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "least squares fit: 100%|| 5000/5000 [00:06<00:00, 735.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bootstrap sample [30.980354529367382, 0.9608047189289308, -1.8571138381579289, 1.2456516010876988]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "least squares fit: 100%|| 5000/5000 [00:06<00:00, 763.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bootstrap sample [29.890049201061156, 0.9320508621300002, -1.8151571408892877, 1.6197634219660286]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "least squares fit: 100%|| 5000/5000 [00:06<00:00, 776.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bootstrap sample [32.74970739067421, 0.8163410438179738, -1.672793722377824, -1.627203273138947]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "least squares fit: 100%|| 5000/5000 [00:06<00:00, 786.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bootstrap sample [32.23550207094589, 0.9915112587422378, -2.201685593411146, 0.6597215256946112]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "least squares fit: 100%|| 5000/5000 [00:06<00:00, 770.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bootstrap sample [30.238346353105726, 0.9812068545490504, -1.9183149068660714, 2.425238910481976]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "least squares fit: 100%|| 5000/5000 [00:06<00:00, 746.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bootstrap sample [30.574120085079137, 0.9174840515163689, -1.7918245395513424, 0.9221993996446346]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "least squares fit: 100%|| 5000/5000 [00:05<00:00, 843.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bootstrap sample [30.20058827249059, 0.9290781608340558, -1.5128386060160501, -0.2716428116419145]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "least squares fit: 100%|| 5000/5000 [00:06<00:00, 756.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bootstrap sample [30.568001921567827, 1.0423323558239712, -2.05393282824843, 2.070512986336468]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "least squares fit: 100%|| 5000/5000 [00:06<00:00, 768.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bootstrap sample [32.241705940332245, 0.9289438462889386, -1.959714643247542, -0.32832700894412226]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "least squares fit: 100%|| 5000/5000 [00:06<00:00, 789.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bootstrap sample [32.86747263095501, 1.0159010210188604, -2.0279568468137548, -0.5177147877542965]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "least squares fit: 100%|| 5000/5000 [00:06<00:00, 756.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bootstrap sample [29.215869116992934, 1.0071212080144287, -1.956750577648415, 3.724851633646791]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "least squares fit: 100%|| 5000/5000 [00:06<00:00, 781.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bootstrap sample [29.73162036395756, 1.0022351904608418, -1.605675006910746, 0.3836580563754841]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "least squares fit: 100%|| 5000/5000 [00:06<00:00, 763.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bootstrap sample [32.673478414355976, 0.8824434637692977, -1.9909101579029305, 0.04871947146703188]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "least squares fit: 100%|| 5000/5000 [00:06<00:00, 801.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bootstrap sample [29.157755537562135, 1.0683351454601346, -1.7096121511993112, 3.2616854857255335]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "least squares fit: 100%|| 5000/5000 [00:06<00:00, 770.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bootstrap sample [30.48824056496075, 1.0353317712496077, -1.9149562223503451, 2.595089595245565]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "least squares fit: 100%|| 5000/5000 [00:06<00:00, 824.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bootstrap sample [31.498485256154574, 0.8651737226485892, -1.9003285713857743, -0.4448014961070422]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "least squares fit: 100%|| 5000/5000 [00:06<00:00, 722.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bootstrap sample [28.568637146495433, 0.937708481630552, -1.669707921454888, 2.037852818692603]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "least squares fit: 100%|| 5000/5000 [00:06<00:00, 771.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bootstrap sample [30.888089000339196, 0.9480046573855905, -1.9409732963472779, -0.38053847722698175]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "least squares fit: 100%|| 5000/5000 [00:06<00:00, 735.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bootstrap sample [30.44930217440876, 1.1218514836785962, -1.962151679669955, 2.2443415978325145]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "least squares fit: 100%|| 5000/5000 [00:06<00:00, 782.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bootstrap sample [30.266204204539513, 1.0068673256804963, -2.1198992898486466, 0.5362851256019148]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "least squares fit: 100%|| 5000/5000 [00:06<00:00, 791.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bootstrap sample [29.330318126136387, 1.0424517245684064, -1.8849226826885932, 2.2650387817258584]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "least squares fit: 100%|| 5000/5000 [00:06<00:00, 812.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bootstrap sample [31.77738953881697, 0.8928310423632744, -1.9269578522157444, 0.048635890062916735]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "least squares fit: 100%|| 5000/5000 [00:06<00:00, 793.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bootstrap sample [28.291072745509144, 1.1873361941623273, -1.854668716906258, 2.639027655808866]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "least squares fit: 100%|| 5000/5000 [00:06<00:00, 800.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bootstrap sample [31.725525991297587, 0.8939775539447467, -1.843559060469148, -0.6224324630864074]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "least squares fit: 100%|| 5000/5000 [00:06<00:00, 783.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bootstrap sample [30.2731194689144, 0.8005769229528958, -1.6991234036996576, 0.9748341305369915]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "least squares fit: 100%|| 5000/5000 [00:06<00:00, 756.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bootstrap sample [31.75696506368952, 1.0790800487199685, -2.0880894078200054, 1.642094338346172]\n",
      "[1.2715078186272786, 0.10318410116073962, 0.15510591689663625, 1.2490975248051261]\n"
     ]
    }
   ],
   "source": [
    "from typing import List\n",
    "\n",
    "inputs: List[List[float]] = [[1.,49,4,0],[1,41,9,0],[1,40,8,0],[1,25,6,0],[1,21,1,0],[1,21,0,0],[1,19,3,0],[1,19,0,0],[1,18,9,0],[1,18,8,0],[1,16,4,0],[1,15,3,0],[1,15,0,0],[1,15,2,0],[1,15,7,0],[1,14,0,0],[1,14,1,0],[1,13,1,0],[1,13,7,0],[1,13,4,0],[1,13,2,0],[1,12,5,0],[1,12,0,0],[1,11,9,0],[1,10,9,0],[1,10,1,0],[1,10,1,0],[1,10,7,0],[1,10,9,0],[1,10,1,0],[1,10,6,0],[1,10,6,0],[1,10,8,0],[1,10,10,0],[1,10,6,0],[1,10,0,0],[1,10,5,0],[1,10,3,0],[1,10,4,0],[1,9,9,0],[1,9,9,0],[1,9,0,0],[1,9,0,0],[1,9,6,0],[1,9,10,0],[1,9,8,0],[1,9,5,0],[1,9,2,0],[1,9,9,0],[1,9,10,0],[1,9,7,0],[1,9,2,0],[1,9,0,0],[1,9,4,0],[1,9,6,0],[1,9,4,0],[1,9,7,0],[1,8,3,0],[1,8,2,0],[1,8,4,0],[1,8,9,0],[1,8,2,0],[1,8,3,0],[1,8,5,0],[1,8,8,0],[1,8,0,0],[1,8,9,0],[1,8,10,0],[1,8,5,0],[1,8,5,0],[1,7,5,0],[1,7,5,0],[1,7,0,0],[1,7,2,0],[1,7,8,0],[1,7,10,0],[1,7,5,0],[1,7,3,0],[1,7,3,0],[1,7,6,0],[1,7,7,0],[1,7,7,0],[1,7,9,0],[1,7,3,0],[1,7,8,0],[1,6,4,0],[1,6,6,0],[1,6,4,0],[1,6,9,0],[1,6,0,0],[1,6,1,0],[1,6,4,0],[1,6,1,0],[1,6,0,0],[1,6,7,0],[1,6,0,0],[1,6,8,0],[1,6,4,0],[1,6,2,1],[1,6,1,1],[1,6,3,1],[1,6,6,1],[1,6,4,1],[1,6,4,1],[1,6,1,1],[1,6,3,1],[1,6,4,1],[1,5,1,1],[1,5,9,1],[1,5,4,1],[1,5,6,1],[1,5,4,1],[1,5,4,1],[1,5,10,1],[1,5,5,1],[1,5,2,1],[1,5,4,1],[1,5,4,1],[1,5,9,1],[1,5,3,1],[1,5,10,1],[1,5,2,1],[1,5,2,1],[1,5,9,1],[1,4,8,1],[1,4,6,1],[1,4,0,1],[1,4,10,1],[1,4,5,1],[1,4,10,1],[1,4,9,1],[1,4,1,1],[1,4,4,1],[1,4,4,1],[1,4,0,1],[1,4,3,1],[1,4,1,1],[1,4,3,1],[1,4,2,1],[1,4,4,1],[1,4,4,1],[1,4,8,1],[1,4,2,1],[1,4,4,1],[1,3,2,1],[1,3,6,1],[1,3,4,1],[1,3,7,1],[1,3,4,1],[1,3,1,1],[1,3,10,1],[1,3,3,1],[1,3,4,1],[1,3,7,1],[1,3,5,1],[1,3,6,1],[1,3,1,1],[1,3,6,1],[1,3,10,1],[1,3,2,1],[1,3,4,1],[1,3,2,1],[1,3,1,1],[1,3,5,1],[1,2,4,1],[1,2,2,1],[1,2,8,1],[1,2,3,1],[1,2,1,1],[1,2,9,1],[1,2,10,1],[1,2,9,1],[1,2,4,1],[1,2,5,1],[1,2,0,1],[1,2,9,1],[1,2,9,1],[1,2,0,1],[1,2,1,1],[1,2,1,1],[1,2,4,1],[1,1,0,1],[1,1,2,1],[1,1,2,1],[1,1,5,1],[1,1,3,1],[1,1,10,1],[1,1,6,1],[1,1,0,1],[1,1,8,1],[1,1,6,1],[1,1,4,1],[1,1,9,1],[1,1,9,1],[1,1,4,1],[1,1,2,1],[1,1,9,1],[1,1,0,1],[1,1,8,1],[1,1,6,1],[1,1,1,1],[1,1,1,1],[1,1,5,1]]\n",
    "\n",
    "from scratch.linear_algebra import dot, Vector\n",
    "\n",
    "def predict(x: Vector, beta: Vector) -> float:\n",
    "    \"\"\"assumes that the first element of x is 1\"\"\"\n",
    "    return dot(x, beta)\n",
    "\n",
    "[1,    # constant term\n",
    " 49,   # number of friends\n",
    " 4,    # work hours per day\n",
    " 0]    # doesn't have PhD\n",
    "\n",
    "from typing import List\n",
    "\n",
    "def error(x: Vector, y: float, beta: Vector) -> float:\n",
    "    return predict(x, beta) - y\n",
    "\n",
    "def squared_error(x: Vector, y: float, beta: Vector) -> float:\n",
    "    return error(x, y, beta) ** 2\n",
    "\n",
    "x = [1, 2, 3]\n",
    "y = 30\n",
    "beta = [4, 4, 4]  # so prediction = 4 + 8 + 12 = 24\n",
    "\n",
    "assert error(x, y, beta) == -6\n",
    "assert squared_error(x, y, beta) == 36\n",
    "\n",
    "def sqerror_gradient(x: Vector, y: float, beta: Vector) -> Vector:\n",
    "    err = error(x, y, beta)\n",
    "    return [2 * err * x_i for x_i in x]\n",
    "\n",
    "assert sqerror_gradient(x, y, beta) == [-12, -24, -36]\n",
    "\n",
    "import random\n",
    "import tqdm\n",
    "from scratch.linear_algebra import vector_mean\n",
    "from scratch.gradient_descent import gradient_step\n",
    "\n",
    "\n",
    "def least_squares_fit(xs: List[Vector],\n",
    "                      ys: List[float],\n",
    "                      learning_rate: float = 0.001,\n",
    "                      num_steps: int = 1000,\n",
    "                      batch_size: int = 1) -> Vector:\n",
    "    \"\"\"\n",
    "    Find the beta that minimizes the sum of squared errors\n",
    "    assuming the model y = dot(x, beta).\n",
    "    \"\"\"\n",
    "    # Start with a random guess\n",
    "    guess = [random.random() for _ in xs[0]]\n",
    "\n",
    "    for _ in tqdm.trange(num_steps, desc=\"least squares fit\"):\n",
    "        for start in range(0, len(xs), batch_size):\n",
    "            batch_xs = xs[start:start+batch_size]\n",
    "            batch_ys = ys[start:start+batch_size]\n",
    "\n",
    "            gradient = vector_mean([sqerror_gradient(x, y, guess)\n",
    "                                    for x, y in zip(batch_xs, batch_ys)])\n",
    "            guess = gradient_step(guess, gradient, -learning_rate)\n",
    "\n",
    "    return guess\n",
    "\n",
    "from scratch.simple_linear_regression import total_sum_of_squares\n",
    "\n",
    "def multiple_r_squared(xs: List[Vector], ys: Vector, beta: Vector) -> float:\n",
    "    sum_of_squared_errors = sum(error(x, y, beta) ** 2\n",
    "                                for x, y in zip(xs, ys))\n",
    "    return 1.0 - sum_of_squared_errors / total_sum_of_squares(ys)\n",
    "\n",
    "from typing import TypeVar, Callable\n",
    "\n",
    "X = TypeVar('X')        # Generic type for data\n",
    "Stat = TypeVar('Stat')  # Generic type for \"statistic\"\n",
    "\n",
    "def bootstrap_sample(data: List[X]) -> List[X]:\n",
    "    \"\"\"randomly samples len(data) elements with replacement\"\"\"\n",
    "    return [random.choice(data) for _ in data]\n",
    "\n",
    "def bootstrap_statistic(data: List[X],\n",
    "                        stats_fn: Callable[[List[X]], Stat],\n",
    "                        num_samples: int) -> List[Stat]:\n",
    "    \"\"\"evaluates stats_fn on num_samples bootstrap samples from data\"\"\"\n",
    "    return [stats_fn(bootstrap_sample(data)) for _ in range(num_samples)]\n",
    "\n",
    "# 101 points all very close to 100\n",
    "close_to_100 = [99.5 + random.random() for _ in range(101)]\n",
    "\n",
    "# 101 points, 50 of them near 0, 50 of them near 200\n",
    "far_from_100 = ([99.5 + random.random()] +\n",
    "                [random.random() for _ in range(50)] +\n",
    "                [200 + random.random() for _ in range(50)])\n",
    "\n",
    "from scratch.statistics import median, standard_deviation\n",
    "\n",
    "medians_close = bootstrap_statistic(close_to_100, median, 100)\n",
    "\n",
    "medians_far = bootstrap_statistic(far_from_100, median, 100)\n",
    "\n",
    "assert standard_deviation(medians_close) < 1\n",
    "assert standard_deviation(medians_far) > 90\n",
    "\n",
    "from scratch.probability import normal_cdf\n",
    "\n",
    "def p_value(beta_hat_j: float, sigma_hat_j: float) -> float:\n",
    "    if beta_hat_j > 0:\n",
    "        # if the coefficient is positive, we need to compute twice the\n",
    "        # probability of seeing an even *larger* value\n",
    "        return 2 * (1 - normal_cdf(beta_hat_j / sigma_hat_j))\n",
    "    else:\n",
    "        # otherwise twice the probability of seeing a *smaller* value\n",
    "        return 2 * normal_cdf(beta_hat_j / sigma_hat_j)\n",
    "\n",
    "assert p_value(30.58, 1.27)   < 0.001  # constant term\n",
    "assert p_value(0.972, 0.103)  < 0.001  # num_friends\n",
    "assert p_value(-1.865, 0.155) < 0.001  # work_hours\n",
    "assert p_value(0.923, 1.249)  > 0.4    # phd\n",
    "\n",
    "# alpha is a *hyperparameter* controlling how harsh the penalty is\n",
    "# sometimes it's called \"lambda\" but that already means something in Python\n",
    "def ridge_penalty(beta: Vector, alpha: float) -> float:\n",
    "    return alpha * dot(beta[1:], beta[1:])\n",
    "\n",
    "def squared_error_ridge(x: Vector,\n",
    "                        y: float,\n",
    "                        beta: Vector,\n",
    "                        alpha: float) -> float:\n",
    "    \"\"\"estimate error plus ridge penalty on beta\"\"\"\n",
    "    return error(x, y, beta) ** 2 + ridge_penalty(beta, alpha)\n",
    "\n",
    "from scratch.linear_algebra import add\n",
    "\n",
    "def ridge_penalty_gradient(beta: Vector, alpha: float) -> Vector:\n",
    "    \"\"\"gradient of just the ridge penalty\"\"\"\n",
    "    return [0.] + [2 * alpha * beta_j for beta_j in beta[1:]]\n",
    "\n",
    "def sqerror_ridge_gradient(x: Vector,\n",
    "                           y: float,\n",
    "                           beta: Vector,\n",
    "                           alpha: float) -> Vector:\n",
    "    \"\"\"\n",
    "    the gradient corresponding to the ith squared error term\n",
    "    including the ridge penalty\n",
    "    \"\"\"\n",
    "    return add(sqerror_gradient(x, y, beta),\n",
    "               ridge_penalty_gradient(beta, alpha))\n",
    "\n",
    "\n",
    "from scratch.statistics import daily_minutes_good\n",
    "from scratch.gradient_descent import gradient_step\n",
    "\n",
    "learning_rate = 0.001\n",
    "\n",
    "def least_squares_fit_ridge(xs: List[Vector],\n",
    "                            ys: List[float],\n",
    "                            alpha: float,\n",
    "                            learning_rate: float,\n",
    "                            num_steps: int,\n",
    "                            batch_size: int = 1) -> Vector:\n",
    "    # Start guess with mean\n",
    "    guess = [random.random() for _ in xs[0]]\n",
    "\n",
    "    for i in range(num_steps):\n",
    "        for start in range(0, len(xs), batch_size):\n",
    "            batch_xs = xs[start:start+batch_size]\n",
    "            batch_ys = ys[start:start+batch_size]\n",
    "\n",
    "            gradient = vector_mean([sqerror_ridge_gradient(x, y, guess, alpha)\n",
    "                                    for x, y in zip(batch_xs, batch_ys)])\n",
    "            guess = gradient_step(guess, gradient, -learning_rate)\n",
    "\n",
    "    return guess\n",
    "\n",
    "def lasso_penalty(beta, alpha):\n",
    "    return alpha * sum(abs(beta_i) for beta_i in beta[1:])\n",
    "\n",
    "def main():\n",
    "    from scratch.statistics import daily_minutes_good\n",
    "    from scratch.gradient_descent import gradient_step\n",
    "    \n",
    "    random.seed(0)\n",
    "    # I used trial and error to choose niters and step_size.\n",
    "    # This will run for a while.\n",
    "    learning_rate = 0.001\n",
    "    \n",
    "    beta = least_squares_fit(inputs, daily_minutes_good, learning_rate, 5000, 25)\n",
    "    assert 30.50 < beta[0] < 30.70  # constant\n",
    "    assert  0.96 < beta[1] <  1.00  # num friends\n",
    "    assert -1.89 < beta[2] < -1.85  # work hours per day\n",
    "    assert  0.91 < beta[3] <  0.94  # has PhD\n",
    "    \n",
    "    assert 0.67 < multiple_r_squared(inputs, daily_minutes_good, beta) < 0.68\n",
    "    \n",
    "    from typing import Tuple\n",
    "    \n",
    "    import datetime\n",
    "    \n",
    "    def estimate_sample_beta(pairs: List[Tuple[Vector, float]]):\n",
    "        x_sample = [x for x, _ in pairs]\n",
    "        y_sample = [y for _, y in pairs]\n",
    "        beta = least_squares_fit(x_sample, y_sample, learning_rate, 5000, 25)\n",
    "        print(\"bootstrap sample\", beta)\n",
    "        return beta\n",
    "    \n",
    "    random.seed(0) # so that you get the same results as me\n",
    "    \n",
    "    # This will take a couple of minutes!\n",
    "    bootstrap_betas = bootstrap_statistic(list(zip(inputs, daily_minutes_good)),\n",
    "                                          estimate_sample_beta,\n",
    "                                          100)\n",
    "    \n",
    "    bootstrap_standard_errors = [\n",
    "        standard_deviation([beta[i] for beta in bootstrap_betas])\n",
    "        for i in range(4)]\n",
    "    \n",
    "    print(bootstrap_standard_errors)\n",
    "    \n",
    "    # [1.272,    # constant term, actual error = 1.19\n",
    "    #  0.103,    # num_friends,   actual error = 0.080\n",
    "    #  0.155,    # work_hours,    actual error = 0.127\n",
    "    #  1.249]    # phd,           actual error = 0.998\n",
    "    \n",
    "    random.seed(0)\n",
    "    beta_0 = least_squares_fit_ridge(inputs, daily_minutes_good, 0.0,  # alpha\n",
    "                                     learning_rate, 5000, 25)\n",
    "    # [30.51, 0.97, -1.85, 0.91]\n",
    "    assert 5 < dot(beta_0[1:], beta_0[1:]) < 6\n",
    "    assert 0.67 < multiple_r_squared(inputs, daily_minutes_good, beta_0) < 0.69\n",
    "    \n",
    "    beta_0_1 = least_squares_fit_ridge(inputs, daily_minutes_good, 0.1,  # alpha\n",
    "                                       learning_rate, 5000, 25)\n",
    "    # [30.8, 0.95, -1.83, 0.54]\n",
    "    assert 4 < dot(beta_0_1[1:], beta_0_1[1:]) < 5\n",
    "    assert 0.67 < multiple_r_squared(inputs, daily_minutes_good, beta_0_1) < 0.69\n",
    "    \n",
    "    \n",
    "    beta_1 = least_squares_fit_ridge(inputs, daily_minutes_good, 1,  # alpha\n",
    "                                     learning_rate, 5000, 25)\n",
    "    # [30.6, 0.90, -1.68, 0.10]\n",
    "    assert 3 < dot(beta_1[1:], beta_1[1:]) < 4\n",
    "    assert 0.67 < multiple_r_squared(inputs, daily_minutes_good, beta_1) < 0.69\n",
    "    \n",
    "    beta_10 = least_squares_fit_ridge(inputs, daily_minutes_good,10,  # alpha\n",
    "                                      learning_rate, 5000, 25)\n",
    "    # [28.3, 0.67, -0.90, -0.01]\n",
    "    assert 1 < dot(beta_10[1:], beta_10[1:]) < 2\n",
    "    assert 0.5 < multiple_r_squared(inputs, daily_minutes_good, beta_10) < 0.6\n",
    "    \n",
    "if __name__ == \"__main__\": main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6013f93",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c12f9809",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'stocks.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[41], line 159\u001b[0m\n\u001b[0;32m    156\u001b[0m     plt\u001b[38;5;241m.\u001b[39msavefig(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mim/logistic_regression_predicted_vs_actual.png\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    157\u001b[0m     plt\u001b[38;5;241m.\u001b[39mgca()\u001b[38;5;241m.\u001b[39mclear()\n\u001b[1;32m--> 159\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m: main()\n",
      "Cell \u001b[1;32mIn[41], line 65\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     62\u001b[0m plt\u001b[38;5;241m.\u001b[39mgca()\u001b[38;5;241m.\u001b[39mclear()\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pyplot \u001b[38;5;28;01mas\u001b[39;00m plt\n\u001b[1;32m---> 65\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscratch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mworking_with_data\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m rescale\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscratch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmultiple_regression\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m least_squares_fit, predict\n\u001b[0;32m     67\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscratch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgradient_descent\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m gradient_step\n",
      "File \u001b[1;32m~\\DSA\\scratch\\working_with_data.py:148\u001b[0m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdateutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mparser\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m parse\n\u001b[0;32m    146\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcsv\u001b[39;00m\n\u001b[1;32m--> 148\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstocks.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m    149\u001b[0m     reader \u001b[38;5;241m=\u001b[39m csv\u001b[38;5;241m.\u001b[39mDictReader(f)\n\u001b[0;32m    150\u001b[0m     rows \u001b[38;5;241m=\u001b[39m [[row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSymbol\u001b[39m\u001b[38;5;124m'\u001b[39m], row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDate\u001b[39m\u001b[38;5;124m'\u001b[39m], row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mClose\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[0;32m    151\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m reader]\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'stocks.csv'"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tuples = [(0.7,48000,1),(1.9,48000,0),(2.5,60000,1),(4.2,63000,0),(6,76000,0),(6.5,69000,0),(7.5,76000,0),(8.1,88000,0),(8.7,83000,1),(10,83000,1),(0.8,43000,0),(1.8,60000,0),(10,79000,1),(6.1,76000,0),(1.4,50000,0),(9.1,92000,0),(5.8,75000,0),(5.2,69000,0),(1,56000,0),(6,67000,0),(4.9,74000,0),(6.4,63000,1),(6.2,82000,0),(3.3,58000,0),(9.3,90000,1),(5.5,57000,1),(9.1,102000,0),(2.4,54000,0),(8.2,65000,1),(5.3,82000,0),(9.8,107000,0),(1.8,64000,0),(0.6,46000,1),(0.8,48000,0),(8.6,84000,1),(0.6,45000,0),(0.5,30000,1),(7.3,89000,0),(2.5,48000,1),(5.6,76000,0),(7.4,77000,0),(2.7,56000,0),(0.7,48000,0),(1.2,42000,0),(0.2,32000,1),(4.7,56000,1),(2.8,44000,1),(7.6,78000,0),(1.1,63000,0),(8,79000,1),(2.7,56000,0),(6,52000,1),(4.6,56000,0),(2.5,51000,0),(5.7,71000,0),(2.9,65000,0),(1.1,33000,1),(3,62000,0),(4,71000,0),(2.4,61000,0),(7.5,75000,0),(9.7,81000,1),(3.2,62000,0),(7.9,88000,0),(4.7,44000,1),(2.5,55000,0),(1.6,41000,0),(6.7,64000,1),(6.9,66000,1),(7.9,78000,1),(8.1,102000,0),(5.3,48000,1),(8.5,66000,1),(0.2,56000,0),(6,69000,0),(7.5,77000,0),(8,86000,0),(4.4,68000,0),(4.9,75000,0),(1.5,60000,0),(2.2,50000,0),(3.4,49000,1),(4.2,70000,0),(7.7,98000,0),(8.2,85000,0),(5.4,88000,0),(0.1,46000,0),(1.5,37000,0),(6.3,86000,0),(3.7,57000,0),(8.4,85000,0),(2,42000,0),(5.8,69000,1),(2.7,64000,0),(3.1,63000,0),(1.9,48000,0),(10,72000,1),(0.2,45000,0),(8.6,95000,0),(1.5,64000,0),(9.8,95000,0),(5.3,65000,0),(7.5,80000,0),(9.9,91000,0),(9.7,50000,1),(2.8,68000,0),(3.6,58000,0),(3.9,74000,0),(4.4,76000,0),(2.5,49000,0),(7.2,81000,0),(5.2,60000,1),(2.4,62000,0),(8.9,94000,0),(2.4,63000,0),(6.8,69000,1),(6.5,77000,0),(7,86000,0),(9.4,94000,0),(7.8,72000,1),(0.2,53000,0),(10,97000,0),(5.5,65000,0),(7.7,71000,1),(8.1,66000,1),(9.8,91000,0),(8,84000,0),(2.7,55000,0),(2.8,62000,0),(9.4,79000,0),(2.5,57000,0),(7.4,70000,1),(2.1,47000,0),(5.3,62000,1),(6.3,79000,0),(6.8,58000,1),(5.7,80000,0),(2.2,61000,0),(4.8,62000,0),(3.7,64000,0),(4.1,85000,0),(2.3,51000,0),(3.5,58000,0),(0.9,43000,0),(0.9,54000,0),(4.5,74000,0),(6.5,55000,1),(4.1,41000,1),(7.1,73000,0),(1.1,66000,0),(9.1,81000,1),(8,69000,1),(7.3,72000,1),(3.3,50000,0),(3.9,58000,0),(2.6,49000,0),(1.6,78000,0),(0.7,56000,0),(2.1,36000,1),(7.5,90000,0),(4.8,59000,1),(8.9,95000,0),(6.2,72000,0),(6.3,63000,0),(9.1,100000,0),(7.3,61000,1),(5.6,74000,0),(0.5,66000,0),(1.1,59000,0),(5.1,61000,0),(6.2,70000,0),(6.6,56000,1),(6.3,76000,0),(6.5,78000,0),(5.1,59000,0),(9.5,74000,1),(4.5,64000,0),(2,54000,0),(1,52000,0),(4,69000,0),(6.5,76000,0),(3,60000,0),(4.5,63000,0),(7.8,70000,0),(3.9,60000,1),(0.8,51000,0),(4.2,78000,0),(1.1,54000,0),(6.2,60000,0),(2.9,59000,0),(2.1,52000,0),(8.2,87000,0),(4.8,73000,0),(2.2,42000,1),(9.1,98000,0),(6.5,84000,0),(6.9,73000,0),(5.1,72000,0),(9.1,69000,1),(9.8,79000,1),]\n",
    "data = [list(row) for row in tuples]\n",
    "\n",
    "xs = [[1.0] + row[:2] for row in data]  # [1, experience, salary]\n",
    "ys = [row[2] for row in data]           # paid_account\n",
    "\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def logistic(x: float) -> float:\n",
    "    return 1.0 / (1 + math.exp(-x))\n",
    "\n",
    "def logistic_prime(x: float) -> float:\n",
    "    y = logistic(x)\n",
    "    return y * (1 - y)\n",
    "\n",
    "import math\n",
    "from scratch.linear_algebra import Vector, dot\n",
    "\n",
    "def _negative_log_likelihood(x: Vector, y: float, beta: Vector) -> float:\n",
    "    \"\"\"The negative log likelihood for one data point\"\"\"\n",
    "    if y == 1:\n",
    "        return -math.log(logistic(dot(x, beta)))\n",
    "    else:\n",
    "        return -math.log(1 - logistic(dot(x, beta)))\n",
    "\n",
    "from typing import List\n",
    "\n",
    "def negative_log_likelihood(xs: List[Vector],\n",
    "                            ys: List[float],\n",
    "                            beta: Vector) -> float:\n",
    "    return sum(_negative_log_likelihood(x, y, beta)\n",
    "               for x, y in zip(xs, ys))\n",
    "\n",
    "from scratch.linear_algebra import vector_sum\n",
    "\n",
    "def _negative_log_partial_j(x: Vector, y: float, beta: Vector, j: int) -> float:\n",
    "    \"\"\"\n",
    "    The j-th partial derivative for one data pont\n",
    "    here i is the index of the data point\n",
    "    \"\"\"\n",
    "    return -(y - logistic(dot(x, beta))) * x[j]\n",
    "\n",
    "def _negative_log_gradient(x: Vector, y: float, beta: Vector) -> Vector:\n",
    "    \"\"\"\n",
    "    The gradient for one data point\n",
    "    \"\"\"\n",
    "    return [_negative_log_partial_j(x, y, beta, j)\n",
    "            for j in range(len(beta))]\n",
    "\n",
    "def negative_log_gradient(xs: List[Vector],\n",
    "                          ys: List[float],\n",
    "                          beta: Vector) -> Vector:\n",
    "    return vector_sum([_negative_log_gradient(x, y, beta)\n",
    "                       for x, y in zip(xs, ys)])\n",
    "\n",
    "def main():\n",
    "    \n",
    "    from matplotlib import pyplot as plt\n",
    "    plt.close()\n",
    "    plt.clf()\n",
    "    plt.gca().clear()\n",
    "    \n",
    "    from matplotlib import pyplot as plt\n",
    "    from scratch.working_with_data import rescale\n",
    "    from scratch.multiple_regression import least_squares_fit, predict\n",
    "    from scratch.gradient_descent import gradient_step\n",
    "    \n",
    "    learning_rate = 0.001\n",
    "    rescaled_xs = rescale(xs)\n",
    "    beta = least_squares_fit(rescaled_xs, ys, learning_rate, 1000, 1)\n",
    "    \n",
    "    #[0.26, 0.43, -0.43]\n",
    "    predictions = [predict(x_i, beta) for x_i in rescaled_xs]\n",
    "    \n",
    "    plt.scatter(predictions, ys)\n",
    "    plt.xlabel(\"predicted\")\n",
    "    plt.ylabel(\"actual\")\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    plt.savefig('im/linear_regression_for_probabilities.png')\n",
    "    plt.close()\n",
    "    \n",
    "    from scratch.machine_learning import train_test_split\n",
    "    import random\n",
    "    import tqdm\n",
    "    \n",
    "    random.seed(0)\n",
    "    x_train, x_test, y_train, y_test = train_test_split(rescaled_xs, ys, 0.33)\n",
    "    \n",
    "    learning_rate = 0.01\n",
    "    \n",
    "    # pick a random starting point\n",
    "    beta = [random.random() for _ in range(3)]\n",
    "    \n",
    "    with tqdm.trange(5000) as t:\n",
    "        for epoch in t:\n",
    "            gradient = negative_log_gradient(x_train, y_train, beta)\n",
    "            beta = gradient_step(beta, gradient, -learning_rate)\n",
    "            loss = negative_log_likelihood(x_train, y_train, beta)\n",
    "            t.set_description(f\"loss: {loss:.3f} beta: {beta}\")\n",
    "    \n",
    "    from scratch.working_with_data import scale\n",
    "    \n",
    "    means, stdevs = scale(xs)\n",
    "    beta_unscaled = [(beta[0]\n",
    "                      - beta[1] * means[1] / stdevs[1]\n",
    "                      - beta[2] * means[2] / stdevs[2]),\n",
    "                     beta[1] / stdevs[1],\n",
    "                     beta[2] / stdevs[2]]\n",
    "    # [8.9, 1.6, -0.000288]\n",
    "    \n",
    "    \n",
    "    \n",
    "    assert (negative_log_likelihood(xs, ys, beta_unscaled) ==\n",
    "            negative_log_likelihood(rescaled_xs, ys, beta))\n",
    "    \n",
    "    true_positives = false_positives = true_negatives = false_negatives = 0\n",
    "    \n",
    "    for x_i, y_i in zip(x_test, y_test):\n",
    "        prediction = logistic(dot(beta, x_i))\n",
    "    \n",
    "        if y_i == 1 and prediction >= 0.5:  # TP: paid and we predict paid\n",
    "            true_positives += 1\n",
    "        elif y_i == 1:                      # FN: paid and we predict unpaid\n",
    "            false_negatives += 1\n",
    "        elif prediction >= 0.5:             # FP: unpaid and we predict paid\n",
    "            false_positives += 1\n",
    "        else:                               # TN: unpaid and we predict unpaid\n",
    "            true_negatives += 1\n",
    "    \n",
    "    precision = true_positives / (true_positives + false_positives)\n",
    "    recall = true_positives / (true_positives + false_negatives)\n",
    "    \n",
    "    print(\"Precision and Recall are as follows:\")\n",
    "    print(\"Precision\")\n",
    "    print(precision)\n",
    "    print(\"Recall:\")\n",
    "    print(recall)\n",
    "    \n",
    "    assert precision == 0.75\n",
    "    assert recall == 0.8\n",
    "    \n",
    "    \n",
    "    \n",
    "    plt.clf()\n",
    "    plt.gca().clear()\n",
    "    \n",
    "    predictions = [logistic(dot(beta, x_i)) for x_i in x_test]\n",
    "    plt.scatter(predictions, y_test, marker='+')\n",
    "    plt.xlabel(\"predicted probability\")\n",
    "    plt.ylabel(\"actual outcome\")\n",
    "    plt.title(\"Logistic Regression Predicted vs. Actual\")\n",
    "    plt.show()\n",
    "    plt.savefig('im/logistic_regression_predicted_vs_actual.png')\n",
    "    plt.gca().clear()\n",
    "    \n",
    "if __name__ == \"__main__\": main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e6905a-e91c-4767-b322-d721db690670",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
